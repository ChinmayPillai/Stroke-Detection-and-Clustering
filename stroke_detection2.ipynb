{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder containing audio files\n",
    "audio_folder = \"audio/audio\"  # Replace with the path to your audio files folder\n",
    "\n",
    "# Set the parameters for Mel spectrogram\n",
    "n_fft = 512  # Number of points in each FFT\n",
    "hop_length = n_fft  # Hop size\n",
    "fft_len = n_fft//2 + 1  # Number of Mel bands\n",
    "window = \"hann\"  # Window function\n",
    "stft_taken = fft_len//4\n",
    "\n",
    "# Initialize an empty matrix\n",
    "stft_matrix = []\n",
    "flux_arr = []\n",
    "spectogram_matrix = []\n",
    "mfcc_matrix = []\n",
    "\n",
    "# Iterate through audio files in the folder\n",
    "for filename in sorted(os.listdir(audio_folder)):\n",
    "    if filename.endswith(\".wav\"):  # Adjust the file extension if needed\n",
    "        audio_path = os.path.join(audio_folder, filename)\n",
    "\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        if sr != 22050:\n",
    "            print(sr)\n",
    "\n",
    "        stft = np.abs(librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, window=window))\n",
    "        flux = librosa.onset.onset_strength(y=y, sr=sr, n_fft=n_fft, hop_length = hop_length)\n",
    "        flux = flux\n",
    "        mfcc = librosa.feature.mfcc(y=y, n_mfcc=13, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        mfcc_matrix.append(mfcc)\n",
    "        stft_matrix.append(stft[:stft_taken,:])\n",
    "        flux_arr.append(flux)\n",
    "\n",
    "stft_matrix = np.hstack(stft_matrix)\n",
    "flux_arr = np.hstack(flux_arr)\n",
    "mfcc_matrix = np.hstack(mfcc_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fc5a7c8e20>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, sharex=True)\n",
    "times = librosa.times_like(stft_matrix[:,:300])\n",
    "ax.plot(times, flux_arr[:300], alpha=0.8, label='Mean (mel)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_arr = flux_arr.T\n",
    "stft_matrix = stft_matrix.T\n",
    "mfcc_matrix = mfcc_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43005,)\n",
      "(43005, 64)\n"
     ]
    }
   ],
   "source": [
    "print(flux_arr.shape)\n",
    "print(stft_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202194, 65)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.column_stack((stft_matrix, flux_arr*4))\n",
    "features.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABwsAAANBCAYAAAAfvFEyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACbm0lEQVR4nOz9f7RlVX0g+n7XPnVOVfGjClCLolr80bEjEr2SoAMrVx3Y4VLpYN/mSaJG2oiXSPBBXpREJdGHtjfBvtrpPO1ECcm9ge4RxzUmI3aCitKaxO5YSkIUFYUkVwwKKUCBOkD9OOfsNd8fB08s5tzbdWqfH2ud9fk49hjyrbnWnHutOeea+8w9565SSikAAAAAAACA3hmsdwEAAAAAAACA9WGyEAAAAAAAAHrKZCEAAAAAAAD0lMlCAAAAAAAA6CmThQAAAAAAANBTJgsBAAAAAACgp0wWAgAAAAAAQE+ZLAQAAAAAAICe2rScxHVdxz333BPHH398VFW1WmUCAAAAAAA6IKUUDz/8cOzatSsGA+uT1suhQ4dibm5uvYuRmZmZiS1btqx3Mfg+ljVZeM8998Spp566WmUBAAAAAAA66Jvf/GY8+clPXu9i9NKhQ4fi6U//Z7Fv3wPrXZTMzp0748477zRh2HLLmiw8/vjjH/t/g4hYj5WFpTzTGuVTUsp7NcpY+jZGvcLpRqUtVZGFCdKN0vS6lcpeii0n76Zlb3p9J20bk9SX5eTd9PqW3mMzVUyPyDnP++Ttz8ti983emh+bDhVzyiLV5nLeheOnprYV0z7eOce/Nov990N/nMUOHr5vxBmW0x6PlNJ8fuQgf491fbB4fBVTjfK59NQ3ZrHfvvu3CuVp3sY+/COXZrGfuuX9+TkL7W5600lZbGF4IIs9+Mk3F/M+8dx/n8VKdaN0fasqvzfTm/K6Mr/waDHv8jlLbWKYH1sXvgVWKE8pj8f+pZB3PiBL6XAhXen65OlG2TS1vVG647bszGLf+J3/JYud8Kq8rlQj+rpqMJPFpgb5+y7FDs8XBtOFel7KIyLimh96fRb7ua/kbad0zqjy59CmqeOy2P98zCuKef/Fw79TOD6vq3XK61WpLZeuzzEzTyzm/dfn/EgW+xd/8uFCyrz/K9WVTVPHZLFSmx+lTnl7Kim1ndL7Ll2zxeMLdaNwH0vnXBg+UkiXv+/txzytmPfWqROy2D2zt2SxQZX3+7uOz+/XM9Ozs9h/m72mmHepf5jZdHwWm96Uv5+U8jqQCvdrbmSfWqirU/n13fd/7MliJ73x97NYNdiaxaY3HVvMe1PhefvLT3l5Frvq7/PrVtf5/Z7edGKeR6HuR0Tcfed/yGIn7XplFiv38Xk9n5l+QhYbFOpuRMR8oa6W1IVnVul5OazzMdigKvep5XZSaqN5Hdoyk1/fp245K4v97ClPLeb9S7e/L4v96fMvyWIvvfk3s1hp3PL6f3ZxFnvfP7ynmPdgkLen0jN483TeJ5fuV1UYZ05vyp8vERGH5/dnseO3nJLF/p9feG4We+K7/iDPu8rb2Obp/PpERMwtPJzFpgb5mKnUj5TGa3Whv9h5/A8X856v82fM7f/w1ix20on/r0Leed+wnGdJeVw5m8XK4+5m49T/dduri3n/4Xf+f8X445XGrjPTJ2SxYzefnMUeePgrxXMOCs+8YrrCc2zr5rzuf/P/flkWO+F//T9GnDXv747Z8s+y2Nx84T4UxjKlPmzU56SFYV7Pt8zk161Up+95Tz5GPvH/838Vji1/Bh4Vf7wHbrg8i53wE1fn5yt8zp8ZMVYsjeO+839emOdz0bV5PoX6V2pjpXsTEVEXnjultlO65iWlsd50YcweUe7DFuq8Px8O8zKW+ozSZ4MTtpafYw8f/scsNlfoW0rP7zO3vSqL3Vd9I4t9c///KOY9KNyfUjspXfOTjnlGFvv2I18t5lNy7OYdhfLk9+xv/tUPZbF//od/msWafnaPiJjZdEIW2zqTj7keOXR3Fit/1snr9HQhj4iI+/7Tv85iJ1ya9w9TU/kYo9RGSmOM0hhu0ZH3MaU6Fob3fc/8AWttbm4u9u17IL7xD38Q27Y1e96uhdnZA/G0p7485ubmTBa23LImC/9p69Eq1mOysPTHwdWZKmz23spThStfxtKWrymVJkeOPt1qnLOUbpSm161c9gnzXunrO2HbmGyqsHneTa/vcq5lk/ONUvpDVfH4UnkK6UbmXby3zT4cTBc+ZJWOHf2+m9XfpseW8hmVd9O6sbkwuG/a7kY5dlPpujW7t02v77Zjy4ON5teo6fWd7H43vpaldMu5D4UGPsn7Xs79bv5hO/8D0LZjmtWVkZOFje9Z0/vYvI1tnWpYzxve71IZN438A1DD9138ckLTa1b+wsHx06UP/02vZdN703wLm6rxF1yaXrPJ2nfTulZKN2oCZ1D4w0Xzc+bHTkfTuruc91iqL836kdH3u1nd2La1WZ1s+l4W4/n72VKYqJwkn1F5lz7kl+rlSre7cfEmeU/avpv3a80mj6YKf6jcWriHo/IujmUaXt/i2GoZz7GJ+s9l/FG8fM0Lz+otpQneSdvY0Y/Pm77v0X1qHt+2Lf/iwETte+T9PvrxSNN6MV34ssPofJqlKz9f8rqynGdJOV2z50v5c8DKjxXL52v6ZebJ8i4925YzTm16zZtey+W178L7aTrmn6BvGHX8cq5bk7yXM3Zo3ndPNlac5PPPpsLzsunYc3l5N3s/y7vfpWte6DMafn5Zzufi5v3iJJ9DR4wVtzZtT0f/uWQ54/NR52Vtbdt2THE8A9/PsiYLAQAAAAAAaKG6Xny1RZvKwlh+bRQAAAAAAAB6ymQhAAAAAAAA9JRtSAEAAAAAALrONqQcJSsLAQAAAAAAoKdMFgIAAAAAAEBP2YYUAAAAAACg62xDylGyshAAAAAAAAB6ymQhAAAAAAAA9FSVUkpNE8/Ozsb27dsjYioiqtUrFQDQO1VhbJGi8TAFIKoq/y5kSiu/7c1a9Vf6xXZwH/5JH65FVeW/1pLSwjqUhCb6USfX5tk2qKazWJ3mVzyftXo/0Aft6gNTRAxj//79sW3btnUqQ799d+7mgX1/FNu2HbvexVkyO/tonLTzAnWjA6wsBAAAAAAAgJ4yWQgAAAAAAAA9le+vAQAAAAAAQLfUKaJu0fbO9cbaHnwjs7IQAAAAAAAAespkIQAAAAAAAPSUbUgBAAAAAAC6rq5btg1pi8rCWFYWAgAAAAAAQE+ZLAQAAAAAAICesg0pAAAAAABA19mGlKNkZSEAAAAAAAD0lJWFAHReFVUxniKtcUmYSFW4j8k9BJaj9F3IDn+TVb8Ia640rtTq2qsX4/216verwjO0B5cXOs1YEVhBJgsBAAAAAAC6zjakHCXbkAIAAAAAAEBPmSwEAAAAAACAnrINKQAAAAAAQNellm1DmlpUFsayshAAAAAAAAB6ymQhAAAAAAAA9JRtSAEAAAAAADquSnVULdr6s01lYTwrCwEAAAAAAKCnTBYCAAAAAABAT9mGFAAAAAAAoOvqevHVFm0qC2NZWQgAAAAAAAA9ZWUhAN1XVeV4SmtbDuiZKvK2l0K7Yz1ttG+tlr7budHe4/oo9V8R+jAiUgzXuwgsg7HICkpr9XzxbIOVoz0BK8dkIQAAAAAAQNfVafHVFm0qC2PZhhQAAAAAAAB6ymQhAAAAAAAA9JRtSAEAAAAAALqurhdfbdGmsjCWlYUAAAAAAADQUyYLAQAAAAAAoKdsQwoAAAAAANB1tiHlKFlZCAAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAXZdSRGrR1p8prXcJaMjKQgAAAAAAAOgpKwsBADgqKXxDkHZJbfoGLWxAvej3C99+r6r8e9b6Gzhaedupomp0ZC/6IFZVqT8v9ftdrmul9tTl9wOsHZOFAAAAAAAAXVfXi6+2aFNZGMs2pAAAAAAAANBTJgsBAAAAAACgp2xDCgAAAAAA0HV1Wny1RZvKwlhWFgIAAAAAAEBPmSwEAAAAAACAnrINKQAAAAAAQNfV9eKrLdpUFsayshAAAAAAAAB6ymQhAAAAAAAA9JRtSAEAAAAAALoutWwb0tSisjCWlYUAAAAAAADQU1YWAgDtkNJ6l4BlqqLKYincR9aPOsmqqPJ65Zm1gZXud/F71r4lz8bStudl28rDxlDFVBarY34dSrJSPIuAlWOyEAAAAAAAoOOquo6qRduQtqksjGcbUgAAAAAAAOgpk4UAAAAAAADQU7YhBQAAAAAA6LqU2vX72m0qC2NZWQgAAAAAAAA9ZbIQAAAAAAAAeso2pAAAAAAAAF1X14uvtmhTWRjLykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAAAAAOg625BylKwsBAAAAAAAgJ6yshCA7ktpvUvACkjhPgITqqo81uFnRFVNZbGUFtahJBvP8p45pe/YNvuGdBV5nfS8a7linzFc82LQTFXlf9ZKaX4dSrIBpPWr5/pF1krSnwOMZLIQAAAAAACg6+q0+GqLNpWFsWxDCgAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAXVfXi6+2aFNZGMvKQgAAAAAAAOgpk4UAAAAAAADQU7YhBQAAAAAA6Lo6tWvrzzqtdwloyMpCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADoupQWX23RprIwlpWFAAAAAAAA0FNWFgLQeSl8SwnWg7ZHX61d3ffdzs6rqjzW4W9XV5G/n432LKgGM1ks1XPrUBKaKN2vGM6vfUFWUzWVx9LCKuSzNv1VVU0X8mnWxjZaf8N6KI2t6jUvxUqpIu8f6thgfSCwZkwWAgAAAAAAdF1dL77aok1lYSxfVQUAAAAAAICeMlkIAAAAAAAAPWUbUgAAAAAAgK5LKaJu0W+8dvj3uvvGykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAAAAAOi6ul58tUWbysJYVhYCAAAAAABAT5ksBAAAAAAAgJ6yDSkAAAAAAEDX2YaUo2SyEIDOq6IqxlOkNS4JkyjdR/ew3dwzWGVpYb1LQEREGk5wrD5xo/IMbIdBtTmLDePRdSjJ6qmq6SyWOvx8qKr8T5Gpms8T6j9ZDYVneqf78yrfNLBKHX4/wLqyDSkAAAAAAAD0lJWFAAAAAAAAXVenxVdbtKksjGVlIQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdF2qF19t0aayMJaVhQAAAAAAANBTJgsBAAAAAACgp2xDCgAAAAAA0HV1Wny1RZvKwlhWFgIAAAAAAEBPmSwEAAAAAACAnrINKQAAAAAAQNfV9eKrLdpUFsYyWQgAtEIK+9h3jXsGq6tO8+tdBEJf1z/5BkylOlBVhY2akrqy1or3YYNJG+xZUNeH82Ch7eh7WRXVVB5LwzxZVHmyDtfJjfZ+gNWx8UdVAAAAAAAAQJGVhQAAAAAAAF1Xp8VXW7SpLIxlZSEAAAAAAAD0lMlCAAAAAAAA6CnbkAIAAAAAAHRdnSLqer1L8U9sQ9oZVhYCAAAAAABAT5ksBAAAAAAAgJ6yDSkAAAAAAEDX1aldW3+2qSyMZWUhAAAAAAAA9JTJQgAAAAAAAOgp25ACAAAAAAB0Xh2R6vUuxPdoU1kYx2QhAACwMaSN9XsYVZVvBJNa9cG/H6qosliKZnWtaTrao9TuqqrZn06qZdxvdWNlDOuD612E1ZeGa5JNFVN51qvwB95Sn1oX2oNnIKuh/EwHIMI2pAAAAAAAANBbVhYCAAAAAAB0XZ0WX23RprIwlpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQdbYh5ShZWQgAAAAAAAA9ZbIQAAAAAAAAeso2pAAAAAAAAF1X14uvtmhTWRjLykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAAAAAOi6Oi2+2qJNZWEsk4UAAAAtlJLf92iFqspjyR89NqpSu6uqqUK6YR4L9WKt1cMD612E1Veof5EWVj6bwdY8OJxf8Xyiyv8UWZXeT8N+topCHx3aIyNUhU32elBVtAegCduQAgAAAAAAQE9ZWQgAAAAAANB1tiHlKFlZCAAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAXVfXi6+2aFNZGMvKQgAAAAAAAOgpk4UAAAAAAADQU7YhBQAAAAAA6LqUFl9t0aayMJaVhQAAAAAAANBTJgsBAAAAAADojL/927+Nf/Nv/k088YlPjG3btsULX/jC+LM/+7Mj0tx1111x3nnnxTHHHBM7duyIN73pTbGwsDD2vA888EBceOGFsW3btjjhhBPi4osvjkceeeSINF/60pfiRS96UWzZsiVOPfXUePe7352d58Mf/nCcdtppsWXLlnjOc54TH/vYx47495RSXHXVVXHKKafE1q1b45xzzom/+7u/W5WyNGGyEAAAAAAAoOvq1L7XBM4+++y47rrriv/20pe+NBYWFuLTn/503HLLLfHc5z43XvrSl8a+ffsiImI4HMZ5550Xc3Nz8dnPfjauv/76uO666+Kqq64am+eFF14Yt912W9x0001xww03xGc+85m45JJLlv59dnY2zj333HjqU58at9xyS7znPe+Jd7zjHXHttdcupfnsZz8bP/3TPx0XX3xxfOELX4jzzz8/zj///PjKV76ylObd7353vO9974trrrkmPv/5z8exxx4be/bsiUOHDq1oWZqqUmq+aezs7Gxs3749IqYiolp2ZgCwGqoRz6QU9kXvktJ9dA+B5dho/UhV5T8xn9L4b8Gy8jZavZpEH67Fpk0nZLHhcDZPWPhTyka7Fl2gn1w5pbq/sPDQiuczNbUti9XDhxsdq40xqVKfEWmYhzpS1waDzVks1XN5bE3eT4qIYezfvz+2bcvbOavvu3M3D/2fl8W2Y/K6sV5mDxyOEy7+raOuG2effXZcdNFFcdFFFx0R//a3vx1PetKT4jOf+Uy86EUvioiIhx9+OLZt2xY33XRTnHPOOfHxj388XvrSl8Y999wTJ598ckREXHPNNfGWt7wl7r///piZmcny+9rXvhann356/NVf/VU873nPi4iIG2+8MX7iJ34ivvWtb8WuXbviAx/4QLz1rW+Nffv2LZ3jyiuvjI985CNx++23R0TEK17xinj00UfjhhtuWDr3C17wgjjjjDPimmuuiZRS7Nq1K37xF38xfumXfikiIvbv3x8nn3xyXHfddfHKV75yxcrSlJWFAAAAAAAArIrZ2dkjXocPH57ofE94whPimc98Zvzn//yf49FHH42FhYX47d/+7dixY0eceeaZERGxd+/eeM5znrM0URgRsWfPnpidnY3bbruteN69e/fGCSecsDQ5FxFxzjnnxGAwiM9//vNLaV784hcfMdm4Z8+euOOOO+LBBx9cSnPOOeccce49e/bE3r17IyLizjvvjH379h2RZvv27XHWWWctpVmpsjRlshAAAAAAAKDr1nvL0RHbkJ566qmxffv2pde73vWuid5mVVXx3/7bf4svfOELcfzxx8eWLVviP/7H/xg33nhjnHjiiRERsW/fviMmCiNi6b+/u1Xp4+3bty927NhxRGzTpk1x0kknLR3T5Lyj0nzvv3/vcaPSrERZmiqsvQYAAAAAAIDJffOb3zxiG9LNm8tbpV599dVx9dVXL/33wYMH43Of+1xcfvnlS7GvfvWrceqpp8Zll10WO3bsiP/+3/97bN26NX73d383/vW//tfxV3/1V3HKKaes3pvZoEwWAgAAAAAAsCq2bdvW6DcLL7300nj5y1++9N8XXnhhXHDBBfGyl71sKbZr16749Kc/HTfccEM8+OCDS+d9//vfHzfddFNcf/31ceWVV8bOnTvj5ptvPuL89957b0RE7Ny5s5j/zp0747777jsitrCwEA888MDSMTt37lw6z6jzjkrzvf/+3dj3Tmzee++9ccYZZ6xoWZqyDSkAAAAAAEDXpTqibtEr1csq/kknnRTPeMYzll5bt26NHTt2HBHbtGlTHDhwICIiBoMjp7gGg0HU9WKeu3fvji9/+ctHTLjddNNNsW3btjj99NOL+e/evTseeuihuOWWW5Zin/70p6Ou6zjrrLOW0nzmM5+J+fn5I877zGc+c2kL1N27d8enPvWpI8590003xe7duyMi4ulPf3rs3LnziDSzs7Px+c9/finNSpWlKZOFAAAAAAAAdMLu3bvjxBNPjNe85jVx6623xt/+7d/Gm970prjzzjvjvPPOi4iIc889N04//fR49atfHbfeemt84hOfiLe97W1x2WWXLW2DevPNN8dpp50Wd999d0REPOtZz4of//Efj9e97nVx8803x1/+5V/G5ZdfHq985Stj165dERHxqle9KmZmZuLiiy+O2267LT70oQ/Fe9/73rjiiiuWyvcLv/ALceONN8av//qvx+233x7veMc74q//+q+XtlOtqire8IY3xK/+6q/Gn/zJn8SXv/zl+Jmf+ZnYtWtXnH/++StalqZMFgIAAAAAANAJT3ziE+PGG2+MRx55JP7lv/yX8bznPS/+x//4H/Ff/+t/jec+97kRETE1NRU33HBDTE1Nxe7du+Pf/tt/Gz/zMz8T73znO5fOc+DAgbjjjjuOWJn3+7//+3HaaafFj/3Yj8VP/MRPxAtf+MK49tprl/59+/bt8clPfjLuvPPOOPPMM+MXf/EX46qrropLLrlkKc2P/uiPxgc/+MG49tpr47nPfW784R/+YXzkIx+JZz/72Utp3vzmN8fP//zPxyWXXBLPf/7z45FHHokbb7wxtmzZsqJlaapKKaWmiWdnZ2P79u0RMRUR1bIzA4DVUI14JqVo/IijBUr30T0ElmOj9SNVlf/EfEoL61CSftto9WoSfbgWmzadkMWGw9k8YeFPKRvtWnSBfnLllOr+wsJDK57P1FT+e1X18OFGx2pjTKrUZ0Qa5qGO1LXBYHMWS/VcHluT95MiYhj79+9v9Lt0rLzvzt08dM3Pxbated1YL7MHD8cJl/62utEBVhYCAAAAAABAT5ksBAAAAAAAgJ4qrL0GAAAAAACgU+qIqFu0lW693gWgKZOFAEArdOV3IYD22mj9SFVNZTG/xQWrq64P5sHC7xNGVfjN7FI6VlX5dzQ3lrX6Xca6Przi5yxJqWE+2hirocO/T1iUzMIAK8c2pAAAAAAAANBTVhYCAAAAAAB0XZ1atg1pi8rCWFYWAgAAAAAAQE+ZLAQAAAAAAICesg0pAAAAAABAx6U6RWrR1p9tKgvjWVkIAAAAAAAAPWWyEAAAAAAAAHrKNqQAAAAAAABdl9Liqy3aVBbGsrIQAAAAAAAAespkIQAAAAAAAPSUbUgBAAAAAAC6rk6Lr7ZoU1kYy2QhAABAC6U0XO8iwBFS9POPPaX3XfXzUrAu6jXJJaXDa5JP403O/MYVq2CjPcdK72ejvUdg7diGFAAAAAAAAHrKykIAAAAAAICusw0pR8nKQgAAAAAAAOgpk4UAAAAAAADQU7YhBQAAAAAA6DrbkHKUrCwEAAAAAACAnjJZCAAAAAAAAD1lG1IAAAAAAICusw0pR8nKQgAAAAAAAOgpk4UAAAAAAADQU7YhBQAAaKM0XO8SQO+kNJ/FqqrwPetkS602SGlhvYuw+jZYXUv1oWbpYmO9b9qhaX/enfpXr3cBaKGUUqQWbf2ZNthzbCOzshAAAAAAAAB6ymQhAAAAAAAA9JRtSAEAAAAAALquTouvtmhTWRjLykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAAAAAOg625BylKwsBAAAAAAAgJ4yWQgAAAAAAAA9ZRtSAAAAAACArrMNKUfJykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAOiIKqoslsLWPrBSBoOtWSylOo/FfBar0rCQrtw+teUVUuXXMdIGu45r9h5L6wnyur9WtBFWQ1VNZ7Fyf54f2876l7fbqlDOdpadVZNSu56FbSoLY1lZCAAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAHZfqxVdbtKksjGdlIQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdF2dFl9t0aayMJaVhQAAAAAAANBTJgsBAAAAAACgp2xDCgAAAAAA0HW2IeUoWVkIAAAAAAAAPWWyEAAAAAAAAHrKNqQAdF9VlePJVgcAbCwpPNvWXGmc0dMxRhX5tdhodTKluhCbL6TM08FqqKrpLJbS4ZXPp9i+V0E1leeTFhqVByZV7M8Lz/QuP9u6XHZWRqoXX23RprIwnpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQdSlF1C3ajran2/d3kZWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQdfVjr7ZoU1kYy8pCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADouFSnSHVa72IsaVNZGM/KQgAAAAAAAOgpk4UAAAAAAADQU7YhBWADGPXdl3pNS8Fkqiq/jym5hwCsryqmslgyxtiwNk0dn8XmFx446vNVURXjKWzJtRKqanMeTIeKabt6zVOaz2KlejXp+6sGM3lwmOc9qarK+9RIwzzU0ftFu5Wf6QvrUBJYRXW0689hbSoLY1lZCAAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAXZcee7VFm8rCWFYWAgAAAAAAQE+ZLAQAAAAAAICesg0pAAAAAABAx6U6Rarbs/dnm8rCeFYWAgAAAAAAQE+ZLAQAAAAAAICesg0pAAAAAABA19WPvdqiTWVhLCsLAQAAAAAAoKdMFgIAAAAAAEBP2YYUgM6roirG0xqXAwDYeJIRxT+pCmOutLGuT0oLR39soa6MGqeyMqoq/w583YM2uxr9Ukprs09cSvN5sNC3VIW3qD9mNXS5XpWfMXmsy++R5Uv14qst2lQWxrOyEAAAAAAAAHrKZCEAAAAAAAD0lG1IAQAAAAAAuq5+7NUWbSoLY1lZCAAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAHZfqxVdbtKksjGdlIQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdF2KiDZt/ZnWuwA0ZWUhAAAAAAAA9JTJQgAAAAAAAOgp25AC0HkphutdBFZASm3aJwOgBaqpPJYW1r4cfZeMM/pkYfhQFjNGaa8+3Jsq8mdBWoX95VKaX/FzllTV9LrlDWmjjaOqwjogWz72XkqLr7ZoU1kYz8pCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADouFQvvtqiTWVhPCsLAQAAAAAAoKdMFgIAAAAAAEBP2YYUAAAAAACg6+rHXm3RprIwlpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQcalefLVFm8rCeFYWAgAAAAAAQE9ZWQhA96W03iUAoAWqqLJYCs8IcqW6ElGuL+rQ9yp933hjfV28qqazWEqH83Qj6lB2rPqzqlKaX+8irLqUFtYop7VpyykNC7FmeXvOM7Gq0Hd3+u8J+XNZmwCOlslCAAAAAACAjkupXXPgbSoL49mGFAAAAAAAAHrKZCEAAAAAAAD0lG1IAQAAAAAAuq6uFl9t0aayMJaVhQAAAAAAANBTJgsBAAAAAACgp2xDCgAAAAAA0HGpXny1RZvKwnhWFgIAAAAAAEBPmSwEAAAAAACAnrINKQAAAAAAQMelVEVK1XoXY0mbysJ4VhYCAAAAAABAT1lZCAC0QhXNvm2WIq1ySQDaos4ipb5Sv7h8y7lmVZV/bE5podmx7lfnDAZbs1hK81msiqk8XeHeVmlYzqgqjHtSfrz6Ml6pLVZV+XvxKeV9aidUeV0r1atJ60q5Tq/GNSs820bcs1wh3Yj+WP9LU6XnfKmejrSufXfD9uT5AjRgshAAAAAAAKDjUr34aos2lYXxbEMKAAAAAAAAPWWyEAAAAAAAAHrKNqQAAAAAAAAdl1K7tv4s/GQmLWVlIQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdFxKVaRUrXcxlrSpLIxnZSEAAAAAAAD0lMlCAAAAAAAA6CnbkAIAAAAAAHRdXUWqW7T1Z5vKwlhWFgIAAAAAAEBPWVkIALRCVeXDkpQW1qEky1dF/k25FGkdSrK2qir/3llK9TqUBBaV2t1qtM+1avNVtTnPJx1a8XwYbzDI78Nw2PD5VBW+SZ26+3wo1/2NZdvWU7PYg4/clsUa9zelOhBRrgcbrL6shdJYxDU7OlNTx2exeuGBRseW6n5EuZ3MTO/IYnPz9+XHFsaUg2qqmHtTfR2z80+qajqLpTRsePSoNTf58WtW13z2AlaQyUIAAAAAAICOS6ld35tpU1kYzzakAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQcSlVkVLz33NdbW0qC+NZWQgAAAAAAAA9ZbIQAAAAAAAAeso2pAAAAAAAAB2X6ipS3Z6tP9tUFsazshAAAAAAAAB6ymQhAAAAAAAA9JRtSAEAAAAAADoupcVXW7SpLIxnZSEAAAAAAAD0lJWFAEBrpejGV9C6Uk54vCryH5vvcn0uvZ+oCrGOfL21qqazWIpDeboNdh/XQrGuxKjrNtXo+OKxHalr/JO5hUcbpUtpIQ9Whe9jj6gD6svKqArts475dSjJ6in3NysvRd0w78lyn194sBDN205VyCfFsHE+noOUpFSoQ4VYqf6U6uSotG3ThTIC689kIQAAAAAAQMelVEVK5S/GrYc2lYXxbEMKAAAAAAAAPWWyEAAAAAAAAHrKNqQAAAAAAAAdV9dV1HV7tv5sU1kYz8pCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADouJQWX23RprIwnpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQcSlVkVK13sVY0qayMJ6VhQAAAAAAANBTJgsBgFao03z26oqq8L8+SKnOXnRLKvyv06oqf6WUvzoi1QezVzHdRruPa6B0zUZdt5Tmsxf/ZKM9Ax89eGf2aqzQ3yynrrF8pWtbqpNdrpfVYCZ7FZ93E6rrw9mrqeXU86raXHhNZ6/SezT2ZFKlvqFpP9KV/rzUTjZSnwiP99GPfjTOOuus2Lp1a5x44olx/vnnH/Hvd911V5x33nlxzDHHxI4dO+JNb3pTLCwsjD3nAw88EBdeeGFs27YtTjjhhLj44ovjkUceOSLNl770pXjRi14UW7ZsiVNPPTXe/e53Z+f58Ic/HKeddlps2bIlnvOc58THPvaxI/49pRRXXXVVnHLKKbF169Y455xz4u/+7u9WpSxNmCwEAAAAAADouO9uQ9qm1yTOPvvsuO6664r/9kd/9Efx6le/Ol772tfGrbfeGn/5l38Zr3rVq5b+fTgcxnnnnRdzc3Px2c9+Nq6//vq47rrr4qqrrhqb54UXXhi33XZb3HTTTXHDDTfEZz7zmbjkkkuW/n12djbOPffceOpTnxq33HJLvOc974l3vOMdce211y6l+exnPxs//dM/HRdffHF84QtfiPPPPz/OP//8+MpXvrKU5t3vfne8733vi2uuuSY+//nPx7HHHht79uyJQ4cOrWhZmqpSav7V2tnZ2di+fXtETEX4BgIALTHqW3Ft/JYfG1OpDqp/sPaqqvBdyMLHnUnb51q1+UE1neeT8m/B6m9W12CwNYul+lAeK9yHjfZ86EOdLI4rC6u2SiuaNtr97oKq2pQH07CYtqv3Ymrq2CxWF1aaT7rKbpK+bjmmprbl5yys2E4pX9nYtN1FdPd+s7pKz7HSjjZd6c/b9X5SRAxj//79sW1b3s5Zfd+du7ntxy+K46dn1rs4Sx6en4sfuvG6o64bZ599dlx00UVx0UUXHRFfWFiIpz3tafHv/t2/i4svvrh47Mc//vF46UtfGvfcc0+cfPLJERFxzTXXxFve8pa4//77Y2Ymv05f+9rX4vTTT4+/+qu/iuc973kREXHjjTfGT/zET8S3vvWt2LVrV3zgAx+It771rbFv376lc1x55ZXxkY98JG6//faIiHjFK14Rjz76aNxwww1L537BC14QZ5xxRlxzzTWRUopdu3bFL/7iL8Yv/dIvRUTE/v374+STT47rrrsuXvnKV65YWZqyshAAAAAAAIBVMTs7e8Tr8OHm212X/M3f/E3cfffdMRgM4od/+IfjlFNOiX/1r/7VESv39u7dG895znOWJgojIvbs2ROzs7Nx2223Fc+7d+/eOOGEE5Ym5yIizjnnnBgMBvH5z39+Kc2LX/ziIyYb9+zZE3fccUc8+OCDS2nOOeecI869Z8+e2Lt3b0RE3HnnnbFv374j0mzfvj3OOuuspTQrVZamTBYCAAAAAACwKk499dTYvn370utd73rXROf7+te/HhER73jHO+Jtb3tb3HDDDXHiiSfG2WefHQ888EBEROzbt++IicKIWPrvffv2Fc+7b9++2LFjxxGxTZs2xUknnbR0TJPzjkrzvf/+vceNSrMSZWmqsF8DAAAAAAAAXVKnKuoJfydwJX23LN/85jeP2IZ08+bNxfRXX311XH311Uv/ffDgwfjc5z4Xl19++VLsq1/9atT14tbUb33rW+OCCy6IiIjf+73fiyc/+cnx4Q9/OH7u535uxd/LRmeyEAAAAAAAgFWxbdu2Rr9ZeOmll8bLX/7ypf++8MIL44ILLoiXvexlS7Fdu3bFKaecEhERp59++lJ88+bN8c//+T+Pu+66KyIidu7cGTfffPMR57/33nuX/q1k586dcd999x0RW1hYiAceeGDpmJ07dy6dZ9R5R6X53n//buy77+W7/33GGWesaFmasg0pAAAAAAAA6+qkk06KZzzjGUuvrVu3xo4dO46Ibdq0Kc4888zYvHlz3HHHHUvHzs/Pxze+8Y146lOfGhERu3fvji9/+ctHTLjddNNNsW3btiMmGb/X7t2746GHHopbbrllKfbpT3866rqOs846aynNZz7zmZifnz/ivM985jPjxBNPXErzqU996ohz33TTTbF79+6IiHj6058eO3fuPCLN7OxsfP7zn19Ks1JlacpkIQAAAAAAQMelumrdazVs27YtLr300nj7298en/zkJ+OOO+6I17/+9RER8VM/9VMREXHuuefG6aefHq9+9avj1ltvjU984hPxtre9LS677LKlbVBvvvnmOO200+Luu++OiIhnPetZ8eM//uPxute9Lm6++eb4y7/8y7j88svjla98ZezatSsiIl71qlfFzMxMXHzxxXHbbbfFhz70oXjve98bV1xxxVL5fuEXfiFuvPHG+PVf//W4/fbb4x3veEf89V//9dJ2qlVVxRve8Ib41V/91fiTP/mT+PKXvxw/8zM/E7t27Yrzzz9/RcvSlG1IAQAAAAAA6Iz3vOc9sWnTpnj1q18dBw8ejLPOOis+/elPL62om5qaihtuuCFe//rXx+7du+PYY4+N17zmNfHOd75z6RwHDhyIO+6444iVeb//+78fl19+efzYj/1YDAaDuOCCC+J973vf0r9v3749PvnJT8Zll10WZ555ZjzxiU+Mq666Ki655JKlND/6oz8aH/zgB+Ntb3tb/Mqv/Er8i3/xL+IjH/lIPPvZz15K8+Y3vzkeffTRuOSSS+Khhx6KF77whXHjjTfGli1bVrQsTVUppdQ08ezsbGzfvj0ipiKiPT+SCUC/VSOeSSkaP+JgIqU6qP7B2quqwsYphY87k7bPtWrzg2o6zyctrEne/JPBYGsWS/WhPFa4Dxvt+dCHOlkcV1aF+5jqRsd2+Vp0QVUVvgOfhsW0Xb0XU1PHZrG6PpjFSnVyOSbp65Zjair/vaqU5guxw4VYs3YX0d37zeoqPcfqQv3rSn/erveTImIY+/fvb/S7dKy8787dfOl/+d/i+OmZ9S7Okofn5+J/uun/Ujc6wMpCAAAAAACAjkup+H3JddOmsjCeyUIAuq/wbe+IMCLpmNKKoEm/Ic3q6so3bumTQj8S+aqnLtPG1sEGWzm30jbatdi65dQsdvDwPVmsKrzvjXYtuqA0FqlH3IeujluK4+FV+ZyzjuPuQj/rsxyrIUV55XFnFT5DV8lugMDRKezTAwAAAAAAAPSBlYUAAAAAAAAdV0cVdYtWmNYjfluW9rGyEAAAAAAAAHrKZCEAAAAAAAD0lG1IAQAAAAAAOi6lKlKLtiFtU1kYz8pCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADouJSqqFu09adtSLvDykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAAAAAOi4lKpWbf3ZprIwnslCAFZVFfmgIEVah5LQeqnD9aIqDH67/H6a6uv7psXq9S7AyqoKG8FoYmsuxXC9i8AaOjz/UBYrjWejKvw5JS0U0o34A1nheWmMvLq6en1Tms9jq/BeqkKdTjG34vmUlPrZ0nusis/Fbt5X1kteh6pSeyr03dWIqtbVvgXg8WxDCgAAAAAAAD1lZSEAAAAAAEDH1dGu/VbaVBbGs7IQAAAAAAAAespkIQAAAAAAAPSUbUgBAAAAAAA6LqUqUqrWuxhL2lQWxrOyEAAAAAAAAHrKZCEAAAAAAAD0lG1IAQAAAAAAOq5OEXWLtv6s03qXgKasLAQAAAAAAICeMlkIAAAAAAAAPWUbUgC6L5X3NKhiZbddSGHvhNVUVYVhSVrIQyPuQ+l+u2drz32AlZPSfBbTxtbBiHFGo0Pdm845ddvuLPaPj96axaoq/+71cHgoj9UHi/mkOFwI5vVlkjY/aiy8oeplcfyY953dVq9JLimtTT6bp0/IYgcPP5LFSp8NBoNjslhKhbYUUawHa/Ueaa/pTSdlsWH9aBYr1pVqRP1Jw0axVel7C+XcUH08RyWlKlKLtiFtU1kYz8pCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADouDotvtqiTWVhPCsLAQAAAAAAoKdMFgIAAAAAAEBP2YYUAAAAAACg41KqIqVqvYuxpE1lYTwrCwEAAAAAAKCnTBYCAAAAAABAT9mGFAAAAAAAoOPqqKKO9mz92aayMJ6VhQAAAAAAANBTJgsBAAAAAACgp2xDCkD3VauwpUFKK39OxqtK32Eq3NsR9yaFe7bmCvfCfWB9lfqRes1LsVKqajqL1enwOpSEo1UVnmNd7ie7XPamNlVbstjMpuOz2NzCw1ksLae/WYOxZh/uV6mfjDi45uVYTVVMFaKrMAZLCyt/zhWW0vx6F4HOy/vplAp9d6E9lD+vrq+2tVHaIaV2/UmrTWVhvPb1cgAAAAAAAMCaMFkIAAAAAAAAPWUbUgAAAAAAgI6rUxV1WoWf6zlKbSoL41lZCAAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAHZeiijras/VnalFZGM/KQgAAAAAAAOgpk4UAAAAAAADQU7YhBQAAAAAA6LiUFl9t0aayMJ6VhQAAAAAAANBTJgsBAAAAAACgp2xDCsCqSrEW+w2M+O5LGjY6em3KyPeT6rk81pV709N9NTpzf+iRek1yWbO6n9bm/fRRFVUxvuL3tirk09NnRld869G/ymILwwNZbLiwP4uV6s+kdc2z9vtpNt6PKN+Lrl7f1Sj3Wl2LQ3P3N0tY+CxXp4UVLg19Mz//nUbpiv15KvfnTY9fHcaK5OpURb2M+rra2lQWxrOyEAAAAAAAAHrKZCEAAAAAAAD0lG1IAQAAAAAAOi5FFWnENujroU1lYTwrCwEAAAAAAKCnTBYCAAAAAABAT9mGFAAAAAAAoOPqtPhqizaVhfGsLAQAAAAAAICeMlkIAAAAAAAAPWUbUgAAAAAAgI6rUxV1qta7GEvaVBbGs7IQAAAAAAAAespkIQAAAAAAAPSUbUgB2ADqxilTpFUsB6yeKspbd6jT8D3SxmoPKS1ksVJfoB9osQ1WJ/vg8Ny+ZgmrqTxUGJOm1HycutL6MHZI9VzztBvofa+G0jNnrQwGW7NYsTxpvhAr31f3m8aqQl9ZqFfqFF2Rooo0YgywHtpUFsazshAAAAAAAAB6ymQhAAAAAAAA9JRtSAEAAAAAADquTouvtmhTWRjPykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAAAAAOi4FFWkqNa7GEvaVBbGs7IQAAAAAAAAespkIQAAAAAAAPSUbUgBAAAAAAA6rk6Lr7ZoU1kYz8pCAAAAAAAA6CmThQAAAAAAANBTtiEFoPtSeU+DFPY66BL3C+BxqioLpVSvQ0F6rnAfRo09VvTYVtr49W8w2JrF6uGBPGGVX4u2tU9jq41hre5jVeXrCVajTpfyaazT/Sdt1ba+e3ny9lQaepR0+30zTp2qqFPDirAG2lQWxrOyEAAAAAAAAHrKZCEAAAAAAAD0lG1IAQAAAAAAOi499mqLNpWF8awsBAAAAAAAgJ4yWQgAAAAAAAA9ZRtSAAAAAACAjktRRZ2q9S7GkhTtKQvjWVkIAAAAAAAAPWWyEAAAAAAAAHrKNqQAAAAAAAAdVz/2aos2lYXxrCwEAAAAAACAnjJZCAAAAAAAAD1lG1IAuq+qyuHU7PAUDROyqqqqMCxJwzw04f2qIq8vXagDbSxjVeXfO0vJJiOwUqqYKkTzvqCN/cPGUvqOrb5uozp+y1Oy2IG572SxOs1lseFwtnE+VTWdBwvP0HL7LtS/1NO+oTAW2XBvuzAeXh3r19eltFCIzTc7dsQNL435R31uLGTeOB+6ZXr6SVlsYbg/ixXrX6FejFSsa83a2HI+T5U/2xYUyt7Vz8V8fylVkVLD/m4NtKksjGdlIQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdFwd7dowv01lYTwrCwEAAAAAAKCnTBYCAAAAAABAT9mGFAAAAAAAoOPqtPhqizaVhfGsLAQAAAAAAICeMlkIAAAAAAAAPWUbUgAAAAAAgI5LUUWKar2LsaRNZWE8KwsBAAAAAACgp6wsBKDzqmrziH9ZaHaClKdLkf8Cc1X6NlS1jG9IpWa/6lzKuw8Gg2OyWF0/ksWqEZen8XUr3LPivW14v9ZKsYyxvvWliqkslqJeh5LABlUVvtvZrq6pu0Y9v4t9/wT9WsueJRPbaO+n4BnTL8xi35i6JYsdnH8gj9UHs1hKw2I+m6aOb1SeujROTfN5rJ7LDy4cO0rjsW/DY9dO3k+2cczUBaXrthpX7PgtT8lijxz+xzzvlP/Jsi60sVGfDaqq8CfP0nO1uI6i0HYafmak3Z547GlZ7P5HvpLFhqX+PA43zmf03ygerzTGyPv4Uc/fUh1M6ejHLU37/VF5A91mshAAAAAAAKDj6rT4aos2lYXxbEMKAAAAAAAAPWWyEAAAAAAAAHrKNqQAAAAAAAAdl6KKtIzfn1xtbSoL41lZCAAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAHVenxVdbtKksjGdlIQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdJxtSDlaVhYCAAAAAABAT1lZCMCGlWJlv75UOl81YRYrXcYuS2m+FFyNjJolW8a9qaI62tI01sa6UmwThWvRxrKzQVV5/Sv1052pk6nOQ10pe9st5/kyybOoUCdX5dnGirk7vprFZg9+K4ultFCI5WOZVGjHERH1hMdn6Vahb+hCf1McP45gjPJ9VPl6giqt/DU7tLA/iw2Hj+R5l8bXy+g/i+VMw0LKUszzd6M6MH9/FlsYPtTs4FH1r/SsL9WhYv1beVWhLRt7AE2YLAQAAAAAAOi4FFWkNfhCc1NtKgvj2YYUAAAAAAAAespkIQAAAAAAAPSUbUgBAAAAAAA6LqWIukU/U+knM7vDykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAAAAAOi4+rFXW7SpLIxnZSEAAAAAAAD0lMlCAAAAAAAA6CnbkAIAAAAAAHRcSlWkVK13MZa0qSyMZ2UhAAAAAAAA9JSVhQB0X1ooh0fEVzTrSKueR1+kdDiPrcL17co5u2At2hj0WV/7lrWwrGtbTRVO0LD/S+5h19w7+9dZLKVhFqui8C35Zdzv4fCRwuGeq8tXr3cBVt8kfdBysqnyPxGmmMvTFer+cvrUubn7C3nn7zHVed7LyacqtFvPVfYf+LtCtLCWZhn1pyqEU5qs/jZVXq9VWhukPQDfn8lCAAAAAACAjqujXV+laVNZGM82pAAAAAAAANBTJgsBAAAAAACgp2xDCgAAAAAA0HF1Wny1RZvKwnhWFgIAAAAAAEBPmSwEAAAAAACAnrINKQAAAAAAQMelx15t0aayMJ6VhQAAAAAAANBTJgsBAAAAAACgp2xDCgAAAAAA0HF1iqhTtd7FWFLbh7QzrCwEAAAAAACAnrKyEABoh+TrZl1TRf5txeTny2mZLtfJUhsL7a5TNty9qQp1coM9v1OaLwXzUMPzldtxREoLjdJuuDq0wqqYymJ1FO5hp9XrXYAjTFonUwyz2KCayWJ1HG50vlFtDIpSXv9KdXrSerV2fXfeP6TUrj4D6A6ThQAAAAAAAB2XovmXmtZCm8rCeLYhBQAAAAAAgJ4yWQgAAAAAAAA9ZRtSAAAAAACAjqvT4qst2lQWxrOyEAAAAAAAAHrKZCEAAAAAAAD0lG1IAQAAAAAAOq5+7NUWbSoL41lZCAAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAHZfS4qst2lQWxrOyEAAAAAAAAHrKykIAOi+FryltBO5j97hntE/pu5D1mpdixVT5x7WU5vNkUeXptM8VdPR1yL1hlKpq+N1tX8dnjepAVU3nWa9Cf1XFVJ5PPbfi+ehrKSnVi9KzetJzAnSRyUIAAAAAAICOS1FFPeEk+EpKLSoL49mGFAAAAAAAAHrKZCEAAAAAAACdc/jw4TjjjDOiqqr44he/eMS/felLX4oXvehFsWXLljj11FPj3e9+9/c931133RXnnXdeHHPMMbFjx45405veFAsLC0ek+fM///P4kR/5kdi8eXM84xnPiOuuuy47z2/91m/F0572tNiyZUucddZZcfPNNx/x74cOHYrLLrssnvCEJ8Rxxx0XF1xwQdx7772rUpYmTBYCAAAAAAB0XErte03i7LPP/r6TX29+85tj165dWXx2djbOPffceOpTnxq33HJLvOc974l3vOMdce21144813A4jPPOOy/m5ubis5/9bFx//fVx3XXXxVVXXbWU5s4774zzzjsvXvKSl8QXv/jFeMMb3hA/+7M/G5/4xCeW0nzoQx+KK664It7+9rfH3/zN38Rzn/vc2LNnT9x3331Lad74xjfGn/7pn8aHP/zh+Iu/+Iu455574mUve9mKl6WpKqXmt2t2dja2b98eEVMR9poFoCWqqvwTvCktFOMAbEyl50GXnwWDwdYsVtcHs1hV+GyWYsJP5Sypqvw7tinVzY7dYPdmkmvRFaX3OPFfucoZNUq20a7vShtU01msTvPrUJLVs1b9yKZNJ2SxhYWHVjyf0j0raXofS9cnott9LWtrVB16vDbWqXY9l1NEDGP//v2xbdu2dSpDv3137ubfP/OXY8vUlvUuzpJDw0Nx5R3vOuq6cfbZZ8dFF10UF110UfHfP/7xj8cVV1wRf/RHfxQ/9EM/FF/4whfijDPOiIiID3zgA/HWt7419u3bFzMzMxERceWVV8ZHPvKRuP3220ee76UvfWncc889cfLJJ0dExDXXXBNvectb4v7774+ZmZl4y1veEh/96EfjK1/5ytJxr3zlK+Ohhx6KG2+8MSIizjrrrHj+858fv/mbvxkREXVdx6mnnho///M/H1deeWXs378/nvSkJ8UHP/jB+Mmf/MmIiLj99tvjWc96Vuzduzde8IIXrFhZmrKyEAAAAAAAgFUxOzt7xOvw4cMTn/Pee++N173udfFf/st/iWOOOSb7971798aLX/zipYnCiIg9e/bEHXfcEQ8++GDxnHv37o3nPOc5S5Nz3z1mdnY2brvttqU055xzzhHH7dmzJ/bu3RsREXNzc3HLLbcckWYwGMQ555yzlOaWW26J+fn5I9Kcdtpp8ZSnPGUpzUqUZTlMFgIAAAAAAHRc3cJXRMSpp54a27dvX3q9613vmuh9ppTioosuiksvvTSe97znFdPs27fviIm2iFj673379h31MaPSzM7OxsGDB+Pb3/52DIfDYprvPcfMzEyccMIJY9NMWpblKO/bBgAAAAAAABP65je/ecQ2pJs3by6mu/rqq+Pqq69e+u+DBw/G5z73ubj88suXYl/96lfjIx/5SDz88MPxy7/8y6tX6J4xWQgAAAAAAMCq2LZtW6PfLLz00kvj5S9/+dJ/X3jhhXHBBRfEy172sqXYrl274tOf/nTs3bs3m3R83vOeFxdeeGFcf/31sXPnzrj33nuP+Pfv/vfOnTuL+e/cuTNuvvnmsceMOu+2bdti69atMTU1FVNTU8U033uOubm5eOihh45YXfj4NJOWZTlsQwoAAAAAANBxdWrfazlOOumkeMYznrH02rp1a+zYseOI2KZNm+J973tf3HrrrfHFL34xvvjFL8bHPvaxiIj40Ic+FL/2a78WERG7d++Oz3zmMzE/P790/ptuuime+cxnxoknnljMf/fu3fHlL3857rvvviOO2bZtW5x++ulLaT71qU8dcdxNN90Uu3fvjoiImZmZOPPMM49IU9d1fOpTn1pKc+aZZ8b09PQRae6444646667ltKsRFmWw2QhAAAAAAAAnfCUpzwlnv3sZy+9fvAHfzAiIn7gB34gnvzkJ0dExKte9aqYmZmJiy++OG677bb40Ic+FO9973vjiiuuWDrPH//xH8dpp5229N/nnntunH766fHqV786br311vjEJz4Rb3vb2+Kyyy5bWsV46aWXxte//vV485vfHLfffnu8//3vjz/4gz+IN77xjUvnueKKK+J3fud34vrrr4+vfe1r8frXvz4effTReO1rXxsREdu3b4+LL744rrjiivizP/uzuOWWW+K1r31t7N69O17wghesaFmasg0pABtAXYxWVeE7MSn/SlOKZX7NiVVRvF+l7zWlYeNzlu5tFVUp88LBzetF43wmOF8bld5jV8oOXZDS4WbptLtlG9VHF6/lMp4HeUaTPV/ap/SsLo/Dumpq6vtvjxURkdJ8IVa6FpNdn3IVyvMuGlXX1rFerkV/taz23QHVYCaLpbrZ82E5GterCU1NHZ/FhvXBLDaoCn+yTAt5KMqfDZqOxauYapSulE+5za/854D1HHNvtPH+1NSxjdKleq4UHZG6WT9fVdP5GZt+tl3GZ+Cm9a/pfSx/Ti+cL6WIEe0R1sv27dvjk5/8ZFx22WVx5plnxhOf+MS46qqr4pJLLllKs3///rjjjjuW/ntqaipuuOGGeP3rXx+7d++OY489Nl7zmtfEO9/5zqU0T3/60+OjH/1ovPGNb4z3vve98eQnPzl+93d/N/bs2bOU5hWveEXcf//9cdVVV8W+ffvijDPOiBtvvDFOPvnkpTS/8Ru/EYPBIC644II4fPhw7NmzJ97//veveFmaqlJqPiKcnZ2N7du3R8RUxAQPPgBYSU0HrxFhsrDFTBaOP18bbbQ/HtB9VeEPi6nwh8WuKPWLo/4wyfIsZzJhkr5uo93DjdbGSjZtOqFRurWaLGya94iE5fgGmiwcFP/4Xq6TXR2jDAabs1i9CpOFpUmU4fDRFc9netNJeT6FycKiZUwWNmWycLyNNt6fZLJw9Ptex8nCCfrz1ZksnI/9+/c3+l06Vt53527+9x/85dgytWW9i7Pk0PBQ/H//9l3qRgfYhhQAAAAAAAB6ymQhAAAAAAAA9JTfLAQAAAAAAOi4Oi2+2qJNZWE8KwsBAAAAAACgp0wWAgAAAAAAQE/ZhhQAAAAAAKDjUlp8tUWbysJ4VhYCAAAAAABAT5ksBAAAAAAAgJ6yDSkAAAAAAEDH1Y+92qJNZWE8KwsBAAAAAACgp6wsBKD7RvxacjWYyZPGfJ6uAz+2nKIDhZzQYLC1UbpUz5XjhWtUFdJVxWgxYaM8Fv9hoXD8VCFhs+/UlerkcupA4/dYsKy6VnqPpWsxgVHvpQ9tgvYq1cvVqJNVNZ0HU7kPzJI1LI829v1Ndi1K38/t7very3V/Y9kyfVIWm57Kxyjzw4OF2IEsVlXl72hXhbpRSjssjHuG9aEsVteHC7k0fyan4oC4VFcn+8551bT+jxjfZ+crjB/T8OHlFKn1Uso/v6xOPmvTN22aOiaLDQqf20pKdX/U9Sm9n9Jzdar0mbFw7LDO23xEqd1FlNpJ07FD0zYy8jNsdfSfA4oatsWuOHbLkxulOzT3YBarR4zBym1nmEWK47ri+fI6vZzPwFE167sb17Uofa6NiOyZldasvwJWh8lCAAAAAACAjqvT4qst2lQWxrMNKQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdFyKdv2mdJvKwnhWFgIAAAAAAEBPmSwEAAAAAACAnrINKQAAAAAAQMfVafHVFm0qC+NZWQgAAAAAAAA9ZbIQAAAAAAAAeso2pAAAAAAAAB2XoooU1XoXY0mbysJ4JgsB6L5qqhhOadjo8BRHv4F6tQqDnknKs9GktJDHRl6futk5i9Gmmy2U8yjXg0La1Ozelt7jqLo2SX2ZvK41u+aT0B5WV6leueYNlJ47hf5qUlODY7PYQj234vn00XLqeVXlH5tLz6deqArPyx50GYfm92exYaEt1imPVcvY0KkqXN+6NBZK8/nBy6iT5frfcNxSrcKzf4LxUUqHV7o0rVNF6bNO4VpM2BhL9Wo1xgkLwwOFc+b1qq5L97ZUT8t1smk9XxgW2lPpfKV2N1KeT/GqNaz7y7LC59xo48LDhf48FerQsD5USDeqDjSrl6kq9dOlZ0Sp/pT/tlFV0/nRdZ5PVfooWezjl9HmH/f3lrQa9RlYU7YhBQAAAAAAgJ6yshAAAAAAAKDjUkTULVro2aKi8H1YWQgAAAAAAAA9ZbIQAAAAAAAAeso2pAAAAAAAAB1Xp3ZtQ9qmsjCelYUAAAAAAADQUyYLAQAAAAAAoKdsQwoAAAAAANBx6bFXW7SpLIxnZSEAAAAAAAD0lMlCAAAAAAAA6CnbkAIAAAAAAHRcnRZfbdGmsjCeyUIANoC6GE2pHF9Jye7rK6YeHshia3d9J6srg2o6P2Oan+ick1ir67YWbQzaqIoqi61Gq6vTQiGflc2pr8+xqip/FE6Fa15VU43SlU84XFa52i/fnKjcHrpbrw4cvjuLpdJ9XKN7O8m1LN2bSc8ZqV33NtVzeazD9a+o0F+lVRhnNu7XJrQwnG2UbjA4Joul+mAeG3W/C2209Fzln5T6jI3Wx8/N3dso3aq8x1U4ZVXo5ot9f6HvLr7HYh/f9DNfd+sFsMg2pAAAAAAAANBTVhYCAAAAAAB0XHrsf23RprIwnpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQcXVafLVFm8rCeFYWAgAAAAAAQE+ZLAQAAAAAAICesg0pAAAAAABAx6XHXm3RprIwnpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQcXVafLVFm8rCeCYLAei+ZOTBOqsKQ6o0v8J5VOX4Otb/qipsUlEoT/IrBe1VTeWxtLD25Vgx9ZrkUg1m8uBwhdt8RGyZOSmLHTj0SJ6wYT+gLf6TqlT3IyIV6/8EG/KU+u4Oj1tK/X69wepVSsMsNhhsztPVc83OF/n5xmTePG0Dxb4qIlJ9eEXzWVcb7jmWS2lt7ldVGM+W+8TJTG/Kn22l53epPMXSjBhzF1vTBqsbK674eaM03u/wdSy8x5SajR+rGPF5rKE1G4dN8B6BfrMNKQAAAAAAAPSUlYUAAAAAAAAdl1K7NrJoU1kYz8pCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADouPqxV1u0qSyMZ2UhAAAAAAAA9JTJQgAAAAAAAOgp25ACAAAAAAB0XJ0WX23RprIwnpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQdSkitWnrzzaVhbFMFgKwYVVRZbFklMIqqKp+btZQVdNZrE6H16EkHK2qmsqDaVhM24n+c40+FQ+qzVmsjgNZbNJrNj3YmgdL77HKn3ft+gtB19VHfWSpn0wd7idTOvpr0RWDwTFZLNUH84RV/ueU0nig0DofO+dcHqsK7TYtjDhDE+XxySRj5NKxJWv1zCg9x9JE16x9pjedlMXm5r+94vmU6v5wOLvi+ZQMC22seB9LfdCIcXixrpbSFp6XnRjzrIbiGGPti7HWBqVndZTGw+W6Vqqrxc+HqzI2O/rPof5eAjxeP/+yBQAAAAAAAFhZCAAAAAAA0HV1TLIvxsprU1kYz8pCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADouJQWX23RprIwnpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQcfVjr7ZoU1kYz8pCAAAAAAAA6CmThQAAAAAAANBTtiEFAAAAAADouJRSpJTWuxhL2lQWxjNZCNBQFVUWS+GB1wZTm7YX4yk13Rl9OMGxI9IVjp+svhTyWcaAqwt1deuWU7PY/MIjWayqRg1f8ms0rA9msdK9TWk+P10q1IuR13Eqi5TLWaovzTZ6KPVBi/9QOL5Q9rVSFcvTrP6tVT1t2p+Puubr2Z4meRaVji3V0xRza1KeVVEV3mOhOKtSxkLey+mnSw7M3d8sn2I/svL9wMh+aA2s9D0bDLYW43V9OM+78Ixo2tcVj21h39Jc/hxrXT8wof9p2wVZ7DvxrSx2bJyYxQ7HgSy2fyE/NiLikcP7stjC8OEsluqGz6yqNBYpjzGqqePzcxbHQguFvJv1LaW+97HM89AEfUupLae6+XOsG/L7uJxr1rQ9Tg1mslg9nKzfL+X9lON3Z7ED9YNZbKbK7+0gprPYw8O8LUVELBQ+BxyY+04Wm1/Ynx+c8mdB8ZlefCZHVFVezsabuxXaXTHZyPs6wefGYj+Sx0Y7+ryXMxYvGnEvHu8HT3xZFnu4vi+Lbao2Z7GDw7yeRkSkwvs+OP9AFpubn81iC8M8VvwsN+L9lfvuCa9llnWzurs4IbR+n0OBydmGFAAAAAAAAHrKykIAAAAAAICOq9Piqy3aVBbGs7IQAAAAAAAAespkIQAAAAAAAPSUbUgBAAAAAAA6Lj32aos2lYXxrCwEAAAAAACAnjJZCAAAAAAAAD1lG1IAAAAAAICOq9Piqy3aVBbGs7IQAAAAAAAAespkIQAAAAAAAPSUbUgBAAAAAAA6zjakHC2ThUArVFE1SpdisidM03zWU6mMk77vpvk0tRrlmcTMpm3F+Nbpk7JYimEWq2Iqiw3rw1lsoRAb1nPFvMvxOi9PymN1WiidMT92RN6l+1MV8o60jvexyuvfv9j6kiy2P/ZlsWGUrk/EMM1nsYML38lic8NH89j8bH6+4cN5JsV7s1iqxxsMjmmULgr1r6SqyhtClOpQqg82OmfTtjyqv6iqzQ3zye9N8XzLqZKFOtRcfi2LbWRU1qXrsVbtqfC+l3XdHmdYaA/LeT607XlQ6s9jkH/kKbWR5bzvcj9daqPN61XJ/MIDWazc7gr9QCFVlQrPkhH3sHg9iu2u1J4mG281fo4VD25WJ1PhmRFR7mtL17yUrvRcLl7fqvxeSm25fC3WZqzYWKlerOcYY0KvOeXJWez+w6dmsVIt3z+Xv+87Hzm9mM8/bPrHLLZv+LUs9vDhe7JYXed9UKlOzmw6vpj39NSWLDY/PJTF5hbysdDC8EDhjIW+pTA+iYiYGmzNYqPGOE3OWVV5H18PZkYcn7f74nNjAqvRFod1fm+KfcOI69i0byk+x6rS9Znsc8Ubdj0ni935SN6ipgqNbGaQB+8/VK5rdz2aX7c7pm/PYvcd+moWO3A4b58p5ecbFOpzRMSmqbztTRXqZemelT5HFj8zjvgsWKf8M2u5PZbuYx4rvcdR7TuV8p7kc0Cx/o04vpg2v75v/GenZbF/eDTvpxcKdfqhw+V6/p3DeZ9859S9Weyb07dmsf0HvpHnvfBgFhvVV00V6lrpc2xVqH91cTyc51O+thH59U0jx1dAN9iGFAAAAAAAAHrKykIAAAAAAICOS9GuHWDaUxK+HysLAQAAAAAAoKdMFgIAAAAAAEBP2YYUAAAAAACg4+q0+GqLNpWF8awsBAAAAAAAgJ4yWQgAAAAAAAA9ZRtSAAAAAACAjktp8dUWbSoL41lZCAAAAAAAAD1lshAAAAAAAAB6yjakQK+kyNe+V1EddbrVUMp7rfJZjffY9Jyr8b4PLTyU55PqLFZV+XdnhvVco2NTWijmXTq+JKX5RumikM/oa5aXc632fWhcrwrl+U76hyy2kA5nsQMLDxTzHhS+A3V44eEsVro3dSGf5dTJYj1IzepAFOpfMY+6cF9HpW1c9mbnHHW2QaHsdd2wTjc06r1UTd9iVeqDGl7LVWg3k/Z1pffduN0VrkUVU4UTDo+maO1QqJOlPr7p9YmIYj0o992F50vDMcYog8HW/PjS86l4zuZ9RmOlNlEVno3F76SuUXkaquu83x9lqnAfhvXBvDiRt51SG6sL44nFtGsz1mS8W76T359HF/J7e2hYiBXGA/cN7ivm80D6ZhabHz6axeqGY9JSvTo0Vx6LLEwdUzg+L/uwPlTIu9R2mrf50pirabdYet/HbX1KFnvkwIONj286DitbhX6tlEt9IIuVnm2TjltmNh2XxeYXvt3o2OU8224tDOXvOpD3qU3Njxi33D2Vt7H989/KYnMLj+QHj/iMlyUbkW5hmN+zUluuqvzPsqVzltrn6M+Rpc+CDetqsTylz8DlvJt/tl3ZzyqjTlkVjv/L+wqfQw/n9W++cOyhEZ/vZgezWewf69uz2KOH8+dBsU8sGNXGBoOZLLYwLKRt+CwpDYdH364j73ey12RrpEhRr9HfFptYq79zMjkrCwEAAAAAAKCnTBYCAAAAAABAT9mGFAAAAAAAoONSWrNfommkTWVhPCsLAQAAAAAAoKdMFgIAAAAAAEBP2YYUAAAAAACg4+rHXm3RprIwnpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQcSmlSCmtdzGWtKksjGdlIQAAAAAAAPSUyUIAAAAAAADoKduQAq2QYv2WpK9n3m2zVtdipfOZW5gtxofDQnyFtz9Qf76/ptfoWw/9eRYbDDbn50vzI85Q+g5UXShQs/Is595WKc8npYVm+TQsT1WVv+OVCnmvlbo+mMVK5amiytNN2HYaH7/Btjxp+r6L6QrXoiqk22j9Wj08kMWaXp+Icv2tqunC4YcblWfS9pBi2CzdhH3DZG1s/fqlktI1HwyOKaathw9nsWGhryv1f2WldpeXZzHlyj+fVlypXm2wfvb37/+PWWzT1LFZrFQvBlU+bqlH9A3lOlR41qe8zZfqwKhxQsnCwoONztlUKe/RfVCzvrKpqSr/s9aoMVix7TW8vutpauq4LFbXjzQ+vun72TJ9QhZ79FCzOrmccerv/uO/b1Se0vsufw6YKh7f+BoV+rBiGyvUn7oeVZ/zeF2qf1WpTq7fs6AqjDGK45sRZVzxMi3r+VL4PFZI9fv3/4dCNnm9Ko31is/AKL/vUj806vnf5Hwxql9r2Pc3HmMU32P5fefvp119Z5/VafHVFm0qC+NZWQgAAAAAAAA9ZbIQAAAAAAAAeso2pAAAAAAAAB1XR4q6RdvCtqksjGdlIQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdFyKiNSinT9bVBS+DysLAQAAAAAAoKdMFgIAAAAAAEBP2YYUAAAAAACg4+pIUbdo8882lYXxrCwEAAAAAACAnjJZCAAAAAAAAD1lG1KAhpJl80dlLa5bXR8s553qVc+blVNV+XeY6vpw8+MLda1t7XY1ylNFtSb5lKQ0zGLrWR4o1clS/SvV05HnLBw/NZjJYnWd92EpFibKO2KqUKBm7anUp/b1uThpH5RS/izS121cU4OtWWx+4aE8Yam/qebyWOTpFv+hVF+a9WFNz1dV5T/51DHf7JwdcHjh4YmOb3p913e8VRgPN3wWRDR/HkwX6n5Enq74vpdRni0zO7PY/PCRvDxTx2WxuYXZwhnLbawqPENLZS89q0smfpZMeN3WT7PxTURHno0Nx0KpzvvzqEaM4Ur97xpdi02DLVlsrmHepb6hWCeX8b5ph5SiVS1PVekOKwsBAAAAAACgp0wWAgAAAAAAQE/ZhhQAAAAAAKDj6khRt2gj0jaVhfGsLAQAAAAAAICeMlkIAAAAAAAAPWUbUgAAAAAAgI6rU8u2IU3tKQvjWVkIAAAAAAAAPWWyEAAAAAAAAHrKNqQAAAAAAAAdlx77X1u0qSyMZ2UhAAAAAAAA9JTJQgAAAAAAAOgp25ACsKqqqLLYim9BkOqVPR/rJP8OU1WoK6Pqz3pubVHKe+XreRu37sjbni1G2qvUHw+mjsliw+GjjY8v3e/G6aq8zadV6M9L+SynPZXeTzmf6UI2C43zKZkabMlidf1Iw6NL3wvNr++o97eR2nLpPQ6Hs43TDgbHZbHifSjVq6pwfVvZnzeTYliIdff9NJYavu9ltPmm/edE56vKf/KpGpaz+b1tNoZb3jmbqUvvpdTuovyMafrM6nQ9L/Q5pfd93GBH4eBmz5JB4Rm4mHV+f+aHef9Z14fzWOEZmNJ8o/JEjLpnG+dz43L6i0nqb2l8U+oTV8Nq/C2hLtShxmPXEVk3HeeWjl+NvqUazOT5FNpYl8cjjJeiXb2dmtYdVhYCAAAAAABAT5ksBAAAAAAAgJ6yDSkAAAAAAEDH1ZGibtHmn20qC+NZWQgAAAAAAAA9ZbIQAAAAAAAAeso2pAAAAAAAAB2XUorUoq0/U2pPWRjPykIAAAAAAADoKZOFAAAAAAAA0FO2IQUAAAAAAOi4OlLULdqGtE1lYTwrCwEAAAAAAKCnTBYCAAAAAABAT9mGFKChKqpG6ZLl9UdYi+uRYrjqebD6Sm2sVHtGtcW1qGuj+4F6GWmPNvOp5nmvWTeUf++sqgrfRUt5G216v9p4v0t5l+vv0Zdx0vpTyrtcnrxeTVx3q/z4taqTVbGd5LGU5vLYiPtVuh5VlX+MGgw2F/KZL5wxb7ORynlPbzomPzpty2LD4SPF4x9vOfd2knFP43wKdWXxpKtfYWamn1iMD+uDpWgWqUr1qtQfV9OFdKV6EWvyvvn+6rSQxUptvjhKKTzvRmnaTpo+X4rnK7yXURo/lwvP+VLfW7qOI885wXPnmJknZLHDc/eNyOfoxx4T9XUjjm+qqvLnS+mr/3V9uHx8w/dzXDohi22ayp85C8PZRudbzDzPe2ZTfs6Dh7+Vxebmy/exsQn61JUe140650TnK/ZLEanYhzVbK1J6tpUTLuNzSfGchbFQ6XNF8ZqN6mebfQapBjN5ssJ4bTlj13L/uzbP9MEgH2cMCn1GisLYtzgOy69jqU5FFOqVYUxr2IaUo2VlIQAAAAAAAPSUyUIAAAAAAADoKduQAgAAAAAAdFx6bCPStmhTWRjPykIAAAAAAADoKZOFAAAAAAAAdMI3vvGNuPjii+PpT396bN26NX7gB34g3v72t8fc3NwR6b70pS/Fi170otiyZUuceuqp8e53v/v7nvuuu+6K8847L4455pjYsWNHvOlNb4qFhYUj0vz5n/95/MiP/Ehs3rw5nvGMZ8R1112Xnee3fuu34mlPe1ps2bIlzjrrrLj55puP+PdDhw7FZZddFk94whPiuOOOiwsuuCDuvffeVSlLEyYLAQAAAAAAOq5e2oi0Pa9JnH322cXJr9tvvz3quo7f/u3fjttuuy1+4zd+I6655pr4lV/5laU0s7Ozce6558ZTn/rUuOWWW+I973lPvOMd74hrr712ZH7D4TDOO++8mJubi89+9rNx/fXXx3XXXRdXXXXVUpo777wzzjvvvHjJS14SX/ziF+MNb3hD/OzP/mx84hOfWErzoQ99KK644op4+9vfHn/zN38Tz33uc2PPnj1x3333LaV54xvfGH/6p38aH/7wh+Mv/uIv4p577omXvexlK16WpqqUUuO7NTs7G9u3b4+IqYiolp0ZQJdVDfu9NOFDkOWrqvJ3X1KyL3qXDKrpLJbSQiFl2Vq0vZH9QFWINx9iNcx8asQ/FOr5Suc9ysgyPU4a5qGG92vUNV/P+13Ku5R2kjI2feaM0jTvqaltWawePjxRPsU+uVQnC+1m0n57MNjcKF2q5/LYiGtWuhczMydnsWF9KI8NHymcMX+Po973sVuflsUOzz/UMJ+CQlucVNP2UFTqOyPWpA+bnn5CMT6sDzY6vlSH6jSfxUp1MhXSLcbbP24pte8ulHs5Sv1iKtSLYp+xCm2spGm7q6pN5eML46vGz+VCHagKY7i6PtzofBGTPfNOPP7ZWezBR75WTjzB/ZmorxtxfFPFOpny6zvqmjcdo/zwia/NYl95+L9msYXhbDGfsrx/2Lr5yVns4OFvLeOcDTV8lqzFuG7UOSc63zLa98jn7eOTRWFsX8hn1HOs+LmkuE6lWbryfRjVjkvjzzxtNZjJk5Xezxp9npq0Xm079plZ7ODh+7PYsDC+L1/L0nO+/Jn88c+DxSmG+di/f39s25b3W6y+787d7N72/45NVbPPRWthIR2OvbPvP+q6cfbZZ8dFF10UF1100fdN+573vCc+8IEPxNe//vWIiPjABz4Qb33rW2Pfvn0xM7PY/q+88sr4yEc+ErfffnvxHB//+MfjpS99adxzzz1x8smLn/uuueaaeMtb3hL3339/zMzMxFve8pb46Ec/Gl/5yleWjnvlK18ZDz30UNx4440REXHWWWfF85///PjN3/zNiIio6zpOPfXU+Pmf//m48sorY//+/fGkJz0pPvjBD8ZP/uRPRsTiBOiznvWs2Lt3b7zgBS9YsbI0ZWUhAAAAAAAAq2J2dvaI1+HDzb9Y1NT+/fvjpJNOWvrvvXv3xotf/OKlicKIiD179sQdd9wRDz74YPEce/fujec85zlLk3PfPWZ2djZuu+22pTTnnHPOEcft2bMn9u7dGxERc3NzccsttxyRZjAYxDnnnLOU5pZbbon5+fkj0px22mnxlKc8ZSnNSpRlOUwWAgAAAAAAdNx6bzk6ahvSU089NbZv3770ete73rWi7/vv//7v4z/9p/8UP/dzP7cU27dv3xETbRGx9N/79u0rnqfJMaPSzM7OxsGDB+Pb3/52DIfDYprvPcfMzEyccMIJY9NMWpblKK9ZBwAAAAAAgAl985vfPGIb0s2by1ulXn311XH11Vcv/ffBgwfjc5/7XFx++eVLsa9+9avxlKc8Zem/77777vjxH//x+Kmf+ql43etetwql7weThQAAAAAAAKyKbdu2NfrNwksvvTRe/vKXL/33hRdeGBdccEG87GUvW4rt2rVr6f/fc8898ZKXvCR+9Ed/NK699tojzrVz58649957j4h997937txZzH/nzp1x8803jz1m1Hm3bdsWW7dujampqZiamiqm+d5zzM3NxUMPPXTE6sLHp5m0LMthshDovYl+aLzKfwC8KvyI9kazGj/uPsk5Uyr9QHr+g9tjTrCi5VkNE9XTFipe3yofllSFWPEH6COiikI9KP0wfbUa17JQ19bslq103vl1rCLv6yIiqkE+8Cy1u+HwkcI5J7tf1SRNdMI6UMy7cM7Vabelfq1wzxpen3r4cBYb1f+t9PsZ1Xc3VSrPoFAnS31GHfnvY4x6f6XrMTWYyWKlul8PHy2cL09Xjbjmw3ouiw2qPO+YOq5RuvmFB/K8C2OZiIjUcDxTbMsNf+1i5DWfqIFPZnrT9ix26PA9WWxQTWexUh0oX8fy9SnVg1L9a9oWV2csU6i/heJM2r7XU6l9D6NwH4vvsTTGXc5ng6ZtpxQr9IlTxxaPLz6XS3W16fOycC0aj8MjYpI+45ipJ2SxB9JC4+NLn+cmea6OMsnnn/K1zFdjVFV5jFxst4X7fVydP0vqwrWsCv3fqPF5yXGbT8lih+e/k5+z8AwsfV4Y+dmgcf0t1JfSuK7h+O+xQhXSFv52MNHfIkY8S0rjhKa/QlW4FqXrOxgcM+IEK/u3kNKzpBr1XgppU+H+lMeKeXtKKR8rjh4bFfIuln3lPy8cs+mkLHZoLv8dtunpvK+cX9ifl6c0lqmbljFFiuZ9Aaunfux/bbHcspx00klH/O7g1q1bY8eOHfGMZzwjS3v33XfHS17ykjjzzDPj937v92IwOLIO7969O9761rfG/Px8TE8vPr9uuummeOYznxknnnhiMf/du3fHr/3ar8V9990XO3bsWDpm27Ztcfrppy+l+djHPnbEcTfddFPs3r07IiJmZmbizDPPjE996lNx/vnnL16Huo5PfepTSyskzzzzzJieno5PfepTccEFF0RExB133BF33XXX0nlWoizL4TcLAQAAAAAA6IS77747zj777HjKU54S/+E//Ie4//77Y9++fUf8FuGrXvWqmJmZiYsvvjhuu+22+NCHPhTvfe9744orrlhK88d//Mdx2mmnLf33ueeeG6effnq8+tWvjltvvTU+8YlPxNve9ra47LLLlrZOvfTSS+PrX/96vPnNb47bb7893v/+98cf/MEfxBvf+Mal81xxxRXxO7/zO3H99dfH1772tXj9618fjz76aLz2ta+NiIjt27fHxRdfHFdccUX82Z/9Wdxyyy3x2te+Nnbv3h0veMELVrQsTVlZCAAAAAAAQCfcdNNN8fd///fx93//9/HkJz/5iH9Lj63w3r59e3zyk5+Myy67LM4888x44hOfGFdddVVccsklS2n3798fd9xxx9J/T01NxQ033BCvf/3rY/fu3XHsscfGa17zmnjnO9+5lObpT396fPSjH403vvGN8d73vjee/OQnx+/+7u/Gnj17ltK84hWviPvvvz+uuuqq2LdvX5xxxhlx4403xsknn7yU5jd+4zdiMBjEBRdcEIcPH449e/bE+9///hUvS1NVSqW18WWzs7Oxffv2iJiKNdxbC2BVrfQ2pGEb0u9rpbchHZmPbUhbq3R9S1vCFI8duc1Ry7Yh7ay12YZ04vvVfAjb/JxNrVm9Kmm2Dekk12c525AWt0gs9b2r0M+WyjNV2EKy1GcMC9uDLmcb0mO2PCWLlbZqm5u7v9H5Ro0dNhe2aqvrPJ86NduudDW2IS3Wv0m3IV2DZ/D0phOK8UFhC8qm25CWt5tcxvOhcM3btg1paXvwptuvdcXM9BOz2LA+mMWK77G0hd8qbENaMuk2pMV+qOGzrTROWJ3tV/Py7Nr+P2exbz30542Pb7oN6UTjjhGattFNhf6qVP/qujTeiihe38L9fuH2y7PYZx+5vpB3/lxdzvj8Sduen8W+88hX8nNOug1p076y4TakE49T12gb0rIJtiEtfm5bv21Iy+OOKG9DWijP1FT+e2mlfNZqG9JJnbz9BVnsgQP/T553ob4034a00BYLUkqR4lDs37+/0e/SsfK+O3fzvO2XxKbilsTrYyHNxV/vv1bd6ICN9JctAAAAAAAAYBlMFgIAAAAAAEBP+c1CAAAAAACAjkuRom7RT+u07Wd+GM3KQgAAAAAAAOgpk4UAAAAAAADQU7YhBQAAAAAA6Lg66qiiXu9iLKlbVBbGs7IQAAAAAAAAespkIQAAAAAAAPSUbUiB3kuRGqWrqvX7fkXTMk6qimpNzrlW76co5Xmva3kaalsdGFWeSe53SvMNyzNiC4vCvZ0o3TJUg6k8m3qukDBPV3w/E9bTle6vUgzL8fpAFpuaOq7hSdvVD7TynCWlJtGwvkzaxzeugxOUZ9K+LqW8PdXDvJ5Oalho3wuN88nLOLpPLbXl/PhSupQW8nSlPqhwzUblU1Sq+1WzY5d1t4v5NKzThWPnFx4oJq2q6Sw2GGwunLLcLzY6tvR8iIhUvD/5fSweu1bjhEIZS+2uy+rCNS+1p3IdaPZMj4gR9ffor2Upl7o+OCJxXvZiP920249m9XTxpA3fd+lZUqh/M1U+7hgMthazTvWhQrBwHxv2LWvV7jZPn5DFDh7+xzzhyLrW7LkzFfn1LY0p62HhOo68Zvnx+w/+Q16eQhuri58NijW9mPNEd2dVPleU7kNThfHAiGdJVZX+1NuwbykcOyjUgTSqb5nA5O2pWT9SDx/N0xXed+M+fkQ+Kz3OHTWOP25qRxb7dvpaFquHhXtWeH6n0phyVLkfd4268HeVvkhRR2rR1p9tKgvjWVkIAAAAAAAAPWWyEAAAAAAAAHrKNqQAAAAAAAAdV1d1VA1/FmAt1LYh7QwrCwEAAAAAAKCnTBYCAAAAAABAT9mGFAAAAAAAoOPqqKNq0daftiHtDisLAQAAAAAAoKdMFgIAAAAAAEBP2YYUAAAAAACg42xDytGyshAAAAAAAAB6yspCgDWSIq13Eb6/qspjaeXLXUWez2pcn5R8e2m5Jr0Pkx2f369UqH9tbEtV0+9fpWEeavh+qqqcR7Ger9F1m5l+YhZbGD5cKE/+vktKZaxGFLuN9WAtlL4hOtG1qKbyWFo4+vPFiPu4Cv1+MZ9SOyk820r1ajnlKbW7mU3bstjCMP+4tTCczWKD0n2IiOO3/LMsdmDu/ix2cO7eLFbXh/N8Bsfk6dIjxbwbP/8L13fS52/j+jLBGGXz9MnF+MLwQBbbOpP3dQcOfbNQnFKdnM7TVSOuT32oHG9grcZWVbU5Dxbud+rwN8hL9Tel+VLCPNSw/xt1fDHZBPdxMCj/ySdV+XO5WuExysh+YIJ2Wyrjljgui22aOr54/HzhPqbCM6849mj4OWnU/Z7kPh4q9PulOjkyj4bX/JhCf3Xc5lOy2Ozw0eZ5F/qCUj9bUryWDceUo6zr+HGiz9X5dRxV1+pSf9VQVbg+xWKPuA9tG5+XrlHx+kxwzUbmXRX63wnG2KOu7Qn1jiy2ZfqkLHbg8N3NzlnP5bFS/1eKt+v2A0fBZCEAAAAAAEDHpahb9cWtNpWF8WxDCgAAAAAAAD1lshAAAAAAAAB6yjakAAAAAAAAHVfHMKqY7DdeV1LdorIwnpWFAAAAAAAA0FMmCwEAAAAAAKCnbEMKAAAAAADQcSlSpKjXuxhLUqT1LgINWVkIAAAAAAAAPWWyEAAAAAAAAHrKNqQAAAAAAAAdV1d1VFV7tiGtW7QlKuNZWQgAAAAAAAA9ZWUhQEMp5d+Eqar8Oxd+uHftVVEV4+5Fx6T8fnXlHqY03yzdGr2fNcsnLTRLVyjPqHbb5NheK7STxocW78PafMtzkjow6viSQZV/vBkWvx85zMtTeKYvZp7nPRjk+UwNZrLYwvBAIZ/pQh7ltvTD1Yuy2J8tXFdIOZVFNk1ty7Mp3O+qcOxi2rxMk97H9VIq47A+VExb6s+P33xKFnv00F2FjPJ86uGjebJCXYmIiXq7pm1k0jFTqZ3Uhfa04TTseyduD4U6NEm/X+obFq1035/Xi2pEnZrkuV46dnt9UiHliPeXltH3Z8c2LHfpHo44vlRfSu9x09TxWWyuPlw4X/NrW8rngXg4ix1a2F84ttTmV34twmqMHZpec75X8/5ikuu7GvdmPetAua6ufN7z1VwWOzT/QJ5PYXxTGpOWxoqjPb7da0vQdSYLAQAAAAAAOq6OYVQt2lCyF18s2yDaU2sAAAAAAACANWWyEAAAAAAAAHrKNqQAAAAAAACdVy/z9ydXW5vKwjhWFgIAAAAAAEBPmSwEAAAAAACAnrINKQAAAAAAQMfVaRhtWiO2WB66oD21BgAAAAAAAFhTJgsBAAAAAACgp2xDCgAAAAAA0HEp6khRr3cxlrSpLIxnZSEAAAAAAAD0lJWFAA1VUeXBDfcjvfl3SFIsTHbKKr9uKa3wt4qqqXI8TVh21lbpPnblHpb6gkLdr1Lh0CgEi3k0TLeGhvWjWSzVc2uSd6lPbnwte6r4HCt+d3CyPrrpvVmz+9X0Wb2MNjYcHspiC8MDhXSPZLHl1N1TtmzJ0z6S35+pwUwWqxv2nylGXJ9SH1Yqe+GZ3vQ9lutkOe+m96dp3sPhbKPzRURMV8cUytOsXg02HZvF6vpgMW3TNtGFvm7kvW1oPd9jXeftds2s8LM+jahrpXwmuuaF9jDqfCv9/H7WMSdlsZsfKY9Fqir/E1i5Dyw9G/N0VbU237/fOn1iFpubvy9PWOo7o/lnrwcH3y7k853SCQt5Nx87TA3yZ9vC8HAWG1TThazzZ9uk/UXpPq7459XVMOJ+l+5P83ZXGGNMbctiw4X95awb3ot1HccXPnNWy+jDmirV1WJxJrwW96c7s1hpjFNVm/N86nw8u5y88yrY/vEJMJ7JQgAAAAAAgI5LMYzUog0lR345kdZpT60BAAAAAAAA1pTJQgAAAAAAAOgp25ACAAAAAAB0XB11TPo79CupblFZGM/KQgAAAAAAAOgpk4UAAAAAAADQU7YhBQAAAAAA6LgUKVKLtv5Mkda7CP//9u4/yKr6vv/465x79+4uLLv8kkXkl9afJIIohqBNvv6gUmud2tiYONQiX5t8ZcAWmbbRmQw4+XYwmU6nmq8/Uu20OvONE9NmTFLzFcYhSBqDQbEY8QcaJBWFBRTYZXdh7957zvcP6ibr+33MWe/u3rt7no+ME33zOefzPp/z+XEu555zkRJPFgIAAAAAAAAAAAAZxc1CAAAAAAAAAAAAIKN4DSkAAAAAAAAAAMAIF8dlxQqqnUafOC5XOwWkxJOFAAAAAAAAAAAAQEbxZCEApBXkTCiOS1VIZHgFgf1eSRxX9kPJgfMNp0p+8Njb3wd/kqaewc4HH08u12RipdJRE0s639U8Z0FYMLE47nUK2nlEaeeRwD/u0Lmcc9vC+TZf2jZLavMx9aeZWHfPu6nq9utx5pbYzzHtWE67rZ9P7fU1rw+lbTe/X9j+V+lxV9q+affpzt3O+hTmxphYVO5OXbc39ry1MXC+hxlV+I3eXx3vNLHYOd+FfHOqfLpP7LXlgrrU+XjfCg688+3NV06f9OZOSYqiHmeXzvdcvfkhZd353Hi37lL5qC2reqcaZ+6t8LowDG09fpunvL5xr139+djtqU7ZvDOevPUuio47dThroKRY3jGmu+5O3S+SOG3knQfveHze97EHct3szC0p11CvD+TzE9yyvaXDtp4BrMF2Y2eeHMhpqOA8bnfmNa+fSlKxfMyp3FlXvbHjnkcv76Qxlm498Mp19uw3sVzOzvuJ/TQuOhXZeg6XfuUUs3NdJGeOHsB6l3Pm/jGFM0ysvfvNVPnImUNO+vjjMfU8W9VrRf/5D388ffyneqJyl91dwvGNhM/V/hzv9OkBtFnqa1+v/7rny/kcmTAnHjn+lonV5SebWKncni6flJ8j/Zxq61wDGDhuFgIAAAAAAAAAAIxwkSIN7MtKQyuqoVzw0XgNKQAAAAAAAAAAAJBR3CwEAAAAAAAAAAAAMorXkAIAAAAAAAAAAIxwscqKK/zt9MHk/T41ahNPFgIAAAAAAAAAAAAZxc1CAAAAAAAAAAAAIKN4DSkAAAAAAAAAAMAIF8eRYkXVTqNPHNdOLvhoPFkIAAAAAAAAAAAAZBQ3CwEAAAAAAAAAAICM4mYhAAAAAAAAAAAAkFH8ZiEAAAAAAAAAAMAIFymSaug3C6MaygUfjZuFAJCaXdwCBSYWKx70moernrQXE5XmEwTO8hOXUm9fCS931IYo6jGxIBjASxDioRgTlUiXe6V9MggLNhgVTSgOnHoqbLN8WO/ssmxiYTjGKdfr5GPngVj+3OC2W5Bz6hn8uSXtHDjY5ZLL2r7mtVvqvua048mdDnJben0yqagScvqQKLbzSC4ca2KxN0Zk+25S3bmwwcSKpQ67rTM+vblOzriRpN3hyyY2fswZJjYpb2NhbPvFbifHstMWkhQ7bRk6Y949npTXTEFg93eyrJeTN6f67WbrsdtGCf3ZO9+xczzuGHX6dBzbbcOw0a3bXQe9azPnOsor57evM/cm8GahnNennePxxpiX98nCtiZv3SiXnTEW1Dm7s3W7157yz6O3brj9wisXOnNV7M913pzjHY/XV9PO5975kqRSyrVEgdP/nPPlztGhfx3kXScE7rrjjDunLSZEE0yskB/n1t1bak9Vj9df0uaddGWV9nrEm6/OG3etib3ZvcnEitHxVHWcrMf2tc6etpTbVvaSsnENp5lY6PS/UsNME+vpPWrLOXPDSSn/ctq7Hnbm82AIPmpU9rnaPz5vjUm9vqT9/JLUB9z5obb+ziT9WLTzQOR9fkmo2+1DCeu/4Vw7xIF/zVMsHTGxQt7Oi6VSymsZT+Jng3TXYQBGDl5DCgAAAAAAAAAAAGQUTxYCAAAAAAAAAACMcHFcVlxDb9Xyns5HbeLJQgAAAAAAAAAAACCjuFkIAAAAAAAAAAAAZBSvIQUAAAAAAAAAABjhYsWKFVU7jT6x4mqngJR4shAAAAAAAAAAAADIKG4WAgAAAAAAAAAAABnFa0gBAAAAAAAAAABGuDiOFCuodhp94rh2XomKj8aThQAAAAAAAAAAAEBGcbMQAAAAAAAAAAAAyCheQwoAAAAAAAAAADDilRVXO4V+ytVOAClxsxAAUvLesR0M0zvA42Fb5p0HzuPBX9QH+3iS9pe2nuE6j/hocdyTtmBF9aQ9317/SdzWfQd/uvfyp++nOX/7uJQqpsDmXmnf7y4eMrFC3WQTK5WPmVgcnbD5BIN/aerv0zk3Xr9y2iyprNuWXps71QxkTvTLfvzfgJg94WoTa+v+hVv2RHGfE023blR8bgNbTxwV023qbCsvnwHMLWFot8+FDU5Je26iyM51YW6MW08ptuMkDOpM7HjcbmLHeu35KkfHTSxw9ndSfUL8Q/mEtlxU7k61bezkczIpf74z27vztLOtey3jX98EYaOJ9cbe8XjjLt2Le/y+IpVL9jx680guHGuzKXfZmJN30rwfhAUnatsyiuz6Uk45FuWtTQPgjmW/YPqdevNVaMdjHCf0VVPOm//8MRYGtq95/dI9bm8dcua1srPWSn4/jyOnnzv1+OuQt7j5Y8y9RvHKpjyP10wbZ2I/+6UzlhIEgZ3DyuUOp5xtXy8WOm0r+WM07Zo+NrZjvrfUabd01hfJ70N+X/XKeZ+B7dwQJ/1FcMq19XD3bhMrldOex4FcB3nziJd7unJJ13Cpr7G9fp6yzZJ+A8ztB2k/0zvpLGr+Xyb2867/m1B3urlSzroReGvjANYN91x4n5Ocut1tnfEwoM9O3vzpfd5N+1tuCf2isdBqYt0979rNU3+GcI474bos/vD2tXV3CsDHwGtIAQAAAAAAAAAAgIziyUIAAAAAAAAAAIAR7uSTx7XzBq2kJ6FRe3iyEAAAAAAAAAAAAMgobhYCAAAAAAAAAAAAGcVrSAEAAAAAAAAAAEY4XkOKj4snCwEAAAAAAAAAAICM4mYhAAAAAAAAAAAAkFG8hhQAAAAAAAAAAGCEixQpqKXXkIrXkI4UPFkIAAAAAAAAAAAAZBQ3CwEAAAAAAAAAAICM4jWkAJCS9wh/rLgKmQyvio8x9rYvf/zdOfkkvVwh7TkbrvOY9jUQWehXPu87TPZ1FQNpH6/Nc/kWW0t03G4bp39VRj4/wcSmNc03scPFX5nYieL7zh7TtYUk9ZaOmlgQ2Eu8IGx0trZj0WuLOKEtfqfpChM7Eu01sULYZGKTNN3E2uI3bOzoz9y6vTZvKEwysZ7eIyZWKrWbWC4/zsSCwP9eXW/psC2rnInFTvsGYYPdYXTCxgJ/vgjDMbaeuNcpZ3OPyt0mdnp0jont1w63bq9fBoE9bgV1Tjm7bRwVbQ25sW7N3jHGQbq1pOy1b1xKta3kn8fekm3LXFhIVbc3L9U585IkLZtox9jpY+0c+MYxZ59O9932fqeJbel8yK27ddxFJhY6faAse27a2reaWENhmt1f6H8cPX7iXRPzzkMY1ttyTl/x5sQk9XXjTayjd7/dpzPm5fTzWc2fNbH93TvcugOnD3m555x5pFzusDt0rsFib8xKiqMep247loslW08+Z+elXuc8JK1jQervMDvzSJzymjJhPpdzHsc2nGpiXSfesZt6h+OcL69PStL4sWea2PGiXbN6inauDHJeX7Hnq77OrpWS1FI4zcQOdb9uYqXyMRPLOdcTZWc+jyI730hJ49ZZL53jiWX76Rvttp+XynadP1mPfy4+LHSOMY5t3f46Zo9P8sd37KzL3vr/bvCmiXntm3TdkvbzWFO97fsniof8fX64bm9OlL9W/47s+vKZ6VeZWKdzup7psm3RKe9a2n/t3dGet02sp9f2lzHONWXZuXZw5wb55yJy5llvInHXLG+MOH1KksbU2/FdLNn+4q3Bvc418mWTJ5rY893+uhqE/nXch5WdzxbetVCx96BTzuYjJVyfe5+JvL8jSDk3JHLWVn+u8z7betctdv5L+gjcWGfb43jxgF/Y7NP5vOG1WcLcYufurP49Ru052ddq6DWkA/i7FVQXTxYCAAAAAAAAAAAAGcXNQgAAAAAAAAAAACCjeA0pAAAAAAAAAADACJf6Ne3DpNbyQTKeLAQAAAAAAAAAAAAyipuFAAAAAAAAAAAAQEbxGlIAAAAAAAAAAIARLlYsKap2Gn1O5oORgCcLAQAAAAAAAAAAgIziZiEAAAAAAAAAAACQUbyGFAAAAAAAAAAAYISL49p5BalUe/kgGU8WAgAAAAAAAAAAABnFzUIAAAAAAAAAAAAgo3gNKQCkFCtOVS5QMOj7rNRAckqz7VDk7e3Tq7ua7VtJOyappF8NV/8ZLrlcU6pycdzrxsOg3sTyuTG2XGgvf3pLhVR1l6MTft3OPqfEs00sKtjXbxwsHTOxQn6ciSW9usOLx7KxMLDHGMVFZ39ddtuw0a17cdM5Jja5wcZeP1o2sdnjbJu92T7VxH5Yt8ute/LYOSZWH9g+1FPoNLG2jp+bWBDY79BFccmtW7Ede/m6Fmef9hhDJ1YsHfHrcdTXjTexUtn2S69PFp3jeSnabMsVD6XOR07/C5y6/X5q2zEq2/53cp+2DwZBnYl580A58vdptg3ttsll7TH+zpj/YWKdes/EOkr7TOy0/AVuPV8+Z7+Jzfo/n7IF/99zJhTMnGhi3/vf9hi37pzg1j02nGRiU8vTTWxP8LKJzRh/pYmdFp3l1uN5p8GO+3fbf2ZiOadfTBhr6+nsse3Y2vhJt+4TcbuJ9ZQ7TGxMwwx3+w+7MDzfxA41nOGW/a8x9rhD2X5+WnS6ib039oCJ9ajbxMbKP98nAjtXnojtcXeX3jex5vw0Ezva+18mVp9rdusuxT02Vj5uYpGztpUju205smtbQ97O0ZJUdOacOXWXm1hH4aiJdcvO3Y2y9bTEdixK0qw6G3+x7jUT2xf+p4n1luz5GlvfamIT6mxfkaQG2fXyaO5tE/PWxsY624c6ju81sTD0r+u867jAObf53FgTK5Vtuae6f2pzrD/VrbvYa/u0d4ylkp0H8rnxJhY5fdfbnyTlAns83jrmtU9X6aDdnzOeImc8nMzTjifvGqVYsu3jngenfZRw3IHz146XTLDryw0zj5rY0aKzLu+1c/w7XbPcuvOh/fz0coNtt0PB6yZWTroG/BDvHEr+9Vra1/CVynbuLkf2HMoZN5I0zun/PXl7bnuczyCRs67+4PButx6Pl6fXh7z+4n/OsuUS29G5Pg/CnFPMfi7x/97B2Taw20pSENiyzY2zTazO+bzbVbTrd+Acdxj6fW1q7jwTaw9/ZWLuvOasjd7nn8jtf0l/R4FaUGuv/ay1fJCMJwsBAAAAAAAAAACAjOJmIQAAAAAAAAAAAJBRvIYUAAAAAAAAAABghPN+lqSaai0fJOPJQgAAAAAAAAAAACCjuFkIAAAAAAAAAAAAZBSvIQUAAAAAAAAAABjh4ri2XvtZa/kgGU8WAgAAAAAAAAAAABnFzUIAAAAAAAAAAAAgo3gNKQAAAAAAAAAAwAhXa6/9rLV8kIwnCwEAAAAAAAAAAICM4mYhAAAAAAAAAAAAkFG8hhRATQgUVDuFfmLFJpY6xyChXFzBPiuVlJOR7tUAA8k7bVu6+6ww70FvXy8f57wmlvWKJWyeatsaGzeVyufGmFgY2EuVpFdYhKEtW58fZ2Lt3W+lyicM6p26e9yyxV4bfyn+Qap6ir0HTaxcPmHrTuzn9rtfXhtFKjrlek0sDBudmG0LSXqto8vEmrsLJvaL+DUTe/XIeCdHm3cubHDr7il3mNgJHbHbO+exvu4UW3dcMrEgoa/l8i22rNNXgyDd9/JyTpsnKZbscUfRcVt35FzmO8dz7MQ+Wy4hb2/GieOyU43Nx+fU47Sj5Ldl4Jxb7zx4fdrNJrB9N0ne6ZdnaLqJdUZTTKwjN9PEGiO/n39793gTW/I/d5pY23Hbp4+Vcia2qc22Y0vDDLfuo6W9Jtab67YFnXXsjOgT7j7tpv4YOy0+y8RONLWbWEPOjsWGoNnWU7D99Hhk5wtJasrZc5YPvPNj5+4wqDOxQs6OnNl1dm2SpLrjtt16Zeems8faYyzHti1OlG37jsn747ur15Y9VLRrUU9o142e2K4vuYJti7HxeLfuY3rfxMK87b+l2OZTdtrHK1cfNLl1e+tOS2zLTpZt8574NLttzs4jp47x57WXO46ZWENo6/auZcqRbfNi2a7JUZ09X5K0p/unbvzDekudJpYL7TF610dJc6936ex9XvB48/57x98wsQZnnZakOO9dZ9h9etce3nF75yGf84+7HNk2imLbN6LI9unOE/tNzFuzgjBh/XbXUDtGu3oOmFg57Zqe9Io55+Lh2aOHTOw/j9h2KzvXru+Hti16A//6POdcC7VH9rqnLjfWxE702HKlsl0DGwoT/bqdfuX1Ae863rsm9XjXPJL0ftcuE/M+G5TLdg6Knbp/2b3ZxErOfHNye3uMJbsEu59BymVvvrLtU3I+AyRK++rDwK45A+FdDzfkx5vY2HCyieXqnc8QsvkUAn9ueS+2n23dvuF+VnHmIKdfJAk+PM/HseLIrsGohlp77Wet5YMkPFkIAAAAAAAAAAAAZBQ3CwEAAAAAAAAAAICM4jWkAAAAAAAAAAAAI1zST7dUS63lg2Q8WQgAAAAAAAAAAABkFDcLAQAAAAAAAAAAgIziNaQAAAAAAAAAAAAjXKzaeu1nreWDZDxZCAAAAAAAAAAAAGQUNwsBAAAAAAAAAACAjOI1pAAAAAAAAAAAACNcHMdSDb3682Q+GAl4shAAAAAAAAAAAADIKG4WAgAAAAAAAAAAABkVxAN4DrSjo0MtLS2ScpKCocsKAGpQ4Mx7sewU6pVLKjtcKs09zbYDqbvSfY5Uac9DVoVhY6pyQZD+u05BUGdi5XKnLRiXU+/TryiXMh9bLo5709WRdMmWsm7/NSSVfW+svjDFxIq9R0wsjk6k2l8QFirKR7FzjEG6t+57fUXy+0Xs1VPJa17c/fmitP3F4c1BXpsn90mnvzhjJ+285o9lv0+mXUu840k7DyTW4eQZBPUm1tw4w8RCp27vHB53xo0kNeRbTKyj+5epcvTPV8mE8vkJbt2enNdfnL7fWGf3WYqKdtuEuTcMbbv1lrqccnZ8R5E9xrJTd6nc7tadz41z8rTHGDltGTrzzaSx55hYMXLWIfn9pVQ+bmLjCtNMLEg5n3vnS5LKTr/sjbptPc6a4/fpw3bbhBy9tqyknHe+BnLt4J3HxrqJqcrlnHPYGPpj7OCJV03M66u9Jdtf/HnaHncuHOvWXY5sv/K2j518Aue4Y3e9rOwaI+28781hUWzzlvx289YIv33TXcP51xOSd02R+nrCvb4ZQPum3N47t1HU4+xvANfNgXPt4ayhcWzrcdvSG98JnyHSXmPnc/44sftzxkjCnOqWTX0Nl/a60O8DXlv6fc3yrxUbnP35xxI783Qln4EHsq07Z1TQ/zxJ7ejVXSi0pto+7fqUVK5YPGRi3rzYW3LWZe861VkfknPsHz95i6FH7e3tam5uTtgGQ+mDezdh2KzA6f/VEsexoqiDvjEC8GQhAAAAAAAAAAAAkFHcLAQAAAAAAAAAAAAyKt17mQAAAAAAAAAAAFCzTr7ytrZeQ4qRgScLAQAAAAAAAAAAgIziZiEAAAAAAAAAAACQUbyGFAAAAAAAAAAAYMSrrdeQSryGdKTgyUIAAAAAAAAAAAAgo7hZCAAAAAAAAAAAAGQUryEFAAAAAAAAAAAY6eIaew1pzGtIRwqeLAQAAAAAAAAAAAAyipuFAAAAAAAAAAAAQEYFcZz+OdCOjg61tLRIyqmmHmUFgCoJnLkw1sh9vH60HQ9QTVkYT2FQZ2JxXPrY+/Pax2vHpLKe0XYeRtvxDAe3DwVOO8ZRhfvMOfv8+ONBknK5ZhOLom4Tqy9MMbGe4kETC5wxGwT+90ejsq2nkr6WNJY9FdXjHM+Azq3bHt4+051bd55U2S3r5enm43yETz0nJpzvtPl4x+OJ4t7U9aRVyfw3kLUkDBtNLIqO230G6X7VJamvpB0TQzLunPlKse2XI2GtLdTZ+a9UOuKWHex+OVzzmscbi0nHlzbPMDfGxOKomKqegY2x+lT5xE497jxZxfMw2gzX9U01eXO3dzyV9qvhmOOT1BemmlhPsc3EBn/ujiWV1d7eruZmew2Loffrezf1CpzPO9Vy8vZTD31jBODJQgAAAAAAAAAAACCjuFkIAAAAAAAAAAAAZFS692YAAAAAAAAAAACghkWqrZ+Q4xXQIwVPFgIAAAAAAAAAAAAZxc1CAAAAAAAAAAAAIKN4DSkAAAAAAAAAAMCIF9fYmz9rKhl8BJ4sBAAAAAAAAAAAADKKm4UAAAAAAAAAAAAYMQ4fPqylS5equblZ48eP1y233KLOzs6P3ObEiRNauXKlJk2apKamJl1//fU6cOBAvzJvv/22rrnmGo0ZM0ZTpkzRX//1X6tUKvUr88wzz+jCCy9UfX29zjzzTD3yyCOmrvvvv1+zZ89WQ0ODFi5cqG3btg1JLoOFm4UAAAAAAAAAAAAjXlxT/6v0NaSXXXaZeyNOkpYuXapXXnlFTz/9tJ588kn95Cc/0Ze//OWP3N/tt9+uf//3f9e//uu/asuWLdq3b58+97nP9f15uVzWNddco2KxqJ/97Gd69NFH9cgjj2jt2rV9Zfbs2aNrrrlGl19+uXbs2KHVq1frz//8z7Vx48a+Mo8//rjWrFmjdevW6cUXX9S8efO0ZMkSHTx4cFBzGUxBHMepz1ZHR4daWlok5SQFQ5IQAIwkgTMXxiP4Xdyj7XiAasrCeAqDOhOL44//DTevfbx2TCrrGW3nYbQdz3Bw+1DgtGMcVbjPnLPPyr7xmcs1m1gUdZtYfWGKifUUD5pY4IzZIPC/PxqVbT2V9LWkseypqB7neAZ0bt328PaZ7ty686TKblkvTzcf5yN86jkx4Xynzcc7Hk8U96auJ61K5r+BrCVh2GhiUXTc7jPIp6o7qa+kHRNDMu6c+Uqx7ZcjYa0t1Nn5r1Q64pYd7H45XPOaxxuLSceXNs8wN8bE4qiYqp6BjbH6VPnETj3uPFnF8zDaDNf1TTV5c7d3PJX2q+GY45PUF6aaWE+xzcQGf+6OJZXV3t6u5mZ7DYuhV7v3birrG5dddpluvvlm3Xzzzf3ir732mubMmaPnn39eCxYskCRt2LBBf/AHf6B33nlH06ZNM/tqb2/XKaecoscee0x/8id/Ikl6/fXXdd5552nr1q369Kc/raeeekp/+Id/qH379qm1tVWS9K1vfUtf+cpXdOjQIRUKBX3lK1/Rj370I+3cubNv31/84hd19OhRbdiwQZK0cOFCXXzxxbrvvvskSVEUacaMGbrtttt0xx13DFougynd1e1/+/V9RRZXAJCSZsORO0eOtuMBqikL48n7zlnlHzB/W+S3/8lvLzVyz8NoO57h4LZO+uAA9ulFKzs37hhzY/YvT/3vhKbP0R/LH/94BrZlBfVUeB4qbbc0+0ueJ9Od78HO5yNKV7D94M9Llcx/A1lL0rZ5pW1R4YxT2ZaD3a8GVvugSj//SYOd03DNa+7eBjDXpe6pKdecSq/X0o6dyutOlw9+bbiub6ppuPrVcMzxiXt0vySVNsfKP8sN7FoDQ6f2zkNHR0e//66vr1d9fbovkHi2bt2q8ePH990olKTFixcrDEP9/Oc/1x//8R+bbbZv367e3l4tXry4L3buuedq5syZfTfotm7dqvPPP7/v5pwkLVmyRCtWrNArr7yi+fPna+vWrf328UGZ1atXS5KKxaK2b9+uO++8s+/PwzDU4sWLtXXr1kHNZTAN6GbhsWPH/vvf0n8zEwAAAKNT0tMxQDYN/rfso8h/OubDeorvpCoXxz1ObEApjQCVzkuDO69VPk8O9jxb2f6yMO/H8Uf/zs2vjeS2GLlPBX1Yb8k+LZMFQzEWo6jjtxcaBHFsn1xHLRs988VJI3nuTqfYu6+q9R87duy/n27DcCsUCpo6dara2mpvbWxqatKMGTP6xdatW6e77rrrY++zra1NU6b0f8NAPp/XxIkTE9ugra1NhUJB48eP7xdvbW3t26atra3fzbkP/vyDP/uoMh0dHTp+/LiOHDmicrnslnn99dcHNZfBNKCbhdOmTdPevXsVx7FmzpypvXv38lgxMIw6Ojo0Y8YMxh4wjBh3QHUw9oDhx7gDqoOxBww/xh0wuOI41rFjx9xXP2J4NDQ0aM+ePSoW7Sukqy2OYwUf+imIpKcK169fr/Xr1/f99/Hjx/Xcc89p1apVfbFXX311aBLNuAHdLAzDUNOnT+97ZLS5uZkFFagCxh4w/Bh3QHUw9oDhx7gDqoOxBww/xh0weHiisPoaGhrU0NBQ7TQqcuutt+qGG27o+++lS5fq+uuv1+c+97m+2LRp0zR16lQdPNj/d9pLpZIOHz6sqVPtb3dK0tSpU1UsFnX06NF+T/QdOHCgb5upU6dq27Zt/bY7cOBA35998P8fxH6zTHNzsxobG5XL5ZTL5dwyv7mPwchlMKX/dXMAAAAAAAAAAABgCEycOFFnnnlm3z+NjY2aMmVKv1g+n9eiRYt09OhRbd++vW/bH//4x4qiSAsXLnT3fdFFF6murk6bNm3qi+3atUtvv/22Fi1aJElatGiRXn755X43Ip9++mk1Nzdrzpw5fWV+cx8flPlgH4VCQRdddFG/MlEUadOmTX1lBiuXwcTNQgAAAAAAAAAAAIwI5513nn7/939fX/rSl7Rt2zY9++yzWrVqlb74xS/2vQ733Xff1bnnntv3dF5LS4tuueUWrVmzRps3b9b27du1fPlyLVq0SJ/+9KclSVdddZXmzJmjm266SS+99JI2btyor371q1q5cmXfq1NvvfVWvfXWW/qbv/kbvf7663rggQf03e9+V7fffntffmvWrNHDDz+sRx99VK+99ppWrFihrq4uLV++fFBzGUwDeg3pB+rr67Vu3bohSQhAMsYeMPwYd0B1MPaA4ce4A6qDsQcMP8YdAIx83/72t7Vq1SpdeeWVCsNQ119/vb75zW/2/Xlvb6927dql7u7uvtg//MM/9JXt6enRkiVL9MADD/T9eS6X05NPPqkVK1Zo0aJFGjt2rJYtW6avfe1rfWVOP/10/ehHP9Ltt9+ue++9V9OnT9c//dM/acmSJX1lvvCFL+jQoUNau3at2tradMEFF2jDhg1qbW0d1FwGUxDHcTwkewYAAAAAAAAAAABQ03gNKQAAAAAAAAAAAJBR3CwEAAAAAAAAAAAAMoqbhQAAAAAAAAAAAEBGcbMQAAAAAAAAAAAAyKiPdbPw/vvv1+zZs9XQ0KCFCxdq27Ztg50XgN/wk5/8RNdee62mTZumIAj0/e9/v9opAaPe3XffrYsvvljjxo3TlClTdN1112nXrl3VTgsY9R588EHNnTtXzc3Nam5u1qJFi/TUU09VOy0gU77+9a8rCAKtXr262qkAo9pdd92lIAj6/XPuuedWOy1g1Hv33Xf1p3/6p5o0aZIaGxt1/vnn64UXXqh2WgAAVNWAbxY+/vjjWrNmjdatW6cXX3xR8+bN05IlS3Tw4MGhyA+ApK6uLs2bN0/3339/tVMBMmPLli1auXKlnnvuOT399NPq7e3VVVddpa6urmqnBoxq06dP19e//nVt375dL7zwgq644gr90R/9kV555ZVqpwZkwvPPP69//Md/1Ny5c6udCpAJn/jEJ7R///6+f376059WOyVgVDty5IguvfRS1dXV6amnntKrr76qv//7v9eECROqnRoAAFUVxHEcD2SDhQsX6uKLL9Z9990nSYqiSDNmzNBtt92mO+64Y0iSBPBrQRDoiSee0HXXXVftVIBMOXTokKZMmaItW7bos5/9bLXTATJl4sSJ+ru/+zvdcsst1U4FGNU6Ozt14YUX6oEHHtDf/u3f6oILLtA999xT7bSAUeuuu+7S97//fe3YsaPaqQCZcccdd+jZZ5/Vf/zHf1Q7FQAAasqAniwsFovavn27Fi9e/OsdhKEWL16srVu3DnpyAADUivb2dkknb1oAGB7lclnf+c531NXVpUWLFlU7HWDUW7lypa655pp+n/cADK0333xT06ZN0xlnnKGlS5fq7bffrnZKwKj2wx/+UAsWLNDnP/95TZkyRfPnz9fDDz9c7bQAAKi6Ad0sfO+991Qul9Xa2tov3traqra2tkFNDACAWhFFkVavXq1LL71Un/zkJ6udDjDqvfzyy2pqalJ9fb1uvfVWPfHEE5ozZ0610wJGte985zt68cUXdffdd1c7FSAzFi5cqEceeUQbNmzQgw8+qD179ugzn/mMjh07Vu3UgFHrrbfe0oMPPqizzjpLGzdu1IoVK/QXf/EXevTRR6udGgAAVZWvdgIAANS6lStXaufOnfyGDDBMzjnnHO3YsUPt7e36t3/7Ny1btkxbtmzhhiEwRPbu3au//Mu/1NNPP62GhoZqpwNkxtVXX93373PnztXChQs1a9Ysffe73+XV28AQiaJICxYs0Pr16yVJ8+fP186dO/Wtb31Ly5Ytq3J2AABUz4CeLJw8ebJyuZwOHDjQL37gwAFNnTp1UBMDAKAWrFq1Sk8++aQ2b96s6dOnVzsdIBMKhYLOPPNMXXTRRbr77rs1b9483XvvvdVOCxi1tm/froMHD+rCCy9UPp9XPp/Xli1b9M1vflP5fF7lcrnaKQKZMH78eJ199tn65S9/We1UgFHr1FNPNV9AO++883gFMAAg8wZ0s7BQKOiiiy7Spk2b+mJRFGnTpk38jgwAYFSJ41irVq3SE088oR//+Mc6/fTTq50SkFlRFKmnp6faaQCj1pVXXqmXX35ZO3bs6PtnwYIFWrp0qXbs2KFcLlftFIFM6Ozs1O7du3XqqadWOxVg1Lr00ku1a9eufrE33nhDs2bNqlJGAADUhgG/hnTNmjVatmyZFixYoE996lO655571NXVpeXLlw9FfgB08kPjb367dM+ePdqxY4cmTpyomTNnVjEzYPRauXKlHnvsMf3gBz/QuHHj+n6bt6WlRY2NjVXODhi97rzzTl199dWaOXOmjh07pscee0zPPPOMNm7cWO3UgFFr3Lhx5jd5x44dq0mTJvFbvcAQ+qu/+itde+21mjVrlvbt26d169Ypl8vpxhtvrHZqwKh1++2365JLLtH69et1ww03aNu2bXrooYf00EMPVTs1AACqasA3C7/whS/o0KFDWrt2rdra2nTBBRdow4YNam1tHYr8AEh64YUXdPnll/f995o1ayRJy5Yt0yOPPFKlrIDR7cEHH5QkXXbZZf3i//Iv/6Kbb755+BMCMuLgwYP6sz/7M+3fv18tLS2aO3euNm7cqN/7vd+rdmoAAAyqd955RzfeeKPef/99nXLKKfrd3/1dPffcczrllFOqnRowal188cV64okndOedd+prX/uaTj/9dN1zzz1aunRptVMDAKCqgjiO42onAQAAAAAAAAAAAGD4Deg3CwEAAAAAAAAAAACMHtwsBAAAAAAAAAAAADKKm4UAAAAAAAAAAABARnGzEAAAAAAAAAAAAMgobhYCAAAAAAAAAAAAGcXNQgAAAAAAAAAAACCjuFkIAAAAAAAAAAAAZBQ3CwEAAAC4br75Zl133XXVTgMAAAAAAAyhfLUTAAAAADD8giD4yD9ft26d7r33XsVxPEwZAQAAAACAauBmIQAAAJBB+/fv7/v3xx9/XGvXrtWuXbv6Yk1NTWpqaqpGagAAAAAAYBjxGlIAAAAgg6ZOndr3T0tLi4Ig6BdramoyryG97LLLdNttt2n16tWaMGGCWltb9fDDD6urq0vLly/XuHHjdOaZZ+qpp57qV9fOnTt19dVXq6mpSa2trbrpppv03nvvDfMRAwAAAAAADzcLAQAAAKT26KOPavLkydq2bZtuu+02rVixQp///Od1ySWX6MUXX9RVV12lm266Sd3d3ZKko0eP6oorrtD8+fP1wgsvaMOGDTpw4IBuuOGGKh8JAAAAAACQuFkIAAAAYADmzZunr371qzrrrLN05513qqGhQZMnT9aXvvQlnXXWWVq7dq3ef/99/eIXv5Ak3XfffZo/f77Wr1+vc889V/Pnz9c///M/a/PmzXrjjTeqfDQAAAAAAIDfLAQAAACQ2ty5c/v+PZfLadKkSTr//PP7Yq2trZKkgwcPSpJeeuklbd682f39w927d+vss88e4owBAAAAAMBH4WYhAAAAgNTq6ur6/XcQBP1iQRBIkqIokiR1dnbq2muv1Te+8Q2zr1NPPXUIMwUAAAAAAGlwsxAAAADAkLnwwgv1ve99T7Nnz1Y+z8cPAAAAAABqDb9ZCAAAAGDIrFy5UocPH9aNN96o559/Xrt379bGjRu1fPlylcvlaqcHAAAAAEDmcbMQAAAAwJCZNm2ann32WZXLZV111VU6//zztXr1ao0fP15hyMcRAAAAAACqLYjjOK52EgAAAAAAAAAAAACGH1/lBQAAAAAAAAAAADKKm4UAAAAAAAAAAABARnGzEAAAAAAAAAAAAMgobhYCAAAAAAAAAAAAGcXNQgAAAAAAAAAAACCjuFkIAAAAAAAAAAAAZBQ3CwEAAAAAAAAAAICM4mYhAAAAAAAAAAAAkFHcLAQAAAAAAAAAAAAyipuFAAAAAAAAAAAAQEZxsxAAAAAAAAAAAADIKG4WAgAAAAAAAAAAABn1/wFPLVxF6WE/YwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot\n",
    "plt.figure(figsize=(25,10))\n",
    "librosa.display.specshow(features.T[:,:300], x_axis=\"time\",sr=sr)\n",
    "plt.colorbar(format=\"%+2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time_step of the audio file\n",
    "time_step = hop_length/22050\n",
    "\n",
    "audio_folder = \"4way-tabla-ismir21-dataset/train/audios\" \n",
    "onset_folder = \"4way-tabla-ismir21-dataset/train/onsets\"\n",
    "\n",
    "# Initialize an empty matrix to store the spectrograms\n",
    "label_array = []\n",
    "\n",
    "for filename in sorted(os.listdir(audio_folder)):\n",
    "\n",
    "    file_name, extension = os.path.splitext(filename)\n",
    "    onsetfile = f\"{file_name}.{'onsets'}\"\n",
    "\n",
    "    # Provide the path to your audio file\n",
    "    audio_file_path = os.path.join(audio_folder, filename)\n",
    "    \n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file_path)\n",
    "\n",
    "    # Calculate the duration of the audio in seconds\n",
    "    audio_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "\n",
    "    # Calculate the number of time steps and initialize the array with zeros\n",
    "    num_time_steps = int(audio_duration / time_step)\n",
    "    num_time_steps += 1\n",
    "    stroke_array = np.zeros(num_time_steps)\n",
    "    \n",
    "    # Read the .ONSETS file to get the times of the strokes\n",
    "    for i in [\"b\", \"d\", \"rb\", \"rt\"]:\n",
    "        file_path = os.path.join(onset_folder, i, onsetfile)\n",
    "        with open(file_path, 'r') as file:\n",
    "            stroke_times = [float(line.strip()) for line in file]\n",
    "\n",
    "        # Set the values to 1 where there is a stroke within the time period\n",
    "        for stroke_time in stroke_times:\n",
    "            time_step_index = int(stroke_time / time_step)\n",
    "            if time_step_index < num_time_steps:\n",
    "                stroke_array[time_step_index] = 1\n",
    "        \n",
    "    \n",
    "    label_array.append(stroke_array)\n",
    "\n",
    "label_array = np.hstack(label_array)\n",
    "\n",
    "label_array = label_array.T   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202194, 65)\n",
      "(202194,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176540 ,  25654\n",
      "12.687814673036787 % Positive Values\n"
     ]
    }
   ],
   "source": [
    "#Ckeck the no. of -ve and +ve values to check class imbalance\n",
    "zero = 0\n",
    "one = 0\n",
    "\n",
    "for i in label_array:\n",
    "    if i==0:\n",
    "        zero+=1\n",
    "    elif i==1:\n",
    "        one+=1\n",
    "\n",
    "print(zero, \", \", one)\n",
    "\n",
    "#Find class imbalance\n",
    "print(one*100/(zero+one), \"% Positive Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25654, 65)\n",
      "(25654,)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "pos_features = features[label_array == 1][:]\n",
    "pos_labels = label_array[label_array == 1]\n",
    "print(pos_features.shape)\n",
    "print(pos_labels.shape)\n",
    "print(pos_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202194, 65)\n",
      "(202194,)\n"
     ]
    }
   ],
   "source": [
    "t = zero//one - 2 \n",
    "r = zero % one\n",
    "pos_features_stack = pos_features\n",
    "\n",
    "for i in range(t):\n",
    "    pos_features_stack = np.vstack((pos_features_stack, pos_features))\n",
    "\n",
    "pos_labels_stack = np.tile(pos_labels, t+1)\n",
    "pos_features_stack = np.vstack((pos_features_stack, pos_features[:r,:]))\n",
    "pos_labels_stack = np.concatenate([pos_labels_stack, pos_labels[:r]])\n",
    "\n",
    "new_features = np.vstack((features, pos_features_stack))\n",
    "new_labels = np.concatenate([label_array, pos_labels_stack])\n",
    "print(features.shape)\n",
    "print(label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353080, 65)\n",
      "(353080,)\n"
     ]
    }
   ],
   "source": [
    "print(new_features.shape)\n",
    "print(new_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176540 ,  176540\n",
      "50.0 % Positive Values\n"
     ]
    }
   ],
   "source": [
    "#Ckeck the no. of -ve and +ve values to check class imbalance\n",
    "zero = 0\n",
    "one = 0\n",
    "\n",
    "for i in new_labels:\n",
    "    if i==0:\n",
    "        zero+=1\n",
    "    elif i==1:\n",
    "        one+=1\n",
    "\n",
    "print(zero, \", \", one)\n",
    "\n",
    "#Find class imbalance\n",
    "print(one*100/(zero+one), \"% Positive Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_features, new_labels, test_size=0.2, random_state=42)\n",
    "# X_train = X_train.reshape(X_train.shape[0], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "# from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(65,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),    \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create an instance of the F1Score metric.\n",
    "f1_score = F1Score(num_classes=2, average='micro')\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy', f1_score])\n",
    "\n",
    "# class_weights = dict(zip(np.unique(label_array), compute_class_weight('balanced', classes=np.unique(label_array), y=label_array)))\n",
    "# class_weights = {int(label): weight_for_class for label, weight_for_class in class_weights.items()}\n",
    "#class_weights = {0: 1, 1: 9}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"./ckpt\" + str(i) + \"/weights-improvement-{epoch:02d}-{accuracy:.2f}-{f1_score:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='f1_score', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=700, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./ckpt1/700.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2207/2207 - 6s - loss: 0.3955 - accuracy: 0.8151 - f1_score: 0.6976 - 6s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3955278992652893, 0.815126895904541, 0.6976120471954346]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(65,)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),    \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),    \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),    \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(25, activation='relu'),    \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),    \n",
    "    tf.keras.layers.BatchNormalization(),    \n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),    \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "new_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy', f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.7754 - f1_score: 0.6764\n",
      "Epoch 1: f1_score improved from -inf to 0.67637, saving model to ./BNckpt2\\wght-imprv-01-0.78-0.68.hdf5\n",
      "8827/8827 [==============================] - 46s 5ms/step - loss: 0.4653 - accuracy: 0.7754 - f1_score: 0.6764\n",
      "Epoch 2/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.7743 - f1_score: 0.6755\n",
      "Epoch 2: f1_score did not improve from 0.67637\n",
      "8827/8827 [==============================] - 45s 5ms/step - loss: 0.4641 - accuracy: 0.7743 - f1_score: 0.6755\n",
      "Epoch 3/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.7729 - f1_score: 0.6760\n",
      "Epoch 3: f1_score did not improve from 0.67637\n",
      "8827/8827 [==============================] - 45s 5ms/step - loss: 0.4661 - accuracy: 0.7729 - f1_score: 0.6761\n",
      "Epoch 4/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.7738 - f1_score: 0.6760\n",
      "Epoch 4: f1_score did not improve from 0.67637\n",
      "8827/8827 [==============================] - 45s 5ms/step - loss: 0.4652 - accuracy: 0.7738 - f1_score: 0.6760\n",
      "Epoch 5/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.7740 - f1_score: 0.6761\n",
      "Epoch 5: f1_score did not improve from 0.67637\n",
      "8827/8827 [==============================] - 45s 5ms/step - loss: 0.4656 - accuracy: 0.7740 - f1_score: 0.6761\n",
      "Epoch 6/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.7725 - f1_score: 0.6759\n",
      "Epoch 6: f1_score did not improve from 0.67637\n",
      "8827/8827 [==============================] - 45s 5ms/step - loss: 0.4666 - accuracy: 0.7725 - f1_score: 0.6759\n",
      "Epoch 7/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.7717 - f1_score: 0.6754\n",
      "Epoch 7: f1_score did not improve from 0.67637\n",
      "8827/8827 [==============================] - 46s 5ms/step - loss: 0.4669 - accuracy: 0.7717 - f1_score: 0.6754\n",
      "Epoch 8/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4673 - accuracy: 0.7731 - f1_score: 0.6752\n",
      "Epoch 8: f1_score did not improve from 0.67637\n",
      "8827/8827 [==============================] - 46s 5ms/step - loss: 0.4673 - accuracy: 0.7731 - f1_score: 0.6752\n",
      "Epoch 9/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.7719 - f1_score: 0.6758\n",
      "Epoch 9: f1_score did not improve from 0.67637\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4659 - accuracy: 0.7719 - f1_score: 0.6758\n",
      "Epoch 10/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4677 - accuracy: 0.7712 - f1_score: 0.6768\n",
      "Epoch 10: f1_score improved from 0.67637 to 0.67682, saving model to ./BNckpt2\\wght-imprv-10-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4678 - accuracy: 0.7712 - f1_score: 0.6768\n",
      "Epoch 11/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.7722 - f1_score: 0.6775\n",
      "Epoch 11: f1_score improved from 0.67682 to 0.67751, saving model to ./BNckpt2\\wght-imprv-11-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4667 - accuracy: 0.7722 - f1_score: 0.6775\n",
      "Epoch 12/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4663 - accuracy: 0.7723 - f1_score: 0.6760\n",
      "Epoch 12: f1_score did not improve from 0.67751\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4664 - accuracy: 0.7723 - f1_score: 0.6759\n",
      "Epoch 13/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4652 - accuracy: 0.7725 - f1_score: 0.6756\n",
      "Epoch 13: f1_score did not improve from 0.67751\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4652 - accuracy: 0.7725 - f1_score: 0.6756\n",
      "Epoch 14/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.7730 - f1_score: 0.6785\n",
      "Epoch 14: f1_score improved from 0.67751 to 0.67851, saving model to ./BNckpt2\\wght-imprv-14-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4657 - accuracy: 0.7730 - f1_score: 0.6785\n",
      "Epoch 15/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.7721 - f1_score: 0.6764\n",
      "Epoch 15: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4658 - accuracy: 0.7721 - f1_score: 0.6764\n",
      "Epoch 16/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.7728 - f1_score: 0.6777\n",
      "Epoch 16: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 45s 5ms/step - loss: 0.4680 - accuracy: 0.7728 - f1_score: 0.6777\n",
      "Epoch 17/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4675 - accuracy: 0.7722 - f1_score: 0.6764\n",
      "Epoch 17: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4675 - accuracy: 0.7722 - f1_score: 0.6764\n",
      "Epoch 18/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7713 - f1_score: 0.6765\n",
      "Epoch 18: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4712 - accuracy: 0.7712 - f1_score: 0.6765\n",
      "Epoch 19/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4671 - accuracy: 0.7724 - f1_score: 0.6768\n",
      "Epoch 19: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4671 - accuracy: 0.7724 - f1_score: 0.6768\n",
      "Epoch 20/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4664 - accuracy: 0.7735 - f1_score: 0.6765\n",
      "Epoch 20: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 51s 6ms/step - loss: 0.4664 - accuracy: 0.7735 - f1_score: 0.6765\n",
      "Epoch 21/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4666 - accuracy: 0.7722 - f1_score: 0.6762\n",
      "Epoch 21: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4666 - accuracy: 0.7721 - f1_score: 0.6762\n",
      "Epoch 22/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4646 - accuracy: 0.7721 - f1_score: 0.6770\n",
      "Epoch 22: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4646 - accuracy: 0.7721 - f1_score: 0.6770\n",
      "Epoch 23/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4635 - accuracy: 0.7765 - f1_score: 0.6767\n",
      "Epoch 23: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4636 - accuracy: 0.7765 - f1_score: 0.6768\n",
      "Epoch 24/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4645 - accuracy: 0.7749 - f1_score: 0.6768\n",
      "Epoch 24: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4645 - accuracy: 0.7749 - f1_score: 0.6768\n",
      "Epoch 25/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.7747 - f1_score: 0.6779\n",
      "Epoch 25: f1_score did not improve from 0.67851\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4656 - accuracy: 0.7747 - f1_score: 0.6779\n",
      "Epoch 26/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.7729 - f1_score: 0.6786\n",
      "Epoch 26: f1_score improved from 0.67851 to 0.67857, saving model to ./BNckpt2\\wght-imprv-26-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4662 - accuracy: 0.7729 - f1_score: 0.6786\n",
      "Epoch 27/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4646 - accuracy: 0.7732 - f1_score: 0.6772\n",
      "Epoch 27: f1_score did not improve from 0.67857\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4646 - accuracy: 0.7731 - f1_score: 0.6772\n",
      "Epoch 28/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4631 - accuracy: 0.7746 - f1_score: 0.6790\n",
      "Epoch 28: f1_score improved from 0.67857 to 0.67901, saving model to ./BNckpt2\\wght-imprv-28-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4631 - accuracy: 0.7747 - f1_score: 0.6790\n",
      "Epoch 29/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4633 - accuracy: 0.7759 - f1_score: 0.6766\n",
      "Epoch 29: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4633 - accuracy: 0.7759 - f1_score: 0.6766\n",
      "Epoch 30/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4686 - accuracy: 0.7733 - f1_score: 0.6756\n",
      "Epoch 30: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4686 - accuracy: 0.7733 - f1_score: 0.6756\n",
      "Epoch 31/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4674 - accuracy: 0.7718 - f1_score: 0.6768\n",
      "Epoch 31: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4674 - accuracy: 0.7719 - f1_score: 0.6768\n",
      "Epoch 32/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.7734 - f1_score: 0.6770\n",
      "Epoch 32: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4660 - accuracy: 0.7734 - f1_score: 0.6770\n",
      "Epoch 33/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4664 - accuracy: 0.7731 - f1_score: 0.6771\n",
      "Epoch 33: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 46s 5ms/step - loss: 0.4664 - accuracy: 0.7731 - f1_score: 0.6771\n",
      "Epoch 34/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4668 - accuracy: 0.7733 - f1_score: 0.6772\n",
      "Epoch 34: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4669 - accuracy: 0.7733 - f1_score: 0.6772\n",
      "Epoch 35/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.7746 - f1_score: 0.6759\n",
      "Epoch 35: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4658 - accuracy: 0.7746 - f1_score: 0.6759\n",
      "Epoch 36/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.7742 - f1_score: 0.6765\n",
      "Epoch 36: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4656 - accuracy: 0.7742 - f1_score: 0.6766\n",
      "Epoch 37/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4642 - accuracy: 0.7747 - f1_score: 0.6771\n",
      "Epoch 37: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4642 - accuracy: 0.7747 - f1_score: 0.6772\n",
      "Epoch 38/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4660 - accuracy: 0.7740 - f1_score: 0.6763\n",
      "Epoch 38: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4660 - accuracy: 0.7740 - f1_score: 0.6763\n",
      "Epoch 39/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.7732 - f1_score: 0.6784\n",
      "Epoch 39: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4665 - accuracy: 0.7732 - f1_score: 0.6784\n",
      "Epoch 40/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.7730 - f1_score: 0.6773\n",
      "Epoch 40: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4665 - accuracy: 0.7730 - f1_score: 0.6773\n",
      "Epoch 41/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4690 - accuracy: 0.7711 - f1_score: 0.6773\n",
      "Epoch 41: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4691 - accuracy: 0.7711 - f1_score: 0.6774\n",
      "Epoch 42/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.7730 - f1_score: 0.6765\n",
      "Epoch 42: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4667 - accuracy: 0.7731 - f1_score: 0.6765\n",
      "Epoch 43/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.7721 - f1_score: 0.6781\n",
      "Epoch 43: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4671 - accuracy: 0.7721 - f1_score: 0.6781\n",
      "Epoch 44/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4683 - accuracy: 0.7726 - f1_score: 0.6784\n",
      "Epoch 44: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4683 - accuracy: 0.7726 - f1_score: 0.6784\n",
      "Epoch 45/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4698 - accuracy: 0.7711 - f1_score: 0.6774\n",
      "Epoch 45: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4698 - accuracy: 0.7711 - f1_score: 0.6774\n",
      "Epoch 46/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4715 - accuracy: 0.7704 - f1_score: 0.6752\n",
      "Epoch 46: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4715 - accuracy: 0.7704 - f1_score: 0.6752\n",
      "Epoch 47/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4719 - accuracy: 0.7697 - f1_score: 0.6766\n",
      "Epoch 47: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4719 - accuracy: 0.7697 - f1_score: 0.6766\n",
      "Epoch 48/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4700 - accuracy: 0.7721 - f1_score: 0.6770\n",
      "Epoch 48: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4700 - accuracy: 0.7721 - f1_score: 0.6770\n",
      "Epoch 49/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4727 - accuracy: 0.7703 - f1_score: 0.6766\n",
      "Epoch 49: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4727 - accuracy: 0.7703 - f1_score: 0.6766\n",
      "Epoch 50/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4728 - accuracy: 0.7686 - f1_score: 0.6770\n",
      "Epoch 50: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4727 - accuracy: 0.7686 - f1_score: 0.6770\n",
      "Epoch 51/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4731 - accuracy: 0.7691 - f1_score: 0.6764\n",
      "Epoch 51: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4731 - accuracy: 0.7691 - f1_score: 0.6764\n",
      "Epoch 52/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4740 - accuracy: 0.7683 - f1_score: 0.6790\n",
      "Epoch 52: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4740 - accuracy: 0.7683 - f1_score: 0.6790\n",
      "Epoch 53/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.7699 - f1_score: 0.6765\n",
      "Epoch 53: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4723 - accuracy: 0.7699 - f1_score: 0.6765\n",
      "Epoch 54/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4697 - accuracy: 0.7726 - f1_score: 0.6765\n",
      "Epoch 54: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4698 - accuracy: 0.7726 - f1_score: 0.6765\n",
      "Epoch 55/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4699 - accuracy: 0.7717 - f1_score: 0.6774\n",
      "Epoch 55: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4700 - accuracy: 0.7716 - f1_score: 0.6774\n",
      "Epoch 56/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.7701 - f1_score: 0.6755\n",
      "Epoch 56: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4701 - accuracy: 0.7701 - f1_score: 0.6756\n",
      "Epoch 57/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4697 - accuracy: 0.7692 - f1_score: 0.6771\n",
      "Epoch 57: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4697 - accuracy: 0.7692 - f1_score: 0.6771\n",
      "Epoch 58/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.7700 - f1_score: 0.6767\n",
      "Epoch 58: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4705 - accuracy: 0.7700 - f1_score: 0.6767\n",
      "Epoch 59/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4690 - accuracy: 0.7717 - f1_score: 0.6778\n",
      "Epoch 59: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4690 - accuracy: 0.7717 - f1_score: 0.6778\n",
      "Epoch 60/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.7711 - f1_score: 0.6769\n",
      "Epoch 60: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4721 - accuracy: 0.7710 - f1_score: 0.6769\n",
      "Epoch 61/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4716 - accuracy: 0.7708 - f1_score: 0.6760\n",
      "Epoch 61: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4715 - accuracy: 0.7709 - f1_score: 0.6761\n",
      "Epoch 62/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4681 - accuracy: 0.7726 - f1_score: 0.6762\n",
      "Epoch 62: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4681 - accuracy: 0.7726 - f1_score: 0.6762\n",
      "Epoch 63/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4683 - accuracy: 0.7719 - f1_score: 0.6782\n",
      "Epoch 63: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4683 - accuracy: 0.7719 - f1_score: 0.6782\n",
      "Epoch 64/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.7723 - f1_score: 0.6786\n",
      "Epoch 64: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4689 - accuracy: 0.7723 - f1_score: 0.6786\n",
      "Epoch 65/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4710 - accuracy: 0.7701 - f1_score: 0.6778\n",
      "Epoch 65: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4710 - accuracy: 0.7701 - f1_score: 0.6778\n",
      "Epoch 66/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.7716 - f1_score: 0.6781\n",
      "Epoch 66: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4707 - accuracy: 0.7716 - f1_score: 0.6781\n",
      "Epoch 67/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4731 - accuracy: 0.7703 - f1_score: 0.6789\n",
      "Epoch 67: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4731 - accuracy: 0.7703 - f1_score: 0.6789\n",
      "Epoch 68/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7697 - f1_score: 0.6786\n",
      "Epoch 68: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4714 - accuracy: 0.7697 - f1_score: 0.6786\n",
      "Epoch 69/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.7732 - f1_score: 0.6779\n",
      "Epoch 69: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 46s 5ms/step - loss: 0.4683 - accuracy: 0.7732 - f1_score: 0.6779\n",
      "Epoch 70/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4678 - accuracy: 0.7730 - f1_score: 0.6780\n",
      "Epoch 70: f1_score did not improve from 0.67901\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4678 - accuracy: 0.7730 - f1_score: 0.6780\n",
      "Epoch 71/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4675 - accuracy: 0.7732 - f1_score: 0.6792\n",
      "Epoch 71: f1_score improved from 0.67901 to 0.67925, saving model to ./BNckpt2\\wght-imprv-71-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4676 - accuracy: 0.7732 - f1_score: 0.6792\n",
      "Epoch 72/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.7733 - f1_score: 0.6798\n",
      "Epoch 72: f1_score improved from 0.67925 to 0.67975, saving model to ./BNckpt2\\wght-imprv-72-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4657 - accuracy: 0.7733 - f1_score: 0.6798\n",
      "Epoch 73/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4707 - accuracy: 0.7718 - f1_score: 0.6783\n",
      "Epoch 73: f1_score did not improve from 0.67975\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4707 - accuracy: 0.7718 - f1_score: 0.6783\n",
      "Epoch 74/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7714 - f1_score: 0.6764\n",
      "Epoch 74: f1_score did not improve from 0.67975\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4703 - accuracy: 0.7714 - f1_score: 0.6764\n",
      "Epoch 75/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.7707 - f1_score: 0.6774\n",
      "Epoch 75: f1_score did not improve from 0.67975\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4698 - accuracy: 0.7707 - f1_score: 0.6774\n",
      "Epoch 76/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4682 - accuracy: 0.7711 - f1_score: 0.6771\n",
      "Epoch 76: f1_score did not improve from 0.67975\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4681 - accuracy: 0.7711 - f1_score: 0.6771\n",
      "Epoch 77/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.7724 - f1_score: 0.6791\n",
      "Epoch 77: f1_score did not improve from 0.67975\n",
      "8827/8827 [==============================] - 46s 5ms/step - loss: 0.4661 - accuracy: 0.7724 - f1_score: 0.6791\n",
      "Epoch 78/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4689 - accuracy: 0.7713 - f1_score: 0.6798\n",
      "Epoch 78: f1_score improved from 0.67975 to 0.67984, saving model to ./BNckpt2\\wght-imprv-78-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4689 - accuracy: 0.7713 - f1_score: 0.6798\n",
      "Epoch 79/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.7717 - f1_score: 0.6777\n",
      "Epoch 79: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4693 - accuracy: 0.7717 - f1_score: 0.6777\n",
      "Epoch 80/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.7711 - f1_score: 0.6771\n",
      "Epoch 80: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4685 - accuracy: 0.7711 - f1_score: 0.6771\n",
      "Epoch 81/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4711 - accuracy: 0.7711 - f1_score: 0.6771\n",
      "Epoch 81: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4710 - accuracy: 0.7711 - f1_score: 0.6771\n",
      "Epoch 82/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4734 - accuracy: 0.7696 - f1_score: 0.6760\n",
      "Epoch 82: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4734 - accuracy: 0.7696 - f1_score: 0.6760\n",
      "Epoch 83/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4723 - accuracy: 0.7700 - f1_score: 0.6764\n",
      "Epoch 83: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4723 - accuracy: 0.7699 - f1_score: 0.6763\n",
      "Epoch 84/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4715 - accuracy: 0.7688 - f1_score: 0.6762\n",
      "Epoch 84: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4715 - accuracy: 0.7688 - f1_score: 0.6762\n",
      "Epoch 85/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4711 - accuracy: 0.7708 - f1_score: 0.6761\n",
      "Epoch 85: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4711 - accuracy: 0.7708 - f1_score: 0.6761\n",
      "Epoch 86/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.7729 - f1_score: 0.6783\n",
      "Epoch 86: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4685 - accuracy: 0.7729 - f1_score: 0.6783\n",
      "Epoch 87/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.7715 - f1_score: 0.6779\n",
      "Epoch 87: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4692 - accuracy: 0.7715 - f1_score: 0.6779\n",
      "Epoch 88/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4734 - accuracy: 0.7698 - f1_score: 0.6778\n",
      "Epoch 88: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4734 - accuracy: 0.7698 - f1_score: 0.6778\n",
      "Epoch 89/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.7699 - f1_score: 0.6767\n",
      "Epoch 89: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 48s 5ms/step - loss: 0.4726 - accuracy: 0.7699 - f1_score: 0.6767\n",
      "Epoch 90/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7715 - f1_score: 0.6765\n",
      "Epoch 90: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 47s 5ms/step - loss: 0.4712 - accuracy: 0.7715 - f1_score: 0.6765\n",
      "Epoch 91/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4700 - accuracy: 0.7721 - f1_score: 0.6786\n",
      "Epoch 91: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4701 - accuracy: 0.7720 - f1_score: 0.6786\n",
      "Epoch 92/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4713 - accuracy: 0.7712 - f1_score: 0.6781\n",
      "Epoch 92: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4713 - accuracy: 0.7712 - f1_score: 0.6781\n",
      "Epoch 93/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4732 - accuracy: 0.7683 - f1_score: 0.6783\n",
      "Epoch 93: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4732 - accuracy: 0.7683 - f1_score: 0.6783\n",
      "Epoch 94/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.7705 - f1_score: 0.6758\n",
      "Epoch 94: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4725 - accuracy: 0.7705 - f1_score: 0.6758\n",
      "Epoch 95/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.7700 - f1_score: 0.6754\n",
      "Epoch 95: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4726 - accuracy: 0.7700 - f1_score: 0.6754\n",
      "Epoch 96/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.7710 - f1_score: 0.6764\n",
      "Epoch 96: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4708 - accuracy: 0.7710 - f1_score: 0.6764\n",
      "Epoch 97/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4720 - accuracy: 0.7699 - f1_score: 0.6752\n",
      "Epoch 97: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4720 - accuracy: 0.7699 - f1_score: 0.6752\n",
      "Epoch 98/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4716 - accuracy: 0.7683 - f1_score: 0.6771\n",
      "Epoch 98: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4716 - accuracy: 0.7683 - f1_score: 0.6772\n",
      "Epoch 99/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4723 - accuracy: 0.7689 - f1_score: 0.6774\n",
      "Epoch 99: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4723 - accuracy: 0.7689 - f1_score: 0.6774\n",
      "Epoch 100/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.7677 - f1_score: 0.6757\n",
      "Epoch 100: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4737 - accuracy: 0.7677 - f1_score: 0.6757\n",
      "Epoch 101/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.7709 - f1_score: 0.6773\n",
      "Epoch 101: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4680 - accuracy: 0.7709 - f1_score: 0.6773\n",
      "Epoch 102/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7691 - f1_score: 0.6781\n",
      "Epoch 102: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4714 - accuracy: 0.7692 - f1_score: 0.6781\n",
      "Epoch 103/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.7680 - f1_score: 0.6783\n",
      "Epoch 103: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4753 - accuracy: 0.7680 - f1_score: 0.6783\n",
      "Epoch 104/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4707 - accuracy: 0.7701 - f1_score: 0.6788\n",
      "Epoch 104: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4707 - accuracy: 0.7701 - f1_score: 0.6788\n",
      "Epoch 105/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4719 - accuracy: 0.7691 - f1_score: 0.6757\n",
      "Epoch 105: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4718 - accuracy: 0.7692 - f1_score: 0.6757\n",
      "Epoch 106/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.7692 - f1_score: 0.6765\n",
      "Epoch 106: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4711 - accuracy: 0.7692 - f1_score: 0.6765\n",
      "Epoch 107/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4691 - accuracy: 0.7706 - f1_score: 0.6760\n",
      "Epoch 107: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4691 - accuracy: 0.7707 - f1_score: 0.6760\n",
      "Epoch 108/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.7707 - f1_score: 0.6776\n",
      "Epoch 108: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4684 - accuracy: 0.7707 - f1_score: 0.6776\n",
      "Epoch 109/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.7719 - f1_score: 0.6776\n",
      "Epoch 109: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4684 - accuracy: 0.7719 - f1_score: 0.6776\n",
      "Epoch 110/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.7718 - f1_score: 0.6780\n",
      "Epoch 110: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4685 - accuracy: 0.7718 - f1_score: 0.6780\n",
      "Epoch 111/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4698 - accuracy: 0.7716 - f1_score: 0.6775\n",
      "Epoch 111: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4698 - accuracy: 0.7716 - f1_score: 0.6776\n",
      "Epoch 112/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4704 - accuracy: 0.7692 - f1_score: 0.6771\n",
      "Epoch 112: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4704 - accuracy: 0.7692 - f1_score: 0.6771\n",
      "Epoch 113/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4723 - accuracy: 0.7697 - f1_score: 0.6763\n",
      "Epoch 113: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4723 - accuracy: 0.7697 - f1_score: 0.6762\n",
      "Epoch 114/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4715 - accuracy: 0.7703 - f1_score: 0.6772\n",
      "Epoch 114: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4715 - accuracy: 0.7703 - f1_score: 0.6772\n",
      "Epoch 115/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4689 - accuracy: 0.7722 - f1_score: 0.6782\n",
      "Epoch 115: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4689 - accuracy: 0.7722 - f1_score: 0.6782\n",
      "Epoch 116/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4694 - accuracy: 0.7733 - f1_score: 0.6775\n",
      "Epoch 116: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4693 - accuracy: 0.7733 - f1_score: 0.6775\n",
      "Epoch 117/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4690 - accuracy: 0.7715 - f1_score: 0.6784\n",
      "Epoch 117: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4690 - accuracy: 0.7715 - f1_score: 0.6784\n",
      "Epoch 118/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4713 - accuracy: 0.7707 - f1_score: 0.6767\n",
      "Epoch 118: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4713 - accuracy: 0.7708 - f1_score: 0.6767\n",
      "Epoch 119/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.7710 - f1_score: 0.6778\n",
      "Epoch 119: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4711 - accuracy: 0.7710 - f1_score: 0.6778\n",
      "Epoch 120/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4698 - accuracy: 0.7724 - f1_score: 0.6787\n",
      "Epoch 120: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4698 - accuracy: 0.7724 - f1_score: 0.6787\n",
      "Epoch 121/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4694 - accuracy: 0.7724 - f1_score: 0.6780\n",
      "Epoch 121: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4695 - accuracy: 0.7724 - f1_score: 0.6780\n",
      "Epoch 122/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4678 - accuracy: 0.7722 - f1_score: 0.6782\n",
      "Epoch 122: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4678 - accuracy: 0.7722 - f1_score: 0.6782\n",
      "Epoch 123/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4694 - accuracy: 0.7724 - f1_score: 0.6773\n",
      "Epoch 123: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4693 - accuracy: 0.7723 - f1_score: 0.6774\n",
      "Epoch 124/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4688 - accuracy: 0.7723 - f1_score: 0.6774\n",
      "Epoch 124: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4687 - accuracy: 0.7723 - f1_score: 0.6774\n",
      "Epoch 125/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.7723 - f1_score: 0.6778\n",
      "Epoch 125: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4684 - accuracy: 0.7723 - f1_score: 0.6778\n",
      "Epoch 126/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7708 - f1_score: 0.6786\n",
      "Epoch 126: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4713 - accuracy: 0.7708 - f1_score: 0.6786\n",
      "Epoch 127/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.7693 - f1_score: 0.6773\n",
      "Epoch 127: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4730 - accuracy: 0.7693 - f1_score: 0.6773\n",
      "Epoch 128/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4734 - accuracy: 0.7684 - f1_score: 0.6773\n",
      "Epoch 128: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4734 - accuracy: 0.7684 - f1_score: 0.6773\n",
      "Epoch 129/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.7704 - f1_score: 0.6766\n",
      "Epoch 129: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4729 - accuracy: 0.7704 - f1_score: 0.6766\n",
      "Epoch 130/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7706 - f1_score: 0.6770\n",
      "Epoch 130: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4702 - accuracy: 0.7706 - f1_score: 0.6770\n",
      "Epoch 131/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4696 - accuracy: 0.7714 - f1_score: 0.6788\n",
      "Epoch 131: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4695 - accuracy: 0.7714 - f1_score: 0.6788\n",
      "Epoch 132/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4713 - accuracy: 0.7698 - f1_score: 0.6773\n",
      "Epoch 132: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4713 - accuracy: 0.7698 - f1_score: 0.6773\n",
      "Epoch 133/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4707 - accuracy: 0.7698 - f1_score: 0.6776\n",
      "Epoch 133: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4707 - accuracy: 0.7698 - f1_score: 0.6776\n",
      "Epoch 134/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4730 - accuracy: 0.7690 - f1_score: 0.6780\n",
      "Epoch 134: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4730 - accuracy: 0.7690 - f1_score: 0.6780\n",
      "Epoch 135/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.7721 - f1_score: 0.6791\n",
      "Epoch 135: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4703 - accuracy: 0.7721 - f1_score: 0.6791\n",
      "Epoch 136/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.7734 - f1_score: 0.6771\n",
      "Epoch 136: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4683 - accuracy: 0.7734 - f1_score: 0.6771\n",
      "Epoch 137/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4671 - accuracy: 0.7733 - f1_score: 0.6774\n",
      "Epoch 137: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4671 - accuracy: 0.7733 - f1_score: 0.6774\n",
      "Epoch 138/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.7723 - f1_score: 0.6760\n",
      "Epoch 138: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4706 - accuracy: 0.7723 - f1_score: 0.6760\n",
      "Epoch 139/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4700 - accuracy: 0.7712 - f1_score: 0.6772\n",
      "Epoch 139: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4700 - accuracy: 0.7712 - f1_score: 0.6772\n",
      "Epoch 140/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4720 - accuracy: 0.7716 - f1_score: 0.6776\n",
      "Epoch 140: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4719 - accuracy: 0.7716 - f1_score: 0.6776\n",
      "Epoch 141/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4715 - accuracy: 0.7700 - f1_score: 0.6772\n",
      "Epoch 141: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4715 - accuracy: 0.7700 - f1_score: 0.6772\n",
      "Epoch 142/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.7708 - f1_score: 0.6785\n",
      "Epoch 142: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4703 - accuracy: 0.7708 - f1_score: 0.6785\n",
      "Epoch 143/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4729 - accuracy: 0.7684 - f1_score: 0.6778\n",
      "Epoch 143: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4729 - accuracy: 0.7684 - f1_score: 0.6777\n",
      "Epoch 144/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.7690 - f1_score: 0.6775\n",
      "Epoch 144: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4725 - accuracy: 0.7690 - f1_score: 0.6776\n",
      "Epoch 145/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.7686 - f1_score: 0.6796\n",
      "Epoch 145: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4720 - accuracy: 0.7686 - f1_score: 0.6796\n",
      "Epoch 146/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.7685 - f1_score: 0.6772\n",
      "Epoch 146: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4739 - accuracy: 0.7685 - f1_score: 0.6772\n",
      "Epoch 147/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.7714 - f1_score: 0.6758\n",
      "Epoch 147: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4721 - accuracy: 0.7714 - f1_score: 0.6758\n",
      "Epoch 148/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.7709 - f1_score: 0.6775\n",
      "Epoch 148: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4706 - accuracy: 0.7709 - f1_score: 0.6775\n",
      "Epoch 149/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.7743 - f1_score: 0.6791\n",
      "Epoch 149: f1_score did not improve from 0.67984\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4666 - accuracy: 0.7743 - f1_score: 0.6792\n",
      "Epoch 150/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.7736 - f1_score: 0.6804\n",
      "Epoch 150: f1_score improved from 0.67984 to 0.68045, saving model to ./BNckpt2\\wght-imprv-150-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4658 - accuracy: 0.7736 - f1_score: 0.6804\n",
      "Epoch 151/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4678 - accuracy: 0.7727 - f1_score: 0.6813\n",
      "Epoch 151: f1_score improved from 0.68045 to 0.68130, saving model to ./BNckpt2\\wght-imprv-151-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4678 - accuracy: 0.7727 - f1_score: 0.6813\n",
      "Epoch 152/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4671 - accuracy: 0.7739 - f1_score: 0.6795\n",
      "Epoch 152: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4671 - accuracy: 0.7739 - f1_score: 0.6796\n",
      "Epoch 153/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4674 - accuracy: 0.7723 - f1_score: 0.6795\n",
      "Epoch 153: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4673 - accuracy: 0.7723 - f1_score: 0.6795\n",
      "Epoch 154/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.7738 - f1_score: 0.6798\n",
      "Epoch 154: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4665 - accuracy: 0.7738 - f1_score: 0.6798\n",
      "Epoch 155/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7721 - f1_score: 0.6771\n",
      "Epoch 155: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4702 - accuracy: 0.7721 - f1_score: 0.6771\n",
      "Epoch 156/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4695 - accuracy: 0.7723 - f1_score: 0.6780\n",
      "Epoch 156: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4695 - accuracy: 0.7723 - f1_score: 0.6780\n",
      "Epoch 157/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4686 - accuracy: 0.7719 - f1_score: 0.6775\n",
      "Epoch 157: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4686 - accuracy: 0.7719 - f1_score: 0.6774\n",
      "Epoch 158/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4678 - accuracy: 0.7717 - f1_score: 0.6803\n",
      "Epoch 158: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4678 - accuracy: 0.7717 - f1_score: 0.6803\n",
      "Epoch 159/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4676 - accuracy: 0.7736 - f1_score: 0.6812\n",
      "Epoch 159: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4676 - accuracy: 0.7736 - f1_score: 0.6811\n",
      "Epoch 160/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4655 - accuracy: 0.7749 - f1_score: 0.6795\n",
      "Epoch 160: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4655 - accuracy: 0.7749 - f1_score: 0.6795\n",
      "Epoch 161/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4671 - accuracy: 0.7733 - f1_score: 0.6800\n",
      "Epoch 161: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4671 - accuracy: 0.7733 - f1_score: 0.6800\n",
      "Epoch 162/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4688 - accuracy: 0.7721 - f1_score: 0.6789\n",
      "Epoch 162: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4687 - accuracy: 0.7721 - f1_score: 0.6788\n",
      "Epoch 163/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.7729 - f1_score: 0.6787\n",
      "Epoch 163: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4686 - accuracy: 0.7729 - f1_score: 0.6787\n",
      "Epoch 164/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4738 - accuracy: 0.7716 - f1_score: 0.6779\n",
      "Epoch 164: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4738 - accuracy: 0.7716 - f1_score: 0.6779\n",
      "Epoch 165/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4679 - accuracy: 0.7717 - f1_score: 0.6787\n",
      "Epoch 165: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4679 - accuracy: 0.7717 - f1_score: 0.6787\n",
      "Epoch 166/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7705 - f1_score: 0.6774\n",
      "Epoch 166: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4702 - accuracy: 0.7705 - f1_score: 0.6774\n",
      "Epoch 167/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4700 - accuracy: 0.7703 - f1_score: 0.6782\n",
      "Epoch 167: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4700 - accuracy: 0.7703 - f1_score: 0.6782\n",
      "Epoch 168/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.7712 - f1_score: 0.6776\n",
      "Epoch 168: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4706 - accuracy: 0.7712 - f1_score: 0.6776\n",
      "Epoch 169/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4738 - accuracy: 0.7671 - f1_score: 0.6797\n",
      "Epoch 169: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4738 - accuracy: 0.7672 - f1_score: 0.6797\n",
      "Epoch 170/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7716 - f1_score: 0.6786\n",
      "Epoch 170: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4711 - accuracy: 0.7717 - f1_score: 0.6786\n",
      "Epoch 171/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4735 - accuracy: 0.7704 - f1_score: 0.6790\n",
      "Epoch 171: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4735 - accuracy: 0.7705 - f1_score: 0.6790\n",
      "Epoch 172/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4678 - accuracy: 0.7727 - f1_score: 0.6781\n",
      "Epoch 172: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4677 - accuracy: 0.7727 - f1_score: 0.6780\n",
      "Epoch 173/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.7705 - f1_score: 0.6789\n",
      "Epoch 173: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4709 - accuracy: 0.7704 - f1_score: 0.6788\n",
      "Epoch 174/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7679 - f1_score: 0.6801\n",
      "Epoch 174: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4711 - accuracy: 0.7679 - f1_score: 0.6801\n",
      "Epoch 175/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.7666 - f1_score: 0.6813\n",
      "Epoch 175: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4726 - accuracy: 0.7666 - f1_score: 0.6813\n",
      "Epoch 176/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7698 - f1_score: 0.6795\n",
      "Epoch 176: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4712 - accuracy: 0.7698 - f1_score: 0.6795\n",
      "Epoch 177/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4723 - accuracy: 0.7678 - f1_score: 0.6799\n",
      "Epoch 177: f1_score did not improve from 0.68130\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4723 - accuracy: 0.7678 - f1_score: 0.6799\n",
      "Epoch 178/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7685 - f1_score: 0.6817\n",
      "Epoch 178: f1_score improved from 0.68130 to 0.68174, saving model to ./BNckpt2\\wght-imprv-178-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4701 - accuracy: 0.7685 - f1_score: 0.6817\n",
      "Epoch 179/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.7678 - f1_score: 0.6813\n",
      "Epoch 179: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 45s 5ms/step - loss: 0.4728 - accuracy: 0.7678 - f1_score: 0.6813\n",
      "Epoch 180/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4746 - accuracy: 0.7690 - f1_score: 0.6798\n",
      "Epoch 180: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4746 - accuracy: 0.7690 - f1_score: 0.6798\n",
      "Epoch 181/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4733 - accuracy: 0.7692 - f1_score: 0.6789\n",
      "Epoch 181: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4732 - accuracy: 0.7692 - f1_score: 0.6789\n",
      "Epoch 182/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.7687 - f1_score: 0.6793\n",
      "Epoch 182: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4724 - accuracy: 0.7687 - f1_score: 0.6793\n",
      "Epoch 183/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4742 - accuracy: 0.7672 - f1_score: 0.6798\n",
      "Epoch 183: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4742 - accuracy: 0.7672 - f1_score: 0.6798\n",
      "Epoch 184/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.7660 - f1_score: 0.6788\n",
      "Epoch 184: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4753 - accuracy: 0.7660 - f1_score: 0.6788\n",
      "Epoch 185/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4752 - accuracy: 0.7652 - f1_score: 0.6788\n",
      "Epoch 185: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4752 - accuracy: 0.7652 - f1_score: 0.6788\n",
      "Epoch 186/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4750 - accuracy: 0.7662 - f1_score: 0.6771\n",
      "Epoch 186: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4751 - accuracy: 0.7661 - f1_score: 0.6771\n",
      "Epoch 187/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.7677 - f1_score: 0.6777\n",
      "Epoch 187: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4722 - accuracy: 0.7677 - f1_score: 0.6777\n",
      "Epoch 188/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.7664 - f1_score: 0.6781\n",
      "Epoch 188: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4745 - accuracy: 0.7664 - f1_score: 0.6781\n",
      "Epoch 189/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.7680 - f1_score: 0.6770\n",
      "Epoch 189: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4768 - accuracy: 0.7680 - f1_score: 0.6770\n",
      "Epoch 190/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4756 - accuracy: 0.7663 - f1_score: 0.6778\n",
      "Epoch 190: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4756 - accuracy: 0.7663 - f1_score: 0.6777\n",
      "Epoch 191/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.7653 - f1_score: 0.6786\n",
      "Epoch 191: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4760 - accuracy: 0.7653 - f1_score: 0.6786\n",
      "Epoch 192/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4757 - accuracy: 0.7675 - f1_score: 0.6779\n",
      "Epoch 192: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4757 - accuracy: 0.7675 - f1_score: 0.6779\n",
      "Epoch 193/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.7669 - f1_score: 0.6791\n",
      "Epoch 193: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4736 - accuracy: 0.7669 - f1_score: 0.6791\n",
      "Epoch 194/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.7670 - f1_score: 0.6771\n",
      "Epoch 194: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4760 - accuracy: 0.7670 - f1_score: 0.6771\n",
      "Epoch 195/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.7685 - f1_score: 0.6776\n",
      "Epoch 195: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4745 - accuracy: 0.7685 - f1_score: 0.6776\n",
      "Epoch 196/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4747 - accuracy: 0.7676 - f1_score: 0.6792\n",
      "Epoch 196: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4747 - accuracy: 0.7676 - f1_score: 0.6792\n",
      "Epoch 197/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7700 - f1_score: 0.6783\n",
      "Epoch 197: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4702 - accuracy: 0.7700 - f1_score: 0.6784\n",
      "Epoch 198/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.7682 - f1_score: 0.6777\n",
      "Epoch 198: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4726 - accuracy: 0.7682 - f1_score: 0.6777\n",
      "Epoch 199/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.7664 - f1_score: 0.6792\n",
      "Epoch 199: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4754 - accuracy: 0.7664 - f1_score: 0.6792\n",
      "Epoch 200/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4754 - accuracy: 0.7669 - f1_score: 0.6774\n",
      "Epoch 200: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4754 - accuracy: 0.7669 - f1_score: 0.6774\n",
      "Epoch 201/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4758 - accuracy: 0.7661 - f1_score: 0.6778\n",
      "Epoch 201: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4758 - accuracy: 0.7661 - f1_score: 0.6778\n",
      "Epoch 202/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.7663 - f1_score: 0.6782\n",
      "Epoch 202: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4737 - accuracy: 0.7663 - f1_score: 0.6782\n",
      "Epoch 203/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4678 - accuracy: 0.7723 - f1_score: 0.6794\n",
      "Epoch 203: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4677 - accuracy: 0.7723 - f1_score: 0.6794\n",
      "Epoch 204/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.7692 - f1_score: 0.6793\n",
      "Epoch 204: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 45s 5ms/step - loss: 0.4711 - accuracy: 0.7692 - f1_score: 0.6793\n",
      "Epoch 205/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4713 - accuracy: 0.7694 - f1_score: 0.6784\n",
      "Epoch 205: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4713 - accuracy: 0.7694 - f1_score: 0.6784\n",
      "Epoch 206/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4718 - accuracy: 0.7682 - f1_score: 0.6801\n",
      "Epoch 206: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4718 - accuracy: 0.7682 - f1_score: 0.6800\n",
      "Epoch 207/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4720 - accuracy: 0.7698 - f1_score: 0.6776\n",
      "Epoch 207: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4720 - accuracy: 0.7698 - f1_score: 0.6776\n",
      "Epoch 208/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.7716 - f1_score: 0.6796\n",
      "Epoch 208: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4707 - accuracy: 0.7715 - f1_score: 0.6795\n",
      "Epoch 209/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4775 - accuracy: 0.7653 - f1_score: 0.6797\n",
      "Epoch 209: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4775 - accuracy: 0.7654 - f1_score: 0.6798\n",
      "Epoch 210/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4695 - accuracy: 0.7702 - f1_score: 0.6797\n",
      "Epoch 210: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4695 - accuracy: 0.7702 - f1_score: 0.6797\n",
      "Epoch 211/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4711 - accuracy: 0.7711 - f1_score: 0.6770\n",
      "Epoch 211: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4712 - accuracy: 0.7711 - f1_score: 0.6770\n",
      "Epoch 212/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4696 - accuracy: 0.7712 - f1_score: 0.6790\n",
      "Epoch 212: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4696 - accuracy: 0.7712 - f1_score: 0.6790\n",
      "Epoch 213/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4690 - accuracy: 0.7724 - f1_score: 0.6807\n",
      "Epoch 213: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4690 - accuracy: 0.7724 - f1_score: 0.6808\n",
      "Epoch 214/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.7723 - f1_score: 0.6793\n",
      "Epoch 214: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4696 - accuracy: 0.7723 - f1_score: 0.6793\n",
      "Epoch 215/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4687 - accuracy: 0.7721 - f1_score: 0.6797\n",
      "Epoch 215: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4687 - accuracy: 0.7720 - f1_score: 0.6797\n",
      "Epoch 216/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4693 - accuracy: 0.7713 - f1_score: 0.6775\n",
      "Epoch 216: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4693 - accuracy: 0.7713 - f1_score: 0.6775\n",
      "Epoch 217/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4679 - accuracy: 0.7721 - f1_score: 0.6805\n",
      "Epoch 217: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4679 - accuracy: 0.7721 - f1_score: 0.6805\n",
      "Epoch 218/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4713 - accuracy: 0.7722 - f1_score: 0.6797\n",
      "Epoch 218: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4712 - accuracy: 0.7722 - f1_score: 0.6797\n",
      "Epoch 219/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4679 - accuracy: 0.7740 - f1_score: 0.6786\n",
      "Epoch 219: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4679 - accuracy: 0.7740 - f1_score: 0.6785\n",
      "Epoch 220/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4705 - accuracy: 0.7709 - f1_score: 0.6780\n",
      "Epoch 220: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4705 - accuracy: 0.7709 - f1_score: 0.6780\n",
      "Epoch 221/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.7715 - f1_score: 0.6755\n",
      "Epoch 221: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4708 - accuracy: 0.7715 - f1_score: 0.6755\n",
      "Epoch 222/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7720 - f1_score: 0.6776\n",
      "Epoch 222: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4714 - accuracy: 0.7720 - f1_score: 0.6776\n",
      "Epoch 223/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.7675 - f1_score: 0.6796\n",
      "Epoch 223: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4778 - accuracy: 0.7675 - f1_score: 0.6796\n",
      "Epoch 224/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.7659 - f1_score: 0.6802\n",
      "Epoch 224: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4784 - accuracy: 0.7659 - f1_score: 0.6802\n",
      "Epoch 225/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.7646 - f1_score: 0.6784\n",
      "Epoch 225: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4792 - accuracy: 0.7646 - f1_score: 0.6784\n",
      "Epoch 226/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.7680 - f1_score: 0.6786\n",
      "Epoch 226: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4769 - accuracy: 0.7680 - f1_score: 0.6786\n",
      "Epoch 227/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4746 - accuracy: 0.7681 - f1_score: 0.6813\n",
      "Epoch 227: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4745 - accuracy: 0.7682 - f1_score: 0.6814\n",
      "Epoch 228/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.7665 - f1_score: 0.6799\n",
      "Epoch 228: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4791 - accuracy: 0.7665 - f1_score: 0.6799\n",
      "Epoch 229/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4776 - accuracy: 0.7679 - f1_score: 0.6782\n",
      "Epoch 229: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4776 - accuracy: 0.7679 - f1_score: 0.6782\n",
      "Epoch 230/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.7679 - f1_score: 0.6790\n",
      "Epoch 230: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4783 - accuracy: 0.7679 - f1_score: 0.6790\n",
      "Epoch 231/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4782 - accuracy: 0.7669 - f1_score: 0.6781\n",
      "Epoch 231: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4782 - accuracy: 0.7669 - f1_score: 0.6781\n",
      "Epoch 232/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.7662 - f1_score: 0.6792\n",
      "Epoch 232: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4844 - accuracy: 0.7662 - f1_score: 0.6792\n",
      "Epoch 233/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4813 - accuracy: 0.7645 - f1_score: 0.6778\n",
      "Epoch 233: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4813 - accuracy: 0.7645 - f1_score: 0.6778\n",
      "Epoch 234/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.7651 - f1_score: 0.6775\n",
      "Epoch 234: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4817 - accuracy: 0.7651 - f1_score: 0.6775\n",
      "Epoch 235/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4765 - accuracy: 0.7664 - f1_score: 0.6799\n",
      "Epoch 235: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4765 - accuracy: 0.7664 - f1_score: 0.6798\n",
      "Epoch 236/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.7649 - f1_score: 0.6805\n",
      "Epoch 236: f1_score did not improve from 0.68174\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4791 - accuracy: 0.7649 - f1_score: 0.6805\n",
      "Epoch 237/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.7653 - f1_score: 0.6843\n",
      "Epoch 237: f1_score improved from 0.68174 to 0.68432, saving model to ./BNckpt2\\wght-imprv-237-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4803 - accuracy: 0.7653 - f1_score: 0.6843\n",
      "Epoch 238/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4809 - accuracy: 0.7642 - f1_score: 0.6811\n",
      "Epoch 238: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4809 - accuracy: 0.7643 - f1_score: 0.6811\n",
      "Epoch 239/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4800 - accuracy: 0.7639 - f1_score: 0.6793\n",
      "Epoch 239: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4800 - accuracy: 0.7639 - f1_score: 0.6793\n",
      "Epoch 240/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4802 - accuracy: 0.7648 - f1_score: 0.6795\n",
      "Epoch 240: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4802 - accuracy: 0.7648 - f1_score: 0.6795\n",
      "Epoch 241/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.7670 - f1_score: 0.6805\n",
      "Epoch 241: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4754 - accuracy: 0.7670 - f1_score: 0.6805\n",
      "Epoch 242/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.7670 - f1_score: 0.6804\n",
      "Epoch 242: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4795 - accuracy: 0.7670 - f1_score: 0.6804\n",
      "Epoch 243/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4800 - accuracy: 0.7654 - f1_score: 0.6798\n",
      "Epoch 243: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4800 - accuracy: 0.7654 - f1_score: 0.6798\n",
      "Epoch 244/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4804 - accuracy: 0.7638 - f1_score: 0.6785\n",
      "Epoch 244: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4803 - accuracy: 0.7638 - f1_score: 0.6785\n",
      "Epoch 245/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.7658 - f1_score: 0.6792\n",
      "Epoch 245: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4781 - accuracy: 0.7658 - f1_score: 0.6792\n",
      "Epoch 246/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.7649 - f1_score: 0.6812\n",
      "Epoch 246: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4784 - accuracy: 0.7649 - f1_score: 0.6812\n",
      "Epoch 247/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4786 - accuracy: 0.7667 - f1_score: 0.6799\n",
      "Epoch 247: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4786 - accuracy: 0.7667 - f1_score: 0.6799\n",
      "Epoch 248/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.7663 - f1_score: 0.6799\n",
      "Epoch 248: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4771 - accuracy: 0.7663 - f1_score: 0.6799\n",
      "Epoch 249/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4785 - accuracy: 0.7647 - f1_score: 0.6818\n",
      "Epoch 249: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4785 - accuracy: 0.7646 - f1_score: 0.6818\n",
      "Epoch 250/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.7654 - f1_score: 0.6817\n",
      "Epoch 250: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4785 - accuracy: 0.7654 - f1_score: 0.6817\n",
      "Epoch 251/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.7669 - f1_score: 0.6805\n",
      "Epoch 251: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4792 - accuracy: 0.7669 - f1_score: 0.6805\n",
      "Epoch 252/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.7657 - f1_score: 0.6789\n",
      "Epoch 252: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4802 - accuracy: 0.7657 - f1_score: 0.6789\n",
      "Epoch 253/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.7669 - f1_score: 0.6793\n",
      "Epoch 253: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 43s 5ms/step - loss: 0.4784 - accuracy: 0.7669 - f1_score: 0.6793\n",
      "Epoch 254/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4802 - accuracy: 0.7658 - f1_score: 0.6815\n",
      "Epoch 254: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4802 - accuracy: 0.7659 - f1_score: 0.6815\n",
      "Epoch 255/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4766 - accuracy: 0.7668 - f1_score: 0.6819\n",
      "Epoch 255: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4766 - accuracy: 0.7668 - f1_score: 0.6819\n",
      "Epoch 256/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4790 - accuracy: 0.7666 - f1_score: 0.6808\n",
      "Epoch 256: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4789 - accuracy: 0.7666 - f1_score: 0.6808\n",
      "Epoch 257/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.7663 - f1_score: 0.6815\n",
      "Epoch 257: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4770 - accuracy: 0.7663 - f1_score: 0.6815\n",
      "Epoch 258/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4766 - accuracy: 0.7681 - f1_score: 0.6828\n",
      "Epoch 258: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4766 - accuracy: 0.7681 - f1_score: 0.6828\n",
      "Epoch 259/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.7671 - f1_score: 0.6807\n",
      "Epoch 259: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4769 - accuracy: 0.7671 - f1_score: 0.6807\n",
      "Epoch 260/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.7671 - f1_score: 0.6817\n",
      "Epoch 260: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4769 - accuracy: 0.7671 - f1_score: 0.6817\n",
      "Epoch 261/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4791 - accuracy: 0.7663 - f1_score: 0.6821\n",
      "Epoch 261: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4791 - accuracy: 0.7662 - f1_score: 0.6820\n",
      "Epoch 262/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4796 - accuracy: 0.7671 - f1_score: 0.6817\n",
      "Epoch 262: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4796 - accuracy: 0.7671 - f1_score: 0.6817\n",
      "Epoch 263/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4773 - accuracy: 0.7701 - f1_score: 0.6821\n",
      "Epoch 263: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4773 - accuracy: 0.7701 - f1_score: 0.6821\n",
      "Epoch 264/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4788 - accuracy: 0.7682 - f1_score: 0.6832\n",
      "Epoch 264: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4788 - accuracy: 0.7682 - f1_score: 0.6832\n",
      "Epoch 265/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.7666 - f1_score: 0.6803\n",
      "Epoch 265: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4792 - accuracy: 0.7666 - f1_score: 0.6803\n",
      "Epoch 266/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4779 - accuracy: 0.7679 - f1_score: 0.6822\n",
      "Epoch 266: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4779 - accuracy: 0.7679 - f1_score: 0.6822\n",
      "Epoch 267/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4863 - accuracy: 0.7645 - f1_score: 0.6801\n",
      "Epoch 267: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4863 - accuracy: 0.7644 - f1_score: 0.6801\n",
      "Epoch 268/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.7656 - f1_score: 0.6786\n",
      "Epoch 268: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4852 - accuracy: 0.7657 - f1_score: 0.6786\n",
      "Epoch 269/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.7650 - f1_score: 0.6840\n",
      "Epoch 269: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4819 - accuracy: 0.7650 - f1_score: 0.6840\n",
      "Epoch 270/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4801 - accuracy: 0.7668 - f1_score: 0.6827\n",
      "Epoch 270: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4801 - accuracy: 0.7668 - f1_score: 0.6827\n",
      "Epoch 271/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.7667 - f1_score: 0.6837\n",
      "Epoch 271: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4781 - accuracy: 0.7667 - f1_score: 0.6837\n",
      "Epoch 272/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.7666 - f1_score: 0.6831\n",
      "Epoch 272: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4788 - accuracy: 0.7666 - f1_score: 0.6831\n",
      "Epoch 273/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4774 - accuracy: 0.7674 - f1_score: 0.6827\n",
      "Epoch 273: f1_score did not improve from 0.68432\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4774 - accuracy: 0.7674 - f1_score: 0.6827\n",
      "Epoch 274/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4786 - accuracy: 0.7665 - f1_score: 0.6845\n",
      "Epoch 274: f1_score improved from 0.68432 to 0.68451, saving model to ./BNckpt2\\wght-imprv-274-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4786 - accuracy: 0.7665 - f1_score: 0.6845\n",
      "Epoch 275/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4790 - accuracy: 0.7659 - f1_score: 0.6829\n",
      "Epoch 275: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4790 - accuracy: 0.7659 - f1_score: 0.6830\n",
      "Epoch 276/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4759 - accuracy: 0.7689 - f1_score: 0.6844\n",
      "Epoch 276: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4760 - accuracy: 0.7689 - f1_score: 0.6844\n",
      "Epoch 277/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.7661 - f1_score: 0.6778\n",
      "Epoch 277: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4912 - accuracy: 0.7661 - f1_score: 0.6778\n",
      "Epoch 278/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4895 - accuracy: 0.7679 - f1_score: 0.6743\n",
      "Epoch 278: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4895 - accuracy: 0.7679 - f1_score: 0.6743\n",
      "Epoch 279/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4814 - accuracy: 0.7681 - f1_score: 0.6793\n",
      "Epoch 279: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4814 - accuracy: 0.7681 - f1_score: 0.6793\n",
      "Epoch 280/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4816 - accuracy: 0.7681 - f1_score: 0.6822\n",
      "Epoch 280: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4816 - accuracy: 0.7681 - f1_score: 0.6823\n",
      "Epoch 281/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.7668 - f1_score: 0.6819\n",
      "Epoch 281: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4805 - accuracy: 0.7668 - f1_score: 0.6819\n",
      "Epoch 282/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.7683 - f1_score: 0.6826\n",
      "Epoch 282: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4781 - accuracy: 0.7683 - f1_score: 0.6826\n",
      "Epoch 283/300\n",
      "8825/8827 [============================>.] - ETA: 0s - loss: 0.4794 - accuracy: 0.7663 - f1_score: 0.6823\n",
      "Epoch 283: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4794 - accuracy: 0.7663 - f1_score: 0.6823\n",
      "Epoch 284/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4790 - accuracy: 0.7674 - f1_score: 0.6826\n",
      "Epoch 284: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4790 - accuracy: 0.7674 - f1_score: 0.6826\n",
      "Epoch 285/300\n",
      "8826/8827 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.7684 - f1_score: 0.6824\n",
      "Epoch 285: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4783 - accuracy: 0.7684 - f1_score: 0.6824\n",
      "Epoch 286/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.7666 - f1_score: 0.6823\n",
      "Epoch 286: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4806 - accuracy: 0.7666 - f1_score: 0.6823\n",
      "Epoch 287/300\n",
      "8822/8827 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.7661 - f1_score: 0.6803\n",
      "Epoch 287: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4803 - accuracy: 0.7661 - f1_score: 0.6803\n",
      "Epoch 288/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4791 - accuracy: 0.7677 - f1_score: 0.6820\n",
      "Epoch 288: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4791 - accuracy: 0.7677 - f1_score: 0.6820\n",
      "Epoch 289/300\n",
      "8823/8827 [============================>.] - ETA: 0s - loss: 0.4829 - accuracy: 0.7661 - f1_score: 0.6791\n",
      "Epoch 289: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4829 - accuracy: 0.7661 - f1_score: 0.6791\n",
      "Epoch 290/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.7662 - f1_score: 0.6798\n",
      "Epoch 290: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4843 - accuracy: 0.7662 - f1_score: 0.6798\n",
      "Epoch 291/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4809 - accuracy: 0.7669 - f1_score: 0.6799\n",
      "Epoch 291: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4810 - accuracy: 0.7669 - f1_score: 0.6799\n",
      "Epoch 292/300\n",
      "8819/8827 [============================>.] - ETA: 0s - loss: 0.4833 - accuracy: 0.7683 - f1_score: 0.6787\n",
      "Epoch 292: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4833 - accuracy: 0.7683 - f1_score: 0.6787\n",
      "Epoch 293/300\n",
      "8827/8827 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7680 - f1_score: 0.6803\n",
      "Epoch 293: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4811 - accuracy: 0.7680 - f1_score: 0.6803\n",
      "Epoch 294/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4841 - accuracy: 0.7663 - f1_score: 0.6797\n",
      "Epoch 294: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4841 - accuracy: 0.7663 - f1_score: 0.6797\n",
      "Epoch 295/300\n",
      "8824/8827 [============================>.] - ETA: 0s - loss: 0.4836 - accuracy: 0.7648 - f1_score: 0.6800\n",
      "Epoch 295: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4836 - accuracy: 0.7647 - f1_score: 0.6800\n",
      "Epoch 296/300\n",
      "8820/8827 [============================>.] - ETA: 0s - loss: 0.4825 - accuracy: 0.7655 - f1_score: 0.6809\n",
      "Epoch 296: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4825 - accuracy: 0.7655 - f1_score: 0.6809\n",
      "Epoch 297/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4814 - accuracy: 0.7662 - f1_score: 0.6814\n",
      "Epoch 297: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4814 - accuracy: 0.7662 - f1_score: 0.6814\n",
      "Epoch 298/300\n",
      "8817/8827 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.7685 - f1_score: 0.6804\n",
      "Epoch 298: f1_score did not improve from 0.68451\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4792 - accuracy: 0.7685 - f1_score: 0.6804\n",
      "Epoch 299/300\n",
      "8821/8827 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.7666 - f1_score: 0.6846\n",
      "Epoch 299: f1_score improved from 0.68451 to 0.68466, saving model to ./BNckpt2\\wght-imprv-299-0.77-0.68.hdf5\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4803 - accuracy: 0.7666 - f1_score: 0.6847\n",
      "Epoch 300/300\n",
      "8818/8827 [============================>.] - ETA: 0s - loss: 0.4814 - accuracy: 0.7657 - f1_score: 0.6820\n",
      "Epoch 300: f1_score did not improve from 0.68466\n",
      "8827/8827 [==============================] - 44s 5ms/step - loss: 0.4814 - accuracy: 0.7657 - f1_score: 0.6820\n"
     ]
    }
   ],
   "source": [
    "filepath=\"./BNckpt\" + str(j) + \"/wght-imprv-{epoch:02d}-{accuracy:.2f}-{f1_score:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='f1_score', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "new_model.fit(X_train, y_train, epochs=300, callbacks=callbacks_list)\n",
    "j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.7771 - f1_score: 0.6757\n",
      "Epoch 1: accuracy improved from -inf to 0.77709, saving model to ./batch_size-625\\weight-improvement-1-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 5s 7ms/step - loss: 0.4659 - accuracy: 0.7771 - f1_score: 0.6756\n",
      "Epoch 2/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4635 - accuracy: 0.7784 - f1_score: 0.6763\n",
      "Epoch 2: accuracy improved from 0.77709 to 0.77828, saving model to ./batch_size-625\\weight-improvement-2-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4635 - accuracy: 0.7783 - f1_score: 0.6763\n",
      "Epoch 3/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4621 - accuracy: 0.7788 - f1_score: 0.6769\n",
      "Epoch 3: accuracy improved from 0.77828 to 0.77882, saving model to ./batch_size-625\\weight-improvement-3-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4621 - accuracy: 0.7788 - f1_score: 0.6770\n",
      "Epoch 4/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.7795 - f1_score: 0.6766\n",
      "Epoch 4: accuracy improved from 0.77882 to 0.77951, saving model to ./batch_size-625\\weight-improvement-4-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4601 - accuracy: 0.7795 - f1_score: 0.6766\n",
      "Epoch 5/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4597 - accuracy: 0.7791 - f1_score: 0.6778\n",
      "Epoch 5: accuracy did not improve from 0.77951\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4598 - accuracy: 0.7791 - f1_score: 0.6777\n",
      "Epoch 6/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4582 - accuracy: 0.7810 - f1_score: 0.6774\n",
      "Epoch 6: accuracy improved from 0.77951 to 0.78087, saving model to ./batch_size-625\\weight-improvement-6-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4582 - accuracy: 0.7809 - f1_score: 0.6774\n",
      "Epoch 7/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4566 - accuracy: 0.7816 - f1_score: 0.6783\n",
      "Epoch 7: accuracy improved from 0.78087 to 0.78162, saving model to ./batch_size-625\\weight-improvement-7-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4566 - accuracy: 0.7816 - f1_score: 0.6782\n",
      "Epoch 8/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4555 - accuracy: 0.7818 - f1_score: 0.6780\n",
      "Epoch 8: accuracy improved from 0.78162 to 0.78184, saving model to ./batch_size-625\\weight-improvement-8-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4554 - accuracy: 0.7818 - f1_score: 0.6780\n",
      "Epoch 9/80\n",
      "559/565 [============================>.] - ETA: 0s - loss: 0.4538 - accuracy: 0.7835 - f1_score: 0.6784\n",
      "Epoch 9: accuracy improved from 0.78184 to 0.78351, saving model to ./batch_size-625\\weight-improvement-9-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4538 - accuracy: 0.7835 - f1_score: 0.6785\n",
      "Epoch 10/80\n",
      "557/565 [============================>.] - ETA: 0s - loss: 0.4546 - accuracy: 0.7834 - f1_score: 0.6787\n",
      "Epoch 10: accuracy did not improve from 0.78351\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4545 - accuracy: 0.7835 - f1_score: 0.6787\n",
      "Epoch 11/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.7850 - f1_score: 0.6788\n",
      "Epoch 11: accuracy improved from 0.78351 to 0.78499, saving model to ./batch_size-625\\weight-improvement-11-0.78-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4523 - accuracy: 0.7850 - f1_score: 0.6788\n",
      "Epoch 12/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.7852 - f1_score: 0.6792\n",
      "Epoch 12: accuracy improved from 0.78499 to 0.78524, saving model to ./batch_size-625\\weight-improvement-12-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4512 - accuracy: 0.7852 - f1_score: 0.6792\n",
      "Epoch 13/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7863 - f1_score: 0.6793\n",
      "Epoch 13: accuracy improved from 0.78524 to 0.78627, saving model to ./batch_size-625\\weight-improvement-13-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4502 - accuracy: 0.7863 - f1_score: 0.6793\n",
      "Epoch 14/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4492 - accuracy: 0.7857 - f1_score: 0.6796\n",
      "Epoch 14: accuracy did not improve from 0.78627\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4491 - accuracy: 0.7858 - f1_score: 0.6796\n",
      "Epoch 15/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4479 - accuracy: 0.7872 - f1_score: 0.6801\n",
      "Epoch 15: accuracy improved from 0.78627 to 0.78723, saving model to ./batch_size-625\\weight-improvement-15-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4479 - accuracy: 0.7872 - f1_score: 0.6801\n",
      "Epoch 16/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4480 - accuracy: 0.7870 - f1_score: 0.6801\n",
      "Epoch 16: accuracy did not improve from 0.78723\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4480 - accuracy: 0.7871 - f1_score: 0.6801\n",
      "Epoch 17/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4456 - accuracy: 0.7885 - f1_score: 0.6802\n",
      "Epoch 17: accuracy improved from 0.78723 to 0.78856, saving model to ./batch_size-625\\weight-improvement-17-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4457 - accuracy: 0.7886 - f1_score: 0.6802\n",
      "Epoch 18/80\n",
      "564/565 [============================>.] - ETA: 0s - loss: 0.4461 - accuracy: 0.7890 - f1_score: 0.6805\n",
      "Epoch 18: accuracy improved from 0.78856 to 0.78900, saving model to ./batch_size-625\\weight-improvement-18-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4461 - accuracy: 0.7890 - f1_score: 0.6805\n",
      "Epoch 19/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4458 - accuracy: 0.7894 - f1_score: 0.6804\n",
      "Epoch 19: accuracy improved from 0.78900 to 0.78947, saving model to ./batch_size-625\\weight-improvement-19-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4457 - accuracy: 0.7895 - f1_score: 0.6804\n",
      "Epoch 20/80\n",
      "564/565 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.7893 - f1_score: 0.6801\n",
      "Epoch 20: accuracy did not improve from 0.78947\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4447 - accuracy: 0.7893 - f1_score: 0.6801\n",
      "Epoch 21/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4442 - accuracy: 0.7892 - f1_score: 0.6805\n",
      "Epoch 21: accuracy did not improve from 0.78947\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4442 - accuracy: 0.7891 - f1_score: 0.6805\n",
      "Epoch 22/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4433 - accuracy: 0.7900 - f1_score: 0.6812\n",
      "Epoch 22: accuracy improved from 0.78947 to 0.79000, saving model to ./batch_size-625\\weight-improvement-22-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4433 - accuracy: 0.7900 - f1_score: 0.6811\n",
      "Epoch 23/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4435 - accuracy: 0.7905 - f1_score: 0.6812\n",
      "Epoch 23: accuracy improved from 0.79000 to 0.79047, saving model to ./batch_size-625\\weight-improvement-23-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4435 - accuracy: 0.7905 - f1_score: 0.6812\n",
      "Epoch 24/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4431 - accuracy: 0.7908 - f1_score: 0.6812\n",
      "Epoch 24: accuracy improved from 0.79047 to 0.79086, saving model to ./batch_size-625\\weight-improvement-24-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4431 - accuracy: 0.7909 - f1_score: 0.6812\n",
      "Epoch 25/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.7905 - f1_score: 0.6807\n",
      "Epoch 25: accuracy did not improve from 0.79086\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4424 - accuracy: 0.7906 - f1_score: 0.6808\n",
      "Epoch 26/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4409 - accuracy: 0.7921 - f1_score: 0.6810\n",
      "Epoch 26: accuracy improved from 0.79086 to 0.79208, saving model to ./batch_size-625\\weight-improvement-26-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4409 - accuracy: 0.7921 - f1_score: 0.6810\n",
      "Epoch 27/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4404 - accuracy: 0.7919 - f1_score: 0.6809\n",
      "Epoch 27: accuracy did not improve from 0.79208\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4403 - accuracy: 0.7919 - f1_score: 0.6808\n",
      "Epoch 28/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4399 - accuracy: 0.7923 - f1_score: 0.6814\n",
      "Epoch 28: accuracy improved from 0.79208 to 0.79231, saving model to ./batch_size-625\\weight-improvement-28-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4399 - accuracy: 0.7923 - f1_score: 0.6815\n",
      "Epoch 29/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4395 - accuracy: 0.7929 - f1_score: 0.6811\n",
      "Epoch 29: accuracy improved from 0.79231 to 0.79284, saving model to ./batch_size-625\\weight-improvement-29-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4395 - accuracy: 0.7928 - f1_score: 0.6810\n",
      "Epoch 30/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4386 - accuracy: 0.7929 - f1_score: 0.6813\n",
      "Epoch 30: accuracy improved from 0.79284 to 0.79285, saving model to ./batch_size-625\\weight-improvement-30-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4387 - accuracy: 0.7929 - f1_score: 0.6812\n",
      "Epoch 31/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4390 - accuracy: 0.7928 - f1_score: 0.6815\n",
      "Epoch 31: accuracy did not improve from 0.79285\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4391 - accuracy: 0.7928 - f1_score: 0.6816\n",
      "Epoch 32/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.7940 - f1_score: 0.6822\n",
      "Epoch 32: accuracy improved from 0.79285 to 0.79408, saving model to ./batch_size-625\\weight-improvement-32-0.79-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4373 - accuracy: 0.7941 - f1_score: 0.6822\n",
      "Epoch 33/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4379 - accuracy: 0.7939 - f1_score: 0.6814\n",
      "Epoch 33: accuracy did not improve from 0.79408\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4378 - accuracy: 0.7940 - f1_score: 0.6815\n",
      "Epoch 34/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4384 - accuracy: 0.7933 - f1_score: 0.6815\n",
      "Epoch 34: accuracy did not improve from 0.79408\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4383 - accuracy: 0.7934 - f1_score: 0.6816\n",
      "Epoch 35/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.7940 - f1_score: 0.6817\n",
      "Epoch 35: accuracy did not improve from 0.79408\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4377 - accuracy: 0.7939 - f1_score: 0.6818\n",
      "Epoch 36/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.7937 - f1_score: 0.6813\n",
      "Epoch 36: accuracy did not improve from 0.79408\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4374 - accuracy: 0.7937 - f1_score: 0.6813\n",
      "Epoch 37/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4350 - accuracy: 0.7953 - f1_score: 0.6819\n",
      "Epoch 37: accuracy improved from 0.79408 to 0.79549, saving model to ./batch_size-625\\weight-improvement-37-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4348 - accuracy: 0.7955 - f1_score: 0.6819\n",
      "Epoch 38/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4354 - accuracy: 0.7940 - f1_score: 0.6826\n",
      "Epoch 38: accuracy did not improve from 0.79549\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4353 - accuracy: 0.7941 - f1_score: 0.6826\n",
      "Epoch 39/80\n",
      "564/565 [============================>.] - ETA: 0s - loss: 0.4353 - accuracy: 0.7956 - f1_score: 0.6823\n",
      "Epoch 39: accuracy improved from 0.79549 to 0.79563, saving model to ./batch_size-625\\weight-improvement-39-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4353 - accuracy: 0.7956 - f1_score: 0.6823\n",
      "Epoch 40/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4341 - accuracy: 0.7959 - f1_score: 0.6827\n",
      "Epoch 40: accuracy improved from 0.79563 to 0.79580, saving model to ./batch_size-625\\weight-improvement-40-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4343 - accuracy: 0.7958 - f1_score: 0.6827\n",
      "Epoch 41/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4343 - accuracy: 0.7961 - f1_score: 0.6821\n",
      "Epoch 41: accuracy improved from 0.79580 to 0.79604, saving model to ./batch_size-625\\weight-improvement-41-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4344 - accuracy: 0.7960 - f1_score: 0.6821\n",
      "Epoch 42/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.7963 - f1_score: 0.6821\n",
      "Epoch 42: accuracy improved from 0.79604 to 0.79626, saving model to ./batch_size-625\\weight-improvement-42-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4339 - accuracy: 0.7963 - f1_score: 0.6821\n",
      "Epoch 43/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4337 - accuracy: 0.7953 - f1_score: 0.6823\n",
      "Epoch 43: accuracy did not improve from 0.79626\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4337 - accuracy: 0.7952 - f1_score: 0.6823\n",
      "Epoch 44/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.7968 - f1_score: 0.6827\n",
      "Epoch 44: accuracy improved from 0.79626 to 0.79676, saving model to ./batch_size-625\\weight-improvement-44-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4315 - accuracy: 0.7968 - f1_score: 0.6827\n",
      "Epoch 45/80\n",
      "559/565 [============================>.] - ETA: 0s - loss: 0.4327 - accuracy: 0.7963 - f1_score: 0.6827\n",
      "Epoch 45: accuracy did not improve from 0.79676\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4328 - accuracy: 0.7963 - f1_score: 0.6826\n",
      "Epoch 46/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4324 - accuracy: 0.7965 - f1_score: 0.6826\n",
      "Epoch 46: accuracy did not improve from 0.79676\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4325 - accuracy: 0.7964 - f1_score: 0.6826\n",
      "Epoch 47/80\n",
      "564/565 [============================>.] - ETA: 0s - loss: 0.4325 - accuracy: 0.7966 - f1_score: 0.6823\n",
      "Epoch 47: accuracy did not improve from 0.79676\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4325 - accuracy: 0.7966 - f1_score: 0.6822\n",
      "Epoch 48/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.7973 - f1_score: 0.6826\n",
      "Epoch 48: accuracy improved from 0.79676 to 0.79740, saving model to ./batch_size-625\\weight-improvement-48-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4314 - accuracy: 0.7974 - f1_score: 0.6827\n",
      "Epoch 49/80\n",
      "564/565 [============================>.] - ETA: 0s - loss: 0.4324 - accuracy: 0.7966 - f1_score: 0.6825\n",
      "Epoch 49: accuracy did not improve from 0.79740\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4324 - accuracy: 0.7966 - f1_score: 0.6825\n",
      "Epoch 50/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4321 - accuracy: 0.7969 - f1_score: 0.6822\n",
      "Epoch 50: accuracy did not improve from 0.79740\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4321 - accuracy: 0.7969 - f1_score: 0.6822\n",
      "Epoch 51/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4316 - accuracy: 0.7976 - f1_score: 0.6837\n",
      "Epoch 51: accuracy improved from 0.79740 to 0.79763, saving model to ./batch_size-625\\weight-improvement-51-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4315 - accuracy: 0.7976 - f1_score: 0.6835\n",
      "Epoch 52/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4312 - accuracy: 0.7984 - f1_score: 0.6826\n",
      "Epoch 52: accuracy improved from 0.79763 to 0.79842, saving model to ./batch_size-625\\weight-improvement-52-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4312 - accuracy: 0.7984 - f1_score: 0.6826\n",
      "Epoch 53/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4302 - accuracy: 0.7978 - f1_score: 0.6828\n",
      "Epoch 53: accuracy did not improve from 0.79842\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4302 - accuracy: 0.7979 - f1_score: 0.6828\n",
      "Epoch 54/80\n",
      "558/565 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.7983 - f1_score: 0.6829\n",
      "Epoch 54: accuracy did not improve from 0.79842\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4287 - accuracy: 0.7983 - f1_score: 0.6831\n",
      "Epoch 55/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.7996 - f1_score: 0.6827\n",
      "Epoch 55: accuracy improved from 0.79842 to 0.79963, saving model to ./batch_size-625\\weight-improvement-55-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4292 - accuracy: 0.7996 - f1_score: 0.6827\n",
      "Epoch 56/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4300 - accuracy: 0.7994 - f1_score: 0.6828\n",
      "Epoch 56: accuracy did not improve from 0.79963\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4300 - accuracy: 0.7994 - f1_score: 0.6828\n",
      "Epoch 57/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.7979 - f1_score: 0.6828\n",
      "Epoch 57: accuracy did not improve from 0.79963\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4298 - accuracy: 0.7979 - f1_score: 0.6828\n",
      "Epoch 58/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.7995 - f1_score: 0.6827\n",
      "Epoch 58: accuracy did not improve from 0.79963\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4288 - accuracy: 0.7995 - f1_score: 0.6827\n",
      "Epoch 59/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4282 - accuracy: 0.7994 - f1_score: 0.6837\n",
      "Epoch 59: accuracy did not improve from 0.79963\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4282 - accuracy: 0.7995 - f1_score: 0.6837\n",
      "Epoch 60/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4292 - accuracy: 0.7994 - f1_score: 0.6826\n",
      "Epoch 60: accuracy did not improve from 0.79963\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4292 - accuracy: 0.7994 - f1_score: 0.6827\n",
      "Epoch 61/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.8003 - f1_score: 0.6828\n",
      "Epoch 61: accuracy improved from 0.79963 to 0.80030, saving model to ./batch_size-625\\weight-improvement-61-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4282 - accuracy: 0.8003 - f1_score: 0.6828\n",
      "Epoch 62/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.7994 - f1_score: 0.6832\n",
      "Epoch 62: accuracy did not improve from 0.80030\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4285 - accuracy: 0.7993 - f1_score: 0.6832\n",
      "Epoch 63/80\n",
      "564/565 [============================>.] - ETA: 0s - loss: 0.4271 - accuracy: 0.8005 - f1_score: 0.6840\n",
      "Epoch 63: accuracy improved from 0.80030 to 0.80046, saving model to ./batch_size-625\\weight-improvement-63-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4271 - accuracy: 0.8005 - f1_score: 0.6840\n",
      "Epoch 64/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.8005 - f1_score: 0.6840\n",
      "Epoch 64: accuracy improved from 0.80046 to 0.80046, saving model to ./batch_size-625\\weight-improvement-64-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4269 - accuracy: 0.8005 - f1_score: 0.6840\n",
      "Epoch 65/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4264 - accuracy: 0.8002 - f1_score: 0.6841\n",
      "Epoch 65: accuracy did not improve from 0.80046\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4264 - accuracy: 0.8002 - f1_score: 0.6841\n",
      "Epoch 66/80\n",
      "559/565 [============================>.] - ETA: 0s - loss: 0.4270 - accuracy: 0.8002 - f1_score: 0.6839\n",
      "Epoch 66: accuracy did not improve from 0.80046\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4270 - accuracy: 0.8003 - f1_score: 0.6839\n",
      "Epoch 67/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4275 - accuracy: 0.7994 - f1_score: 0.6836\n",
      "Epoch 67: accuracy did not improve from 0.80046\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4275 - accuracy: 0.7995 - f1_score: 0.6836\n",
      "Epoch 68/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.8009 - f1_score: 0.6839\n",
      "Epoch 68: accuracy improved from 0.80046 to 0.80093, saving model to ./batch_size-625\\weight-improvement-68-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4262 - accuracy: 0.8009 - f1_score: 0.6839\n",
      "Epoch 69/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4261 - accuracy: 0.8000 - f1_score: 0.6838\n",
      "Epoch 69: accuracy did not improve from 0.80093\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4260 - accuracy: 0.8001 - f1_score: 0.6838\n",
      "Epoch 70/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.8006 - f1_score: 0.6836\n",
      "Epoch 70: accuracy did not improve from 0.80093\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4257 - accuracy: 0.8006 - f1_score: 0.6836\n",
      "Epoch 71/80\n",
      "565/565 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.8008 - f1_score: 0.6840\n",
      "Epoch 71: accuracy did not improve from 0.80093\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4252 - accuracy: 0.8008 - f1_score: 0.6840\n",
      "Epoch 72/80\n",
      "558/565 [============================>.] - ETA: 0s - loss: 0.4246 - accuracy: 0.8028 - f1_score: 0.6841\n",
      "Epoch 72: accuracy improved from 0.80093 to 0.80265, saving model to ./batch_size-625\\weight-improvement-72-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4247 - accuracy: 0.8026 - f1_score: 0.6840\n",
      "Epoch 73/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4255 - accuracy: 0.8012 - f1_score: 0.6842\n",
      "Epoch 73: accuracy did not improve from 0.80265\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4255 - accuracy: 0.8012 - f1_score: 0.6841\n",
      "Epoch 74/80\n",
      "564/565 [============================>.] - ETA: 0s - loss: 0.4238 - accuracy: 0.8022 - f1_score: 0.6838\n",
      "Epoch 74: accuracy did not improve from 0.80265\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4238 - accuracy: 0.8022 - f1_score: 0.6838\n",
      "Epoch 75/80\n",
      "564/565 [============================>.] - ETA: 0s - loss: 0.4242 - accuracy: 0.8023 - f1_score: 0.6841\n",
      "Epoch 75: accuracy did not improve from 0.80265\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4242 - accuracy: 0.8023 - f1_score: 0.6841\n",
      "Epoch 76/80\n",
      "561/565 [============================>.] - ETA: 0s - loss: 0.4235 - accuracy: 0.8023 - f1_score: 0.6846\n",
      "Epoch 76: accuracy did not improve from 0.80265\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4234 - accuracy: 0.8023 - f1_score: 0.6846\n",
      "Epoch 77/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4244 - accuracy: 0.8014 - f1_score: 0.6844\n",
      "Epoch 77: accuracy did not improve from 0.80265\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4245 - accuracy: 0.8014 - f1_score: 0.6843\n",
      "Epoch 78/80\n",
      "563/565 [============================>.] - ETA: 0s - loss: 0.4234 - accuracy: 0.8017 - f1_score: 0.6843\n",
      "Epoch 78: accuracy did not improve from 0.80265\n",
      "565/565 [==============================] - 4s 7ms/step - loss: 0.4235 - accuracy: 0.8016 - f1_score: 0.6843\n",
      "Epoch 79/80\n",
      "560/565 [============================>.] - ETA: 0s - loss: 0.4244 - accuracy: 0.8034 - f1_score: 0.6836\n",
      "Epoch 79: accuracy improved from 0.80265 to 0.80336, saving model to ./batch_size-625\\weight-improvement-79-0.80-0.68.hdf5\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4244 - accuracy: 0.8034 - f1_score: 0.6836\n",
      "Epoch 80/80\n",
      "562/565 [============================>.] - ETA: 0s - loss: 0.4235 - accuracy: 0.8032 - f1_score: 0.6841\n",
      "Epoch 80: accuracy did not improve from 0.80336\n",
      "565/565 [==============================] - 4s 8ms/step - loss: 0.4236 - accuracy: 0.8033 - f1_score: 0.6841\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [5,25,125,625,3125,15625,78125,353080]:\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(100, activation='relu', input_shape=(65,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(200, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(50, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(25, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),    \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(5, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Create an instance of the F1Score metric.\n",
    "    f1_score = F1Score(num_classes=2, average='micro')\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy', f1_score])\n",
    "    model.load_weights(\"./batch_size-\" + str(batch_size) + \"/100.hdf5\")\n",
    "\n",
    "    filepath=\"./batch_size-\" + str(batch_size) + \"/weight--improvement-{epoch}-{accuracy:.2f}-{f1_score:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=batch_size, callbacks=callbacks_list)\n",
    "    model.save_weights(\"./batch_size-\" + str(batch_size) + \"/600.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"batch_size-625/20.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8243 - f1_score: 0.6874\n",
      "Epoch 1: accuracy improved from -inf to 0.82429, saving model to ./625-batch_size625\\weight-improvement2-1-0.82-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3902 - accuracy: 0.8243 - f1_score: 0.6874\n",
      "Epoch 2/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8248 - f1_score: 0.6869\n",
      "Epoch 2: accuracy improved from 0.82429 to 0.82476, saving model to ./625-batch_size625\\weight-improvement2-2-0.82-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3906 - accuracy: 0.8248 - f1_score: 0.6869\n",
      "Epoch 3/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8242 - f1_score: 0.6861\n",
      "Epoch 3: accuracy did not improve from 0.82476\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3908 - accuracy: 0.8242 - f1_score: 0.6861\n",
      "Epoch 4/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8246 - f1_score: 0.6872\n",
      "Epoch 4: accuracy did not improve from 0.82476\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3900 - accuracy: 0.8245 - f1_score: 0.6872\n",
      "Epoch 5/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.8231 - f1_score: 0.6872\n",
      "Epoch 5: accuracy did not improve from 0.82476\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3919 - accuracy: 0.8231 - f1_score: 0.6872\n",
      "Epoch 6/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3919 - accuracy: 0.8232 - f1_score: 0.6870\n",
      "Epoch 6: accuracy did not improve from 0.82476\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3920 - accuracy: 0.8232 - f1_score: 0.6869\n",
      "Epoch 7/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8251 - f1_score: 0.6873\n",
      "Epoch 7: accuracy improved from 0.82476 to 0.82510, saving model to ./625-batch_size625\\weight-improvement2-7-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3893 - accuracy: 0.8251 - f1_score: 0.6873\n",
      "Epoch 8/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8243 - f1_score: 0.6876\n",
      "Epoch 8: accuracy did not improve from 0.82510\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3901 - accuracy: 0.8243 - f1_score: 0.6876\n",
      "Epoch 9/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.8250 - f1_score: 0.6863\n",
      "Epoch 9: accuracy did not improve from 0.82510\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3905 - accuracy: 0.8250 - f1_score: 0.6863\n",
      "Epoch 10/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3899 - accuracy: 0.8248 - f1_score: 0.6869\n",
      "Epoch 10: accuracy did not improve from 0.82510\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3899 - accuracy: 0.8248 - f1_score: 0.6870\n",
      "Epoch 11/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8251 - f1_score: 0.6871\n",
      "Epoch 11: accuracy improved from 0.82510 to 0.82516, saving model to ./625-batch_size625\\weight-improvement2-11-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3895 - accuracy: 0.8252 - f1_score: 0.6872\n",
      "Epoch 12/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8255 - f1_score: 0.6871\n",
      "Epoch 12: accuracy improved from 0.82516 to 0.82552, saving model to ./625-batch_size625\\weight-improvement2-12-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3885 - accuracy: 0.8255 - f1_score: 0.6871\n",
      "Epoch 13/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8241 - f1_score: 0.6868\n",
      "Epoch 13: accuracy did not improve from 0.82552\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3914 - accuracy: 0.8241 - f1_score: 0.6867\n",
      "Epoch 14/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8243 - f1_score: 0.6863\n",
      "Epoch 14: accuracy did not improve from 0.82552\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3905 - accuracy: 0.8243 - f1_score: 0.6863\n",
      "Epoch 15/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8239 - f1_score: 0.6867\n",
      "Epoch 15: accuracy did not improve from 0.82552\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3904 - accuracy: 0.8239 - f1_score: 0.6866\n",
      "Epoch 16/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8252 - f1_score: 0.6864\n",
      "Epoch 16: accuracy did not improve from 0.82552\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3906 - accuracy: 0.8253 - f1_score: 0.6865\n",
      "Epoch 17/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8232 - f1_score: 0.6867\n",
      "Epoch 17: accuracy did not improve from 0.82552\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3907 - accuracy: 0.8234 - f1_score: 0.6869\n",
      "Epoch 18/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8256 - f1_score: 0.6877\n",
      "Epoch 18: accuracy improved from 0.82552 to 0.82557, saving model to ./625-batch_size625\\weight-improvement2-18-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3884 - accuracy: 0.8256 - f1_score: 0.6878\n",
      "Epoch 19/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8241 - f1_score: 0.6881\n",
      "Epoch 19: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3893 - accuracy: 0.8240 - f1_score: 0.6881\n",
      "Epoch 20/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.8234 - f1_score: 0.6875\n",
      "Epoch 20: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3909 - accuracy: 0.8234 - f1_score: 0.6875\n",
      "Epoch 21/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8231 - f1_score: 0.6860\n",
      "Epoch 21: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3923 - accuracy: 0.8232 - f1_score: 0.6860\n",
      "Epoch 22/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8250 - f1_score: 0.6866\n",
      "Epoch 22: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3913 - accuracy: 0.8250 - f1_score: 0.6865\n",
      "Epoch 23/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.8236 - f1_score: 0.6867\n",
      "Epoch 23: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3906 - accuracy: 0.8236 - f1_score: 0.6868\n",
      "Epoch 24/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3899 - accuracy: 0.8251 - f1_score: 0.6862\n",
      "Epoch 24: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3898 - accuracy: 0.8252 - f1_score: 0.6862\n",
      "Epoch 25/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3902 - accuracy: 0.8246 - f1_score: 0.6869\n",
      "Epoch 25: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3902 - accuracy: 0.8247 - f1_score: 0.6869\n",
      "Epoch 26/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8242 - f1_score: 0.6870\n",
      "Epoch 26: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3908 - accuracy: 0.8242 - f1_score: 0.6870\n",
      "Epoch 27/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8246 - f1_score: 0.6868\n",
      "Epoch 27: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3897 - accuracy: 0.8246 - f1_score: 0.6869\n",
      "Epoch 28/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8243 - f1_score: 0.6863\n",
      "Epoch 28: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3915 - accuracy: 0.8243 - f1_score: 0.6863\n",
      "Epoch 29/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8247 - f1_score: 0.6867\n",
      "Epoch 29: accuracy did not improve from 0.82557\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3890 - accuracy: 0.8247 - f1_score: 0.6868\n",
      "Epoch 30/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8263 - f1_score: 0.6872\n",
      "Epoch 30: accuracy improved from 0.82557 to 0.82625, saving model to ./625-batch_size625\\weight-improvement2-30-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3890 - accuracy: 0.8263 - f1_score: 0.6872\n",
      "Epoch 31/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8249 - f1_score: 0.6875\n",
      "Epoch 31: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3887 - accuracy: 0.8249 - f1_score: 0.6875\n",
      "Epoch 32/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8250 - f1_score: 0.6877\n",
      "Epoch 32: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3888 - accuracy: 0.8250 - f1_score: 0.6878\n",
      "Epoch 33/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3913 - accuracy: 0.8240 - f1_score: 0.6868\n",
      "Epoch 33: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3913 - accuracy: 0.8240 - f1_score: 0.6869\n",
      "Epoch 34/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8240 - f1_score: 0.6870\n",
      "Epoch 34: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3909 - accuracy: 0.8240 - f1_score: 0.6870\n",
      "Epoch 35/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8244 - f1_score: 0.6868\n",
      "Epoch 35: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3890 - accuracy: 0.8244 - f1_score: 0.6867\n",
      "Epoch 36/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.8247 - f1_score: 0.6870\n",
      "Epoch 36: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3904 - accuracy: 0.8247 - f1_score: 0.6870\n",
      "Epoch 37/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3919 - accuracy: 0.8237 - f1_score: 0.6858\n",
      "Epoch 37: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3920 - accuracy: 0.8237 - f1_score: 0.6858\n",
      "Epoch 38/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8249 - f1_score: 0.6870\n",
      "Epoch 38: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3895 - accuracy: 0.8248 - f1_score: 0.6870\n",
      "Epoch 39/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8237 - f1_score: 0.6866\n",
      "Epoch 39: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3908 - accuracy: 0.8237 - f1_score: 0.6865\n",
      "Epoch 40/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3952 - accuracy: 0.8229 - f1_score: 0.6840\n",
      "Epoch 40: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3951 - accuracy: 0.8230 - f1_score: 0.6841\n",
      "Epoch 41/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3933 - accuracy: 0.8225 - f1_score: 0.6852\n",
      "Epoch 41: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3932 - accuracy: 0.8226 - f1_score: 0.6851\n",
      "Epoch 42/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3949 - accuracy: 0.8220 - f1_score: 0.6851\n",
      "Epoch 42: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3948 - accuracy: 0.8220 - f1_score: 0.6851\n",
      "Epoch 43/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.8231 - f1_score: 0.6856\n",
      "Epoch 43: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3924 - accuracy: 0.8231 - f1_score: 0.6856\n",
      "Epoch 44/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8247 - f1_score: 0.6873\n",
      "Epoch 44: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3900 - accuracy: 0.8248 - f1_score: 0.6874\n",
      "Epoch 45/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8238 - f1_score: 0.6864\n",
      "Epoch 45: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3915 - accuracy: 0.8238 - f1_score: 0.6865\n",
      "Epoch 46/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8242 - f1_score: 0.6875\n",
      "Epoch 46: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3908 - accuracy: 0.8243 - f1_score: 0.6875\n",
      "Epoch 47/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3911 - accuracy: 0.8239 - f1_score: 0.6857\n",
      "Epoch 47: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3911 - accuracy: 0.8238 - f1_score: 0.6859\n",
      "Epoch 48/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 48: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3886 - accuracy: 0.8252 - f1_score: 0.6872\n",
      "Epoch 49/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8239 - f1_score: 0.6871\n",
      "Epoch 49: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3912 - accuracy: 0.8239 - f1_score: 0.6870\n",
      "Epoch 50/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8255 - f1_score: 0.6870\n",
      "Epoch 50: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3894 - accuracy: 0.8255 - f1_score: 0.6870\n",
      "Epoch 51/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8238 - f1_score: 0.6870\n",
      "Epoch 51: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3905 - accuracy: 0.8238 - f1_score: 0.6868\n",
      "Epoch 52/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8232 - f1_score: 0.6865\n",
      "Epoch 52: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3918 - accuracy: 0.8232 - f1_score: 0.6865\n",
      "Epoch 53/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8252 - f1_score: 0.6875\n",
      "Epoch 53: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3894 - accuracy: 0.8252 - f1_score: 0.6875\n",
      "Epoch 54/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8239 - f1_score: 0.6860\n",
      "Epoch 54: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3911 - accuracy: 0.8240 - f1_score: 0.6860\n",
      "Epoch 55/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8250 - f1_score: 0.6866\n",
      "Epoch 55: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3887 - accuracy: 0.8249 - f1_score: 0.6867\n",
      "Epoch 56/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3933 - accuracy: 0.8233 - f1_score: 0.6860\n",
      "Epoch 56: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3934 - accuracy: 0.8233 - f1_score: 0.6859\n",
      "Epoch 57/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8233 - f1_score: 0.6872\n",
      "Epoch 57: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3907 - accuracy: 0.8233 - f1_score: 0.6871\n",
      "Epoch 58/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3944 - accuracy: 0.8217 - f1_score: 0.6858\n",
      "Epoch 58: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3946 - accuracy: 0.8216 - f1_score: 0.6858\n",
      "Epoch 59/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3948 - accuracy: 0.8220 - f1_score: 0.6851\n",
      "Epoch 59: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3949 - accuracy: 0.8219 - f1_score: 0.6851\n",
      "Epoch 60/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8228 - f1_score: 0.6865\n",
      "Epoch 60: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3922 - accuracy: 0.8228 - f1_score: 0.6865\n",
      "Epoch 61/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3935 - accuracy: 0.8222 - f1_score: 0.6870\n",
      "Epoch 61: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3934 - accuracy: 0.8223 - f1_score: 0.6869\n",
      "Epoch 62/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8247 - f1_score: 0.6871\n",
      "Epoch 62: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3891 - accuracy: 0.8247 - f1_score: 0.6872\n",
      "Epoch 63/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 63: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3898 - accuracy: 0.8253 - f1_score: 0.6872\n",
      "Epoch 64/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8255 - f1_score: 0.6870\n",
      "Epoch 64: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3891 - accuracy: 0.8255 - f1_score: 0.6870\n",
      "Epoch 65/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3911 - accuracy: 0.8232 - f1_score: 0.6866\n",
      "Epoch 65: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3910 - accuracy: 0.8234 - f1_score: 0.6864\n",
      "Epoch 66/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3934 - accuracy: 0.8224 - f1_score: 0.6860\n",
      "Epoch 66: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3932 - accuracy: 0.8225 - f1_score: 0.6860\n",
      "Epoch 67/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3925 - accuracy: 0.8227 - f1_score: 0.6861\n",
      "Epoch 67: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3923 - accuracy: 0.8228 - f1_score: 0.6861\n",
      "Epoch 68/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.8234 - f1_score: 0.6867\n",
      "Epoch 68: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3915 - accuracy: 0.8234 - f1_score: 0.6867\n",
      "Epoch 69/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3934 - accuracy: 0.8216 - f1_score: 0.6857\n",
      "Epoch 69: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3934 - accuracy: 0.8216 - f1_score: 0.6857\n",
      "Epoch 70/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3942 - accuracy: 0.8223 - f1_score: 0.6850\n",
      "Epoch 70: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3942 - accuracy: 0.8222 - f1_score: 0.6850\n",
      "Epoch 71/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3913 - accuracy: 0.8235 - f1_score: 0.6857\n",
      "Epoch 71: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3913 - accuracy: 0.8235 - f1_score: 0.6859\n",
      "Epoch 72/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3926 - accuracy: 0.8237 - f1_score: 0.6861\n",
      "Epoch 72: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3925 - accuracy: 0.8237 - f1_score: 0.6861\n",
      "Epoch 73/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3956 - accuracy: 0.8208 - f1_score: 0.6862\n",
      "Epoch 73: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3957 - accuracy: 0.8207 - f1_score: 0.6861\n",
      "Epoch 74/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8236 - f1_score: 0.6866\n",
      "Epoch 74: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3923 - accuracy: 0.8235 - f1_score: 0.6866\n",
      "Epoch 75/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3941 - accuracy: 0.8212 - f1_score: 0.6866\n",
      "Epoch 75: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 5s 10ms/step - loss: 0.3940 - accuracy: 0.8213 - f1_score: 0.6866\n",
      "Epoch 76/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.8237 - f1_score: 0.6863\n",
      "Epoch 76: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3921 - accuracy: 0.8237 - f1_score: 0.6863\n",
      "Epoch 77/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8241 - f1_score: 0.6868\n",
      "Epoch 77: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3905 - accuracy: 0.8241 - f1_score: 0.6868\n",
      "Epoch 78/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.8230 - f1_score: 0.6860\n",
      "Epoch 78: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3921 - accuracy: 0.8231 - f1_score: 0.6860\n",
      "Epoch 79/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8238 - f1_score: 0.6862\n",
      "Epoch 79: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3911 - accuracy: 0.8237 - f1_score: 0.6862\n",
      "Epoch 80/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8232 - f1_score: 0.6857\n",
      "Epoch 80: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3924 - accuracy: 0.8232 - f1_score: 0.6857\n",
      "Epoch 81/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8245 - f1_score: 0.6872\n",
      "Epoch 81: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3897 - accuracy: 0.8242 - f1_score: 0.6870\n",
      "Epoch 82/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8238 - f1_score: 0.6875\n",
      "Epoch 82: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3902 - accuracy: 0.8237 - f1_score: 0.6874\n",
      "Epoch 83/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8238 - f1_score: 0.6878\n",
      "Epoch 83: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3898 - accuracy: 0.8236 - f1_score: 0.6877\n",
      "Epoch 84/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8231 - f1_score: 0.6875\n",
      "Epoch 84: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3903 - accuracy: 0.8232 - f1_score: 0.6876\n",
      "Epoch 85/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.8233 - f1_score: 0.6873\n",
      "Epoch 85: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3922 - accuracy: 0.8233 - f1_score: 0.6874\n",
      "Epoch 86/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3932 - accuracy: 0.8223 - f1_score: 0.6852\n",
      "Epoch 86: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3932 - accuracy: 0.8223 - f1_score: 0.6852\n",
      "Epoch 87/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8234 - f1_score: 0.6859\n",
      "Epoch 87: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3917 - accuracy: 0.8234 - f1_score: 0.6860\n",
      "Epoch 88/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8241 - f1_score: 0.6867\n",
      "Epoch 88: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8241 - f1_score: 0.6866\n",
      "Epoch 89/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8246 - f1_score: 0.6872\n",
      "Epoch 89: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3886 - accuracy: 0.8247 - f1_score: 0.6872\n",
      "Epoch 90/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8242 - f1_score: 0.6870\n",
      "Epoch 90: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3903 - accuracy: 0.8242 - f1_score: 0.6870\n",
      "Epoch 91/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8255 - f1_score: 0.6869\n",
      "Epoch 91: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3884 - accuracy: 0.8255 - f1_score: 0.6868\n",
      "Epoch 92/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8245 - f1_score: 0.6871\n",
      "Epoch 92: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3906 - accuracy: 0.8246 - f1_score: 0.6870\n",
      "Epoch 93/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3902 - accuracy: 0.8241 - f1_score: 0.6875\n",
      "Epoch 93: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3903 - accuracy: 0.8241 - f1_score: 0.6874\n",
      "Epoch 94/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8250 - f1_score: 0.6876\n",
      "Epoch 94: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3896 - accuracy: 0.8251 - f1_score: 0.6876\n",
      "Epoch 95/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8238 - f1_score: 0.6854\n",
      "Epoch 95: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3922 - accuracy: 0.8238 - f1_score: 0.6854\n",
      "Epoch 96/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8232 - f1_score: 0.6859\n",
      "Epoch 96: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3915 - accuracy: 0.8232 - f1_score: 0.6859\n",
      "Epoch 97/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3920 - accuracy: 0.8235 - f1_score: 0.6857\n",
      "Epoch 97: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3920 - accuracy: 0.8235 - f1_score: 0.6857\n",
      "Epoch 98/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8262 - f1_score: 0.6867\n",
      "Epoch 98: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3888 - accuracy: 0.8262 - f1_score: 0.6867\n",
      "Epoch 99/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8236 - f1_score: 0.6871\n",
      "Epoch 99: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3911 - accuracy: 0.8236 - f1_score: 0.6871\n",
      "Epoch 100/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8253 - f1_score: 0.6868\n",
      "Epoch 100: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3897 - accuracy: 0.8253 - f1_score: 0.6868\n",
      "Epoch 101/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8241 - f1_score: 0.6862\n",
      "Epoch 101: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3914 - accuracy: 0.8242 - f1_score: 0.6862\n",
      "Epoch 102/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.8223 - f1_score: 0.6868\n",
      "Epoch 102: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3934 - accuracy: 0.8223 - f1_score: 0.6870\n",
      "Epoch 103/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.8242 - f1_score: 0.6871\n",
      "Epoch 103: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3905 - accuracy: 0.8242 - f1_score: 0.6870\n",
      "Epoch 104/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8237 - f1_score: 0.6870\n",
      "Epoch 104: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3914 - accuracy: 0.8237 - f1_score: 0.6869\n",
      "Epoch 105/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8250 - f1_score: 0.6880\n",
      "Epoch 105: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3883 - accuracy: 0.8250 - f1_score: 0.6880\n",
      "Epoch 106/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8250 - f1_score: 0.6875\n",
      "Epoch 106: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3891 - accuracy: 0.8251 - f1_score: 0.6875\n",
      "Epoch 107/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8232 - f1_score: 0.6879\n",
      "Epoch 107: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3908 - accuracy: 0.8232 - f1_score: 0.6879\n",
      "Epoch 108/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.8246 - f1_score: 0.6867\n",
      "Epoch 108: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3904 - accuracy: 0.8246 - f1_score: 0.6867\n",
      "Epoch 109/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8256 - f1_score: 0.6875\n",
      "Epoch 109: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3885 - accuracy: 0.8256 - f1_score: 0.6876\n",
      "Epoch 110/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8239 - f1_score: 0.6875\n",
      "Epoch 110: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3905 - accuracy: 0.8239 - f1_score: 0.6874\n",
      "Epoch 111/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8242 - f1_score: 0.6862\n",
      "Epoch 111: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3915 - accuracy: 0.8242 - f1_score: 0.6862\n",
      "Epoch 112/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3921 - accuracy: 0.8235 - f1_score: 0.6871\n",
      "Epoch 112: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3923 - accuracy: 0.8234 - f1_score: 0.6872\n",
      "Epoch 113/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8244 - f1_score: 0.6874\n",
      "Epoch 113: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3893 - accuracy: 0.8245 - f1_score: 0.6874\n",
      "Epoch 114/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.8257 - f1_score: 0.6868\n",
      "Epoch 114: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8257 - f1_score: 0.6868\n",
      "Epoch 115/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8256 - f1_score: 0.6872\n",
      "Epoch 115: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8256 - f1_score: 0.6871\n",
      "Epoch 116/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3922 - accuracy: 0.8229 - f1_score: 0.6864\n",
      "Epoch 116: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3922 - accuracy: 0.8229 - f1_score: 0.6864\n",
      "Epoch 117/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8240 - f1_score: 0.6868\n",
      "Epoch 117: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3909 - accuracy: 0.8240 - f1_score: 0.6868\n",
      "Epoch 118/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3884 - accuracy: 0.8253 - f1_score: 0.6878\n",
      "Epoch 118: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3884 - accuracy: 0.8253 - f1_score: 0.6878\n",
      "Epoch 119/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8240 - f1_score: 0.6863\n",
      "Epoch 119: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3910 - accuracy: 0.8240 - f1_score: 0.6863\n",
      "Epoch 120/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8251 - f1_score: 0.6865\n",
      "Epoch 120: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3892 - accuracy: 0.8252 - f1_score: 0.6865\n",
      "Epoch 121/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8254 - f1_score: 0.6867\n",
      "Epoch 121: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3898 - accuracy: 0.8253 - f1_score: 0.6867\n",
      "Epoch 122/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8253 - f1_score: 0.6881\n",
      "Epoch 122: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3881 - accuracy: 0.8253 - f1_score: 0.6880\n",
      "Epoch 123/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8236 - f1_score: 0.6854\n",
      "Epoch 123: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3905 - accuracy: 0.8238 - f1_score: 0.6855\n",
      "Epoch 124/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8242 - f1_score: 0.6870\n",
      "Epoch 124: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3896 - accuracy: 0.8242 - f1_score: 0.6871\n",
      "Epoch 125/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3931 - accuracy: 0.8225 - f1_score: 0.6862\n",
      "Epoch 125: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3932 - accuracy: 0.8225 - f1_score: 0.6862\n",
      "Epoch 126/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8242 - f1_score: 0.6874\n",
      "Epoch 126: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3900 - accuracy: 0.8241 - f1_score: 0.6873\n",
      "Epoch 127/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8249 - f1_score: 0.6873\n",
      "Epoch 127: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3897 - accuracy: 0.8249 - f1_score: 0.6872\n",
      "Epoch 128/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8242 - f1_score: 0.6860\n",
      "Epoch 128: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3912 - accuracy: 0.8243 - f1_score: 0.6860\n",
      "Epoch 129/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3902 - accuracy: 0.8251 - f1_score: 0.6864\n",
      "Epoch 129: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3900 - accuracy: 0.8252 - f1_score: 0.6863\n",
      "Epoch 130/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3899 - accuracy: 0.8252 - f1_score: 0.6869\n",
      "Epoch 130: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3900 - accuracy: 0.8251 - f1_score: 0.6868\n",
      "Epoch 131/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8242 - f1_score: 0.6873\n",
      "Epoch 131: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8242 - f1_score: 0.6872\n",
      "Epoch 132/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8240 - f1_score: 0.6855\n",
      "Epoch 132: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3915 - accuracy: 0.8240 - f1_score: 0.6856\n",
      "Epoch 133/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8236 - f1_score: 0.6860\n",
      "Epoch 133: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3918 - accuracy: 0.8236 - f1_score: 0.6860\n",
      "Epoch 134/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.8233 - f1_score: 0.6863\n",
      "Epoch 134: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3915 - accuracy: 0.8233 - f1_score: 0.6863\n",
      "Epoch 135/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8233 - f1_score: 0.6866\n",
      "Epoch 135: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3920 - accuracy: 0.8233 - f1_score: 0.6866\n",
      "Epoch 136/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8235 - f1_score: 0.6867\n",
      "Epoch 136: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3927 - accuracy: 0.8235 - f1_score: 0.6867\n",
      "Epoch 137/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8241 - f1_score: 0.6871\n",
      "Epoch 137: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3906 - accuracy: 0.8242 - f1_score: 0.6871\n",
      "Epoch 138/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8260 - f1_score: 0.6860\n",
      "Epoch 138: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8260 - f1_score: 0.6860\n",
      "Epoch 139/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8250 - f1_score: 0.6870\n",
      "Epoch 139: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3896 - accuracy: 0.8249 - f1_score: 0.6870\n",
      "Epoch 140/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8249 - f1_score: 0.6875\n",
      "Epoch 140: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3893 - accuracy: 0.8248 - f1_score: 0.6875\n",
      "Epoch 141/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8240 - f1_score: 0.6867\n",
      "Epoch 141: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3900 - accuracy: 0.8240 - f1_score: 0.6867\n",
      "Epoch 142/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8246 - f1_score: 0.6862\n",
      "Epoch 142: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3901 - accuracy: 0.8245 - f1_score: 0.6863\n",
      "Epoch 143/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8240 - f1_score: 0.6863\n",
      "Epoch 143: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3900 - accuracy: 0.8240 - f1_score: 0.6864\n",
      "Epoch 144/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8250 - f1_score: 0.6872\n",
      "Epoch 144: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3892 - accuracy: 0.8250 - f1_score: 0.6872\n",
      "Epoch 145/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8251 - f1_score: 0.6864\n",
      "Epoch 145: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3894 - accuracy: 0.8252 - f1_score: 0.6866\n",
      "Epoch 146/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8251 - f1_score: 0.6868\n",
      "Epoch 146: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3891 - accuracy: 0.8251 - f1_score: 0.6868\n",
      "Epoch 147/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8245 - f1_score: 0.6866\n",
      "Epoch 147: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3890 - accuracy: 0.8245 - f1_score: 0.6868\n",
      "Epoch 148/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3889 - accuracy: 0.8259 - f1_score: 0.6868\n",
      "Epoch 148: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3889 - accuracy: 0.8259 - f1_score: 0.6868\n",
      "Epoch 149/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8254 - f1_score: 0.6870\n",
      "Epoch 149: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8255 - f1_score: 0.6870\n",
      "Epoch 150/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8254 - f1_score: 0.6873\n",
      "Epoch 150: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8254 - f1_score: 0.6873\n",
      "Epoch 151/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8257 - f1_score: 0.6864\n",
      "Epoch 151: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3897 - accuracy: 0.8257 - f1_score: 0.6865\n",
      "Epoch 152/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8243 - f1_score: 0.6864\n",
      "Epoch 152: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3897 - accuracy: 0.8243 - f1_score: 0.6864\n",
      "Epoch 153/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8249 - f1_score: 0.6864\n",
      "Epoch 153: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3895 - accuracy: 0.8250 - f1_score: 0.6863\n",
      "Epoch 154/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8249 - f1_score: 0.6873\n",
      "Epoch 154: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8250 - f1_score: 0.6873\n",
      "Epoch 155/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8238 - f1_score: 0.6863\n",
      "Epoch 155: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3911 - accuracy: 0.8238 - f1_score: 0.6863\n",
      "Epoch 156/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8253 - f1_score: 0.6870\n",
      "Epoch 156: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3885 - accuracy: 0.8251 - f1_score: 0.6871\n",
      "Epoch 157/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8256 - f1_score: 0.6866\n",
      "Epoch 157: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3898 - accuracy: 0.8255 - f1_score: 0.6865\n",
      "Epoch 158/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8255 - f1_score: 0.6864\n",
      "Epoch 158: accuracy did not improve from 0.82625\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3883 - accuracy: 0.8254 - f1_score: 0.6864\n",
      "Epoch 159/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8265 - f1_score: 0.6872\n",
      "Epoch 159: accuracy improved from 0.82625 to 0.82648, saving model to ./625-batch_size625\\weight-improvement2-159-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3875 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 160/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8256 - f1_score: 0.6865\n",
      "Epoch 160: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3881 - accuracy: 0.8256 - f1_score: 0.6865\n",
      "Epoch 161/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.8231 - f1_score: 0.6867\n",
      "Epoch 161: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3923 - accuracy: 0.8230 - f1_score: 0.6867\n",
      "Epoch 162/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3889 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 162: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 163/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8259 - f1_score: 0.6872\n",
      "Epoch 163: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8257 - f1_score: 0.6872\n",
      "Epoch 164/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8247 - f1_score: 0.6867\n",
      "Epoch 164: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3894 - accuracy: 0.8247 - f1_score: 0.6868\n",
      "Epoch 165/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8239 - f1_score: 0.6870\n",
      "Epoch 165: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3906 - accuracy: 0.8240 - f1_score: 0.6870\n",
      "Epoch 166/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8251 - f1_score: 0.6873\n",
      "Epoch 166: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3892 - accuracy: 0.8251 - f1_score: 0.6874\n",
      "Epoch 167/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8242 - f1_score: 0.6872\n",
      "Epoch 167: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3903 - accuracy: 0.8240 - f1_score: 0.6870\n",
      "Epoch 168/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8252 - f1_score: 0.6875\n",
      "Epoch 168: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8253 - f1_score: 0.6876\n",
      "Epoch 169/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3878 - accuracy: 0.8259 - f1_score: 0.6876\n",
      "Epoch 169: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8259 - f1_score: 0.6876\n",
      "Epoch 170/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8245 - f1_score: 0.6880\n",
      "Epoch 170: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3891 - accuracy: 0.8245 - f1_score: 0.6880\n",
      "Epoch 171/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3932 - accuracy: 0.8224 - f1_score: 0.6865\n",
      "Epoch 171: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3932 - accuracy: 0.8224 - f1_score: 0.6866\n",
      "Epoch 172/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8243 - f1_score: 0.6882\n",
      "Epoch 172: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3897 - accuracy: 0.8242 - f1_score: 0.6883\n",
      "Epoch 173/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3910 - accuracy: 0.8241 - f1_score: 0.6874\n",
      "Epoch 173: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3910 - accuracy: 0.8241 - f1_score: 0.6874\n",
      "Epoch 174/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8240 - f1_score: 0.6871\n",
      "Epoch 174: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3902 - accuracy: 0.8240 - f1_score: 0.6871\n",
      "Epoch 175/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 175: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3880 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 176/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 176: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8260 - f1_score: 0.6867\n",
      "Epoch 177/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8248 - f1_score: 0.6872\n",
      "Epoch 177: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8248 - f1_score: 0.6872\n",
      "Epoch 178/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8233 - f1_score: 0.6858\n",
      "Epoch 178: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3923 - accuracy: 0.8232 - f1_score: 0.6859\n",
      "Epoch 179/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8251 - f1_score: 0.6864\n",
      "Epoch 179: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3895 - accuracy: 0.8251 - f1_score: 0.6866\n",
      "Epoch 180/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8253 - f1_score: 0.6871\n",
      "Epoch 180: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8253 - f1_score: 0.6871\n",
      "Epoch 181/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8241 - f1_score: 0.6882\n",
      "Epoch 181: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3887 - accuracy: 0.8241 - f1_score: 0.6882\n",
      "Epoch 182/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8219 - f1_score: 0.6877\n",
      "Epoch 182: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3913 - accuracy: 0.8220 - f1_score: 0.6877\n",
      "Epoch 183/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8234 - f1_score: 0.6871\n",
      "Epoch 183: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3923 - accuracy: 0.8234 - f1_score: 0.6872\n",
      "Epoch 184/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8246 - f1_score: 0.6863\n",
      "Epoch 184: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3894 - accuracy: 0.8246 - f1_score: 0.6863\n",
      "Epoch 185/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8250 - f1_score: 0.6868\n",
      "Epoch 185: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3889 - accuracy: 0.8250 - f1_score: 0.6869\n",
      "Epoch 186/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8250 - f1_score: 0.6871\n",
      "Epoch 186: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8249 - f1_score: 0.6872\n",
      "Epoch 187/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3917 - accuracy: 0.8230 - f1_score: 0.6865\n",
      "Epoch 187: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3918 - accuracy: 0.8231 - f1_score: 0.6865\n",
      "Epoch 188/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8249 - f1_score: 0.6862\n",
      "Epoch 188: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3889 - accuracy: 0.8249 - f1_score: 0.6862\n",
      "Epoch 189/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8240 - f1_score: 0.6867\n",
      "Epoch 189: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3895 - accuracy: 0.8240 - f1_score: 0.6867\n",
      "Epoch 190/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8252 - f1_score: 0.6868\n",
      "Epoch 190: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3900 - accuracy: 0.8252 - f1_score: 0.6867\n",
      "Epoch 191/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8260 - f1_score: 0.6869\n",
      "Epoch 191: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6869\n",
      "Epoch 192/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8257 - f1_score: 0.6874\n",
      "Epoch 192: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8256 - f1_score: 0.6876\n",
      "Epoch 193/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8261 - f1_score: 0.6877\n",
      "Epoch 193: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3871 - accuracy: 0.8261 - f1_score: 0.6878\n",
      "Epoch 194/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8238 - f1_score: 0.6860\n",
      "Epoch 194: accuracy did not improve from 0.82648\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3912 - accuracy: 0.8238 - f1_score: 0.6859\n",
      "Epoch 195/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 195: accuracy improved from 0.82648 to 0.82688, saving model to ./625-batch_size625\\weight-improvement2-195-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 196/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8251 - f1_score: 0.6865\n",
      "Epoch 196: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3882 - accuracy: 0.8251 - f1_score: 0.6865\n",
      "Epoch 197/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3902 - accuracy: 0.8248 - f1_score: 0.6861\n",
      "Epoch 197: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3900 - accuracy: 0.8249 - f1_score: 0.6861\n",
      "Epoch 198/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8248 - f1_score: 0.6873\n",
      "Epoch 198: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3885 - accuracy: 0.8249 - f1_score: 0.6872\n",
      "Epoch 199/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8265 - f1_score: 0.6880\n",
      "Epoch 199: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8264 - f1_score: 0.6880\n",
      "Epoch 200/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8253 - f1_score: 0.6872\n",
      "Epoch 200: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8253 - f1_score: 0.6872\n",
      "Epoch 201/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8255 - f1_score: 0.6876\n",
      "Epoch 201: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8255 - f1_score: 0.6876\n",
      "Epoch 202/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8256 - f1_score: 0.6867\n",
      "Epoch 202: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8256 - f1_score: 0.6868\n",
      "Epoch 203/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8238 - f1_score: 0.6868\n",
      "Epoch 203: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3906 - accuracy: 0.8239 - f1_score: 0.6868\n",
      "Epoch 204/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8256 - f1_score: 0.6869\n",
      "Epoch 204: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3891 - accuracy: 0.8255 - f1_score: 0.6868\n",
      "Epoch 205/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.8239 - f1_score: 0.6868\n",
      "Epoch 205: accuracy did not improve from 0.82688\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3897 - accuracy: 0.8239 - f1_score: 0.6868\n",
      "Epoch 206/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 206: accuracy improved from 0.82688 to 0.82760, saving model to ./625-batch_size625\\weight-improvement2-206-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 207/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8262 - f1_score: 0.6875\n",
      "Epoch 207: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8262 - f1_score: 0.6876\n",
      "Epoch 208/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8251 - f1_score: 0.6868\n",
      "Epoch 208: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8252 - f1_score: 0.6869\n",
      "Epoch 209/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8251 - f1_score: 0.6869\n",
      "Epoch 209: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3890 - accuracy: 0.8251 - f1_score: 0.6869\n",
      "Epoch 210/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8266 - f1_score: 0.6879\n",
      "Epoch 210: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8266 - f1_score: 0.6879\n",
      "Epoch 211/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8262 - f1_score: 0.6865\n",
      "Epoch 211: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8261 - f1_score: 0.6866\n",
      "Epoch 212/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8257 - f1_score: 0.6869\n",
      "Epoch 212: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3882 - accuracy: 0.8256 - f1_score: 0.6870\n",
      "Epoch 213/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8251 - f1_score: 0.6883\n",
      "Epoch 213: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3888 - accuracy: 0.8252 - f1_score: 0.6883\n",
      "Epoch 214/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 214: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8258 - f1_score: 0.6870\n",
      "Epoch 215/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8244 - f1_score: 0.6869\n",
      "Epoch 215: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3902 - accuracy: 0.8245 - f1_score: 0.6869\n",
      "Epoch 216/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8245 - f1_score: 0.6871\n",
      "Epoch 216: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8245 - f1_score: 0.6872\n",
      "Epoch 217/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3899 - accuracy: 0.8247 - f1_score: 0.6863\n",
      "Epoch 217: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3901 - accuracy: 0.8247 - f1_score: 0.6863\n",
      "Epoch 218/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8256 - f1_score: 0.6873\n",
      "Epoch 218: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8258 - f1_score: 0.6874\n",
      "Epoch 219/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8259 - f1_score: 0.6872\n",
      "Epoch 219: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3886 - accuracy: 0.8258 - f1_score: 0.6871\n",
      "Epoch 220/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8259 - f1_score: 0.6864\n",
      "Epoch 220: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3894 - accuracy: 0.8258 - f1_score: 0.6864\n",
      "Epoch 221/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8254 - f1_score: 0.6860\n",
      "Epoch 221: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3896 - accuracy: 0.8255 - f1_score: 0.6860\n",
      "Epoch 222/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8263 - f1_score: 0.6876\n",
      "Epoch 222: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8263 - f1_score: 0.6876\n",
      "Epoch 223/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8256 - f1_score: 0.6868\n",
      "Epoch 223: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8257 - f1_score: 0.6867\n",
      "Epoch 224/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.8249 - f1_score: 0.6865\n",
      "Epoch 224: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3898 - accuracy: 0.8249 - f1_score: 0.6865\n",
      "Epoch 225/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8243 - f1_score: 0.6870\n",
      "Epoch 225: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8243 - f1_score: 0.6871\n",
      "Epoch 226/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8261 - f1_score: 0.6873\n",
      "Epoch 226: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8262 - f1_score: 0.6873\n",
      "Epoch 227/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.8236 - f1_score: 0.6864\n",
      "Epoch 227: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3922 - accuracy: 0.8237 - f1_score: 0.6863\n",
      "Epoch 228/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8265 - f1_score: 0.6878\n",
      "Epoch 228: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3872 - accuracy: 0.8265 - f1_score: 0.6877\n",
      "Epoch 229/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8248 - f1_score: 0.6873\n",
      "Epoch 229: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3892 - accuracy: 0.8248 - f1_score: 0.6874\n",
      "Epoch 230/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8242 - f1_score: 0.6867\n",
      "Epoch 230: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3908 - accuracy: 0.8242 - f1_score: 0.6867\n",
      "Epoch 231/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8241 - f1_score: 0.6863\n",
      "Epoch 231: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3912 - accuracy: 0.8241 - f1_score: 0.6863\n",
      "Epoch 232/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3899 - accuracy: 0.8239 - f1_score: 0.6864\n",
      "Epoch 232: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3899 - accuracy: 0.8239 - f1_score: 0.6864\n",
      "Epoch 233/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8261 - f1_score: 0.6871\n",
      "Epoch 233: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3882 - accuracy: 0.8260 - f1_score: 0.6870\n",
      "Epoch 234/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8261 - f1_score: 0.6864\n",
      "Epoch 234: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8261 - f1_score: 0.6864\n",
      "Epoch 235/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8250 - f1_score: 0.6872\n",
      "Epoch 235: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8250 - f1_score: 0.6873\n",
      "Epoch 236/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8247 - f1_score: 0.6864\n",
      "Epoch 236: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3896 - accuracy: 0.8246 - f1_score: 0.6864\n",
      "Epoch 237/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8260 - f1_score: 0.6859\n",
      "Epoch 237: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3885 - accuracy: 0.8261 - f1_score: 0.6860\n",
      "Epoch 238/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8261 - f1_score: 0.6864\n",
      "Epoch 238: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3867 - accuracy: 0.8261 - f1_score: 0.6864\n",
      "Epoch 239/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3913 - accuracy: 0.8243 - f1_score: 0.6856\n",
      "Epoch 239: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3912 - accuracy: 0.8243 - f1_score: 0.6857\n",
      "Epoch 240/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8249 - f1_score: 0.6872\n",
      "Epoch 240: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3891 - accuracy: 0.8249 - f1_score: 0.6873\n",
      "Epoch 241/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3919 - accuracy: 0.8244 - f1_score: 0.6846\n",
      "Epoch 241: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3919 - accuracy: 0.8244 - f1_score: 0.6847\n",
      "Epoch 242/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8250 - f1_score: 0.6866\n",
      "Epoch 242: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3893 - accuracy: 0.8250 - f1_score: 0.6867\n",
      "Epoch 243/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8255 - f1_score: 0.6863\n",
      "Epoch 243: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3894 - accuracy: 0.8254 - f1_score: 0.6863\n",
      "Epoch 244/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8247 - f1_score: 0.6868\n",
      "Epoch 244: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3901 - accuracy: 0.8247 - f1_score: 0.6866\n",
      "Epoch 245/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8253 - f1_score: 0.6855\n",
      "Epoch 245: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3902 - accuracy: 0.8253 - f1_score: 0.6855\n",
      "Epoch 246/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8265 - f1_score: 0.6866\n",
      "Epoch 246: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8265 - f1_score: 0.6866\n",
      "Epoch 247/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8258 - f1_score: 0.6863\n",
      "Epoch 247: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3884 - accuracy: 0.8259 - f1_score: 0.6863\n",
      "Epoch 248/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8257 - f1_score: 0.6860\n",
      "Epoch 248: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8257 - f1_score: 0.6861\n",
      "Epoch 249/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8260 - f1_score: 0.6861\n",
      "Epoch 249: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3885 - accuracy: 0.8260 - f1_score: 0.6862\n",
      "Epoch 250/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8269 - f1_score: 0.6868\n",
      "Epoch 250: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3868 - accuracy: 0.8269 - f1_score: 0.6868\n",
      "Epoch 251/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8247 - f1_score: 0.6879\n",
      "Epoch 251: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8246 - f1_score: 0.6878\n",
      "Epoch 252/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8258 - f1_score: 0.6868\n",
      "Epoch 252: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3891 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 253/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8264 - f1_score: 0.6871\n",
      "Epoch 253: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3869 - accuracy: 0.8263 - f1_score: 0.6872\n",
      "Epoch 254/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6874\n",
      "Epoch 254: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8273 - f1_score: 0.6874\n",
      "Epoch 255/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 255: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 256/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8260 - f1_score: 0.6878\n",
      "Epoch 256: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3867 - accuracy: 0.8259 - f1_score: 0.6878\n",
      "Epoch 257/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8252 - f1_score: 0.6874\n",
      "Epoch 257: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8252 - f1_score: 0.6875\n",
      "Epoch 258/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8251 - f1_score: 0.6878\n",
      "Epoch 258: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3885 - accuracy: 0.8250 - f1_score: 0.6878\n",
      "Epoch 259/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8257 - f1_score: 0.6879\n",
      "Epoch 259: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8257 - f1_score: 0.6879\n",
      "Epoch 260/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8249 - f1_score: 0.6882\n",
      "Epoch 260: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3888 - accuracy: 0.8248 - f1_score: 0.6881\n",
      "Epoch 261/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8253 - f1_score: 0.6878\n",
      "Epoch 261: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3874 - accuracy: 0.8253 - f1_score: 0.6879\n",
      "Epoch 262/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8258 - f1_score: 0.6874\n",
      "Epoch 262: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3882 - accuracy: 0.8258 - f1_score: 0.6873\n",
      "Epoch 263/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8265 - f1_score: 0.6878\n",
      "Epoch 263: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8265 - f1_score: 0.6878\n",
      "Epoch 264/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.8262 - f1_score: 0.6860\n",
      "Epoch 264: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8262 - f1_score: 0.6860\n",
      "Epoch 265/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8262 - f1_score: 0.6859\n",
      "Epoch 265: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3886 - accuracy: 0.8263 - f1_score: 0.6860\n",
      "Epoch 266/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8260 - f1_score: 0.6871\n",
      "Epoch 266: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8259 - f1_score: 0.6870\n",
      "Epoch 267/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8253 - f1_score: 0.6879\n",
      "Epoch 267: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3881 - accuracy: 0.8253 - f1_score: 0.6879\n",
      "Epoch 268/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8246 - f1_score: 0.6870\n",
      "Epoch 268: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3889 - accuracy: 0.8246 - f1_score: 0.6871\n",
      "Epoch 269/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8255 - f1_score: 0.6864\n",
      "Epoch 269: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6865\n",
      "Epoch 270/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8255 - f1_score: 0.6863\n",
      "Epoch 270: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8257 - f1_score: 0.6864\n",
      "Epoch 271/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8255 - f1_score: 0.6865\n",
      "Epoch 271: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3891 - accuracy: 0.8255 - f1_score: 0.6865\n",
      "Epoch 272/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8236 - f1_score: 0.6862\n",
      "Epoch 272: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3899 - accuracy: 0.8237 - f1_score: 0.6863\n",
      "Epoch 273/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8246 - f1_score: 0.6867\n",
      "Epoch 273: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8245 - f1_score: 0.6866\n",
      "Epoch 274/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8262 - f1_score: 0.6875\n",
      "Epoch 274: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3878 - accuracy: 0.8262 - f1_score: 0.6876\n",
      "Epoch 275/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8253 - f1_score: 0.6869\n",
      "Epoch 275: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3882 - accuracy: 0.8252 - f1_score: 0.6869\n",
      "Epoch 276/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8233 - f1_score: 0.6870\n",
      "Epoch 276: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3909 - accuracy: 0.8233 - f1_score: 0.6870\n",
      "Epoch 277/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8241 - f1_score: 0.6881\n",
      "Epoch 277: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3900 - accuracy: 0.8241 - f1_score: 0.6881\n",
      "Epoch 278/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8256 - f1_score: 0.6873\n",
      "Epoch 278: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3891 - accuracy: 0.8256 - f1_score: 0.6873\n",
      "Epoch 279/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8264 - f1_score: 0.6876\n",
      "Epoch 279: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3866 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 280/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 280: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 281/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8258 - f1_score: 0.6876\n",
      "Epoch 281: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3877 - accuracy: 0.8257 - f1_score: 0.6874\n",
      "Epoch 282/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 282: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 283/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8262 - f1_score: 0.6864\n",
      "Epoch 283: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3874 - accuracy: 0.8261 - f1_score: 0.6864\n",
      "Epoch 284/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8259 - f1_score: 0.6866\n",
      "Epoch 284: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3877 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 285/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8251 - f1_score: 0.6863\n",
      "Epoch 285: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8252 - f1_score: 0.6863\n",
      "Epoch 286/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8259 - f1_score: 0.6859\n",
      "Epoch 286: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3885 - accuracy: 0.8259 - f1_score: 0.6859\n",
      "Epoch 287/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8257 - f1_score: 0.6864\n",
      "Epoch 287: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8257 - f1_score: 0.6863\n",
      "Epoch 288/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 288: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8264 - f1_score: 0.6872\n",
      "Epoch 289/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8274 - f1_score: 0.6873\n",
      "Epoch 289: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6874\n",
      "Epoch 290/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 290: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3869 - accuracy: 0.8263 - f1_score: 0.6874\n",
      "Epoch 291/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8265 - f1_score: 0.6866\n",
      "Epoch 291: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3877 - accuracy: 0.8265 - f1_score: 0.6866\n",
      "Epoch 292/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8272 - f1_score: 0.6866\n",
      "Epoch 292: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3874 - accuracy: 0.8271 - f1_score: 0.6866\n",
      "Epoch 293/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8260 - f1_score: 0.6865\n",
      "Epoch 293: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3870 - accuracy: 0.8261 - f1_score: 0.6866\n",
      "Epoch 294/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8256 - f1_score: 0.6864\n",
      "Epoch 294: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8257 - f1_score: 0.6864\n",
      "Epoch 295/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8260 - f1_score: 0.6871\n",
      "Epoch 295: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 296/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8268 - f1_score: 0.6887\n",
      "Epoch 296: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8270 - f1_score: 0.6886\n",
      "Epoch 297/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 297: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 298/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8253 - f1_score: 0.6876\n",
      "Epoch 298: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8252 - f1_score: 0.6877\n",
      "Epoch 299/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8243 - f1_score: 0.6867\n",
      "Epoch 299: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3891 - accuracy: 0.8243 - f1_score: 0.6866\n",
      "Epoch 300/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.8262 - f1_score: 0.6869\n",
      "Epoch 300: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3874 - accuracy: 0.8262 - f1_score: 0.6869\n",
      "Epoch 301/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8265 - f1_score: 0.6870\n",
      "Epoch 301: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3873 - accuracy: 0.8266 - f1_score: 0.6871\n",
      "Epoch 302/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 302: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 303/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8259 - f1_score: 0.6859\n",
      "Epoch 303: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8260 - f1_score: 0.6858\n",
      "Epoch 304/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 304: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 305/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 305: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3876 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 306/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8273 - f1_score: 0.6877\n",
      "Epoch 306: accuracy did not improve from 0.82760\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8273 - f1_score: 0.6877\n",
      "Epoch 307/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 307: accuracy improved from 0.82760 to 0.82761, saving model to ./625-batch_size625\\weight-improvement2-307-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8276 - f1_score: 0.6869\n",
      "Epoch 308/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8263 - f1_score: 0.6863\n",
      "Epoch 308: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8263 - f1_score: 0.6864\n",
      "Epoch 309/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8248 - f1_score: 0.6866\n",
      "Epoch 309: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3892 - accuracy: 0.8248 - f1_score: 0.6866\n",
      "Epoch 310/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8241 - f1_score: 0.6870\n",
      "Epoch 310: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8242 - f1_score: 0.6871\n",
      "Epoch 311/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 311: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 312/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.8261 - f1_score: 0.6881\n",
      "Epoch 312: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8261 - f1_score: 0.6881\n",
      "Epoch 313/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8259 - f1_score: 0.6876\n",
      "Epoch 313: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3880 - accuracy: 0.8259 - f1_score: 0.6875\n",
      "Epoch 314/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8258 - f1_score: 0.6877\n",
      "Epoch 314: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3887 - accuracy: 0.8258 - f1_score: 0.6877\n",
      "Epoch 315/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8257 - f1_score: 0.6878\n",
      "Epoch 315: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3881 - accuracy: 0.8257 - f1_score: 0.6880\n",
      "Epoch 316/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6888\n",
      "Epoch 316: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6887\n",
      "Epoch 317/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8260 - f1_score: 0.6880\n",
      "Epoch 317: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8260 - f1_score: 0.6881\n",
      "Epoch 318/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8256 - f1_score: 0.6870\n",
      "Epoch 318: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8257 - f1_score: 0.6871\n",
      "Epoch 319/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8265 - f1_score: 0.6870\n",
      "Epoch 319: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8264 - f1_score: 0.6870\n",
      "Epoch 320/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8256 - f1_score: 0.6869\n",
      "Epoch 320: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8256 - f1_score: 0.6868\n",
      "Epoch 321/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 321: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3875 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 322/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8260 - f1_score: 0.6871\n",
      "Epoch 322: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 323/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8242 - f1_score: 0.6863\n",
      "Epoch 323: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3912 - accuracy: 0.8241 - f1_score: 0.6863\n",
      "Epoch 324/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8252 - f1_score: 0.6872\n",
      "Epoch 324: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8254 - f1_score: 0.6873\n",
      "Epoch 325/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8260 - f1_score: 0.6870\n",
      "Epoch 325: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3891 - accuracy: 0.8260 - f1_score: 0.6870\n",
      "Epoch 326/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8251 - f1_score: 0.6866\n",
      "Epoch 326: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8250 - f1_score: 0.6865\n",
      "Epoch 327/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8250 - f1_score: 0.6872\n",
      "Epoch 327: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8250 - f1_score: 0.6872\n",
      "Epoch 328/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8261 - f1_score: 0.6866\n",
      "Epoch 328: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8261 - f1_score: 0.6866\n",
      "Epoch 329/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8253 - f1_score: 0.6867\n",
      "Epoch 329: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3898 - accuracy: 0.8253 - f1_score: 0.6867\n",
      "Epoch 330/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8262 - f1_score: 0.6880\n",
      "Epoch 330: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3875 - accuracy: 0.8262 - f1_score: 0.6878\n",
      "Epoch 331/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 331: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3882 - accuracy: 0.8259 - f1_score: 0.6873\n",
      "Epoch 332/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8260 - f1_score: 0.6875\n",
      "Epoch 332: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3876 - accuracy: 0.8260 - f1_score: 0.6875\n",
      "Epoch 333/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8271 - f1_score: 0.6879\n",
      "Epoch 333: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3867 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 334/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8266 - f1_score: 0.6879\n",
      "Epoch 334: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8265 - f1_score: 0.6879\n",
      "Epoch 335/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8268 - f1_score: 0.6881\n",
      "Epoch 335: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8268 - f1_score: 0.6881\n",
      "Epoch 336/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 336: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 337/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.8251 - f1_score: 0.6876\n",
      "Epoch 337: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3897 - accuracy: 0.8251 - f1_score: 0.6876\n",
      "Epoch 338/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8258 - f1_score: 0.6873\n",
      "Epoch 338: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8258 - f1_score: 0.6875\n",
      "Epoch 339/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8256 - f1_score: 0.6874\n",
      "Epoch 339: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8255 - f1_score: 0.6874\n",
      "Epoch 340/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8251 - f1_score: 0.6868\n",
      "Epoch 340: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3897 - accuracy: 0.8251 - f1_score: 0.6867\n",
      "Epoch 341/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8257 - f1_score: 0.6873\n",
      "Epoch 341: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8256 - f1_score: 0.6872\n",
      "Epoch 342/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8261 - f1_score: 0.6874\n",
      "Epoch 342: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8261 - f1_score: 0.6874\n",
      "Epoch 343/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 343: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8252 - f1_score: 0.6869\n",
      "Epoch 344/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8255 - f1_score: 0.6863\n",
      "Epoch 344: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3885 - accuracy: 0.8255 - f1_score: 0.6863\n",
      "Epoch 345/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 345: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3867 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 346/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8258 - f1_score: 0.6873\n",
      "Epoch 346: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3878 - accuracy: 0.8258 - f1_score: 0.6872\n",
      "Epoch 347/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.8263 - f1_score: 0.6869\n",
      "Epoch 347: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8263 - f1_score: 0.6869\n",
      "Epoch 348/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8252 - f1_score: 0.6873\n",
      "Epoch 348: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8251 - f1_score: 0.6874\n",
      "Epoch 349/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8263 - f1_score: 0.6864\n",
      "Epoch 349: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8262 - f1_score: 0.6865\n",
      "Epoch 350/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8257 - f1_score: 0.6868\n",
      "Epoch 350: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8256 - f1_score: 0.6868\n",
      "Epoch 351/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8241 - f1_score: 0.6861\n",
      "Epoch 351: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3918 - accuracy: 0.8241 - f1_score: 0.6861\n",
      "Epoch 352/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8249 - f1_score: 0.6873\n",
      "Epoch 352: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3893 - accuracy: 0.8249 - f1_score: 0.6873\n",
      "Epoch 353/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8258 - f1_score: 0.6875\n",
      "Epoch 353: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3877 - accuracy: 0.8258 - f1_score: 0.6874\n",
      "Epoch 354/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8260 - f1_score: 0.6868\n",
      "Epoch 354: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3892 - accuracy: 0.8261 - f1_score: 0.6868\n",
      "Epoch 355/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8261 - f1_score: 0.6862\n",
      "Epoch 355: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8261 - f1_score: 0.6862\n",
      "Epoch 356/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8262 - f1_score: 0.6876\n",
      "Epoch 356: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8262 - f1_score: 0.6874\n",
      "Epoch 357/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 357: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 358/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8252 - f1_score: 0.6861\n",
      "Epoch 358: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3893 - accuracy: 0.8253 - f1_score: 0.6861\n",
      "Epoch 359/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8259 - f1_score: 0.6862\n",
      "Epoch 359: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3879 - accuracy: 0.8260 - f1_score: 0.6864\n",
      "Epoch 360/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8261 - f1_score: 0.6870\n",
      "Epoch 360: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8261 - f1_score: 0.6869\n",
      "Epoch 361/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8267 - f1_score: 0.6872\n",
      "Epoch 361: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3865 - accuracy: 0.8266 - f1_score: 0.6872\n",
      "Epoch 362/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8261 - f1_score: 0.6885\n",
      "Epoch 362: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8261 - f1_score: 0.6885\n",
      "Epoch 363/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8263 - f1_score: 0.6883\n",
      "Epoch 363: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3868 - accuracy: 0.8263 - f1_score: 0.6883\n",
      "Epoch 364/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.8250 - f1_score: 0.6874\n",
      "Epoch 364: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3892 - accuracy: 0.8250 - f1_score: 0.6874\n",
      "Epoch 365/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8261 - f1_score: 0.6860\n",
      "Epoch 365: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8261 - f1_score: 0.6860\n",
      "Epoch 366/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8237 - f1_score: 0.6856\n",
      "Epoch 366: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3900 - accuracy: 0.8238 - f1_score: 0.6857\n",
      "Epoch 367/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8246 - f1_score: 0.6868\n",
      "Epoch 367: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8246 - f1_score: 0.6868\n",
      "Epoch 368/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8256 - f1_score: 0.6864\n",
      "Epoch 368: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3885 - accuracy: 0.8256 - f1_score: 0.6864\n",
      "Epoch 369/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8249 - f1_score: 0.6862\n",
      "Epoch 369: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3893 - accuracy: 0.8248 - f1_score: 0.6861\n",
      "Epoch 370/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8261 - f1_score: 0.6884\n",
      "Epoch 370: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8260 - f1_score: 0.6882\n",
      "Epoch 371/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8260 - f1_score: 0.6882\n",
      "Epoch 371: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8260 - f1_score: 0.6882\n",
      "Epoch 372/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8264 - f1_score: 0.6871\n",
      "Epoch 372: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8263 - f1_score: 0.6870\n",
      "Epoch 373/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3919 - accuracy: 0.8240 - f1_score: 0.6858\n",
      "Epoch 373: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3921 - accuracy: 0.8240 - f1_score: 0.6859\n",
      "Epoch 374/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8248 - f1_score: 0.6870\n",
      "Epoch 374: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3894 - accuracy: 0.8249 - f1_score: 0.6870\n",
      "Epoch 375/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 375: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3887 - accuracy: 0.8261 - f1_score: 0.6872\n",
      "Epoch 376/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8255 - f1_score: 0.6877\n",
      "Epoch 376: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3881 - accuracy: 0.8255 - f1_score: 0.6877\n",
      "Epoch 377/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8240 - f1_score: 0.6872\n",
      "Epoch 377: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3908 - accuracy: 0.8239 - f1_score: 0.6872\n",
      "Epoch 378/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8258 - f1_score: 0.6871\n",
      "Epoch 378: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8258 - f1_score: 0.6870\n",
      "Epoch 379/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8261 - f1_score: 0.6876\n",
      "Epoch 379: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6875\n",
      "Epoch 380/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8272 - f1_score: 0.6867\n",
      "Epoch 380: accuracy did not improve from 0.82761\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3871 - accuracy: 0.8272 - f1_score: 0.6868\n",
      "Epoch 381/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6877\n",
      "Epoch 381: accuracy improved from 0.82761 to 0.82780, saving model to ./625-batch_size625\\weight-improvement2-381-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6877\n",
      "Epoch 382/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8261 - f1_score: 0.6867\n",
      "Epoch 382: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8261 - f1_score: 0.6867\n",
      "Epoch 383/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8249 - f1_score: 0.6870\n",
      "Epoch 383: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8249 - f1_score: 0.6870\n",
      "Epoch 384/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8245 - f1_score: 0.6876\n",
      "Epoch 384: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3897 - accuracy: 0.8245 - f1_score: 0.6878\n",
      "Epoch 385/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8257 - f1_score: 0.6885\n",
      "Epoch 385: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8257 - f1_score: 0.6886\n",
      "Epoch 386/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8246 - f1_score: 0.6874\n",
      "Epoch 386: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8246 - f1_score: 0.6874\n",
      "Epoch 387/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8248 - f1_score: 0.6869\n",
      "Epoch 387: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3897 - accuracy: 0.8248 - f1_score: 0.6870\n",
      "Epoch 388/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8269 - f1_score: 0.6879\n",
      "Epoch 388: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6879\n",
      "Epoch 389/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8253 - f1_score: 0.6874\n",
      "Epoch 389: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8253 - f1_score: 0.6874\n",
      "Epoch 390/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6871\n",
      "Epoch 390: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6871\n",
      "Epoch 391/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8251 - f1_score: 0.6871\n",
      "Epoch 391: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3894 - accuracy: 0.8251 - f1_score: 0.6871\n",
      "Epoch 392/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8252 - f1_score: 0.6876\n",
      "Epoch 392: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8252 - f1_score: 0.6876\n",
      "Epoch 393/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8257 - f1_score: 0.6879\n",
      "Epoch 393: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3877 - accuracy: 0.8257 - f1_score: 0.6879\n",
      "Epoch 394/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 394: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 395/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8263 - f1_score: 0.6868\n",
      "Epoch 395: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8263 - f1_score: 0.6869\n",
      "Epoch 396/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8249 - f1_score: 0.6872\n",
      "Epoch 396: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3886 - accuracy: 0.8248 - f1_score: 0.6873\n",
      "Epoch 397/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8261 - f1_score: 0.6871\n",
      "Epoch 397: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8261 - f1_score: 0.6871\n",
      "Epoch 398/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8263 - f1_score: 0.6879\n",
      "Epoch 398: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8263 - f1_score: 0.6878\n",
      "Epoch 399/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8272 - f1_score: 0.6882\n",
      "Epoch 399: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3848 - accuracy: 0.8272 - f1_score: 0.6883\n",
      "Epoch 400/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8257 - f1_score: 0.6874\n",
      "Epoch 400: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3879 - accuracy: 0.8257 - f1_score: 0.6874\n",
      "Epoch 401/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8253 - f1_score: 0.6859\n",
      "Epoch 401: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3894 - accuracy: 0.8253 - f1_score: 0.6859\n",
      "Epoch 402/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8260 - f1_score: 0.6873\n",
      "Epoch 402: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8259 - f1_score: 0.6871\n",
      "Epoch 403/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8276 - f1_score: 0.6873\n",
      "Epoch 403: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 404/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8248 - f1_score: 0.6869\n",
      "Epoch 404: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3885 - accuracy: 0.8247 - f1_score: 0.6871\n",
      "Epoch 405/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8253 - f1_score: 0.6879\n",
      "Epoch 405: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3882 - accuracy: 0.8253 - f1_score: 0.6878\n",
      "Epoch 406/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8256 - f1_score: 0.6883\n",
      "Epoch 406: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3876 - accuracy: 0.8256 - f1_score: 0.6883\n",
      "Epoch 407/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 407: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 408/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 408: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8266 - f1_score: 0.6869\n",
      "Epoch 409/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8255 - f1_score: 0.6871\n",
      "Epoch 409: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8255 - f1_score: 0.6871\n",
      "Epoch 410/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8251 - f1_score: 0.6854\n",
      "Epoch 410: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3903 - accuracy: 0.8251 - f1_score: 0.6854\n",
      "Epoch 411/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8259 - f1_score: 0.6855\n",
      "Epoch 411: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3897 - accuracy: 0.8259 - f1_score: 0.6856\n",
      "Epoch 412/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8260 - f1_score: 0.6861\n",
      "Epoch 412: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3883 - accuracy: 0.8260 - f1_score: 0.6861\n",
      "Epoch 413/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8252 - f1_score: 0.6867\n",
      "Epoch 413: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8251 - f1_score: 0.6868\n",
      "Epoch 414/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8254 - f1_score: 0.6872\n",
      "Epoch 414: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3876 - accuracy: 0.8254 - f1_score: 0.6872\n",
      "Epoch 415/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8261 - f1_score: 0.6868\n",
      "Epoch 415: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8261 - f1_score: 0.6869\n",
      "Epoch 416/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 416: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8269 - f1_score: 0.6866\n",
      "Epoch 417/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8265 - f1_score: 0.6875\n",
      "Epoch 417: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3873 - accuracy: 0.8266 - f1_score: 0.6875\n",
      "Epoch 418/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8254 - f1_score: 0.6871\n",
      "Epoch 418: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8254 - f1_score: 0.6870\n",
      "Epoch 419/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8263 - f1_score: 0.6869\n",
      "Epoch 419: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3884 - accuracy: 0.8262 - f1_score: 0.6869\n",
      "Epoch 420/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8264 - f1_score: 0.6868\n",
      "Epoch 420: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3888 - accuracy: 0.8264 - f1_score: 0.6869\n",
      "Epoch 421/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8275 - f1_score: 0.6872\n",
      "Epoch 421: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 422/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8261 - f1_score: 0.6866\n",
      "Epoch 422: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8261 - f1_score: 0.6867\n",
      "Epoch 423/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8266 - f1_score: 0.6867\n",
      "Epoch 423: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8266 - f1_score: 0.6868\n",
      "Epoch 424/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8270 - f1_score: 0.6869\n",
      "Epoch 424: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 425/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 425: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 426/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6882\n",
      "Epoch 426: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6883\n",
      "Epoch 427/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6871\n",
      "Epoch 427: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6871\n",
      "Epoch 428/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 428: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3871 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 429/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 429: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 430/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8256 - f1_score: 0.6859\n",
      "Epoch 430: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3894 - accuracy: 0.8255 - f1_score: 0.6859\n",
      "Epoch 431/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8263 - f1_score: 0.6864\n",
      "Epoch 431: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8263 - f1_score: 0.6865\n",
      "Epoch 432/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8253 - f1_score: 0.6870\n",
      "Epoch 432: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8253 - f1_score: 0.6871\n",
      "Epoch 433/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8266 - f1_score: 0.6876\n",
      "Epoch 433: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3857 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 434/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 434: accuracy did not improve from 0.82780\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 435/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 435: accuracy improved from 0.82780 to 0.82822, saving model to ./625-batch_size625\\weight-improvement2-435-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 436/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8263 - f1_score: 0.6874\n",
      "Epoch 436: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 437/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 437: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 438/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6884\n",
      "Epoch 438: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6885\n",
      "Epoch 439/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8259 - f1_score: 0.6875\n",
      "Epoch 439: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6876\n",
      "Epoch 440/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8259 - f1_score: 0.6879\n",
      "Epoch 440: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8259 - f1_score: 0.6878\n",
      "Epoch 441/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8266 - f1_score: 0.6877\n",
      "Epoch 441: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8266 - f1_score: 0.6877\n",
      "Epoch 442/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8251 - f1_score: 0.6874\n",
      "Epoch 442: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3880 - accuracy: 0.8253 - f1_score: 0.6875\n",
      "Epoch 443/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 443: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 444/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8238 - f1_score: 0.6862\n",
      "Epoch 444: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3905 - accuracy: 0.8238 - f1_score: 0.6860\n",
      "Epoch 445/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8259 - f1_score: 0.6864\n",
      "Epoch 445: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8259 - f1_score: 0.6864\n",
      "Epoch 446/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8266 - f1_score: 0.6872\n",
      "Epoch 446: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8267 - f1_score: 0.6872\n",
      "Epoch 447/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 447: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 448/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8254 - f1_score: 0.6872\n",
      "Epoch 448: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8254 - f1_score: 0.6872\n",
      "Epoch 449/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8264 - f1_score: 0.6882\n",
      "Epoch 449: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6882\n",
      "Epoch 450/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8249 - f1_score: 0.6873\n",
      "Epoch 450: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3894 - accuracy: 0.8249 - f1_score: 0.6873\n",
      "Epoch 451/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8257 - f1_score: 0.6861\n",
      "Epoch 451: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3896 - accuracy: 0.8257 - f1_score: 0.6861\n",
      "Epoch 452/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8269 - f1_score: 0.6868\n",
      "Epoch 452: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8269 - f1_score: 0.6867\n",
      "Epoch 453/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8259 - f1_score: 0.6878\n",
      "Epoch 453: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8259 - f1_score: 0.6878\n",
      "Epoch 454/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 454: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 455/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8259 - f1_score: 0.6875\n",
      "Epoch 455: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3883 - accuracy: 0.8258 - f1_score: 0.6873\n",
      "Epoch 456/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8235 - f1_score: 0.6869\n",
      "Epoch 456: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3919 - accuracy: 0.8234 - f1_score: 0.6869\n",
      "Epoch 457/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8241 - f1_score: 0.6883\n",
      "Epoch 457: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3896 - accuracy: 0.8241 - f1_score: 0.6882\n",
      "Epoch 458/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6881\n",
      "Epoch 458: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6881\n",
      "Epoch 459/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 459: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8264 - f1_score: 0.6870\n",
      "Epoch 460/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8274 - f1_score: 0.6885\n",
      "Epoch 460: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8274 - f1_score: 0.6884\n",
      "Epoch 461/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.8258 - f1_score: 0.6876\n",
      "Epoch 461: accuracy did not improve from 0.82822\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8258 - f1_score: 0.6876\n",
      "Epoch 462/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 462: accuracy improved from 0.82822 to 0.82827, saving model to ./625-batch_size625\\weight-improvement2-462-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 463/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8267 - f1_score: 0.6877\n",
      "Epoch 463: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8267 - f1_score: 0.6878\n",
      "Epoch 464/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8250 - f1_score: 0.6871\n",
      "Epoch 464: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3885 - accuracy: 0.8251 - f1_score: 0.6872\n",
      "Epoch 465/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8241 - f1_score: 0.6876\n",
      "Epoch 465: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3898 - accuracy: 0.8241 - f1_score: 0.6874\n",
      "Epoch 466/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8248 - f1_score: 0.6864\n",
      "Epoch 466: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8248 - f1_score: 0.6865\n",
      "Epoch 467/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8256 - f1_score: 0.6860\n",
      "Epoch 467: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8255 - f1_score: 0.6860\n",
      "Epoch 468/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.8262 - f1_score: 0.6856\n",
      "Epoch 468: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8262 - f1_score: 0.6856\n",
      "Epoch 469/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8239 - f1_score: 0.6859\n",
      "Epoch 469: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3906 - accuracy: 0.8239 - f1_score: 0.6858\n",
      "Epoch 470/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6879\n",
      "Epoch 470: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6879\n",
      "Epoch 471/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8271 - f1_score: 0.6884\n",
      "Epoch 471: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8270 - f1_score: 0.6882\n",
      "Epoch 472/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8251 - f1_score: 0.6873\n",
      "Epoch 472: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8251 - f1_score: 0.6873\n",
      "Epoch 473/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 473: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 474/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8254 - f1_score: 0.6879\n",
      "Epoch 474: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8253 - f1_score: 0.6879\n",
      "Epoch 475/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8263 - f1_score: 0.6875\n",
      "Epoch 475: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3883 - accuracy: 0.8263 - f1_score: 0.6875\n",
      "Epoch 476/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.8251 - f1_score: 0.6867\n",
      "Epoch 476: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8251 - f1_score: 0.6867\n",
      "Epoch 477/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8263 - f1_score: 0.6870\n",
      "Epoch 477: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3868 - accuracy: 0.8263 - f1_score: 0.6870\n",
      "Epoch 478/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 478: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3863 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 479/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8267 - f1_score: 0.6881\n",
      "Epoch 479: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3864 - accuracy: 0.8266 - f1_score: 0.6881\n",
      "Epoch 480/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8260 - f1_score: 0.6870\n",
      "Epoch 480: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8260 - f1_score: 0.6870\n",
      "Epoch 481/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 481: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 482/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8259 - f1_score: 0.6872\n",
      "Epoch 482: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8260 - f1_score: 0.6873\n",
      "Epoch 483/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8267 - f1_score: 0.6887\n",
      "Epoch 483: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8267 - f1_score: 0.6889\n",
      "Epoch 484/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8255 - f1_score: 0.6887\n",
      "Epoch 484: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8255 - f1_score: 0.6888\n",
      "Epoch 485/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8257 - f1_score: 0.6880\n",
      "Epoch 485: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8257 - f1_score: 0.6879\n",
      "Epoch 486/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6880\n",
      "Epoch 486: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6879\n",
      "Epoch 487/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8268 - f1_score: 0.6872\n",
      "Epoch 487: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 488/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8256 - f1_score: 0.6870\n",
      "Epoch 488: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3897 - accuracy: 0.8256 - f1_score: 0.6870\n",
      "Epoch 489/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8248 - f1_score: 0.6879\n",
      "Epoch 489: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8248 - f1_score: 0.6879\n",
      "Epoch 490/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8255 - f1_score: 0.6867\n",
      "Epoch 490: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3894 - accuracy: 0.8256 - f1_score: 0.6866\n",
      "Epoch 491/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8265 - f1_score: 0.6864\n",
      "Epoch 491: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8264 - f1_score: 0.6864\n",
      "Epoch 492/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 492: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3890 - accuracy: 0.8260 - f1_score: 0.6868\n",
      "Epoch 493/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8262 - f1_score: 0.6868\n",
      "Epoch 493: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8262 - f1_score: 0.6869\n",
      "Epoch 494/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6866\n",
      "Epoch 494: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8263 - f1_score: 0.6866\n",
      "Epoch 495/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 495: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 496/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8266 - f1_score: 0.6877\n",
      "Epoch 496: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8267 - f1_score: 0.6877\n",
      "Epoch 497/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 497: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8263 - f1_score: 0.6874\n",
      "Epoch 498/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8251 - f1_score: 0.6864\n",
      "Epoch 498: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8251 - f1_score: 0.6865\n",
      "Epoch 499/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8254 - f1_score: 0.6862\n",
      "Epoch 499: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8255 - f1_score: 0.6862\n",
      "Epoch 500/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 500: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 501/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8264 - f1_score: 0.6874\n",
      "Epoch 501: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8265 - f1_score: 0.6874\n",
      "Epoch 502/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 502: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8264 - f1_score: 0.6877\n",
      "Epoch 503/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8243 - f1_score: 0.6875\n",
      "Epoch 503: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3903 - accuracy: 0.8243 - f1_score: 0.6874\n",
      "Epoch 504/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8250 - f1_score: 0.6876\n",
      "Epoch 504: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3879 - accuracy: 0.8249 - f1_score: 0.6877\n",
      "Epoch 505/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8249 - f1_score: 0.6867\n",
      "Epoch 505: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3893 - accuracy: 0.8250 - f1_score: 0.6868\n",
      "Epoch 506/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8253 - f1_score: 0.6868\n",
      "Epoch 506: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8251 - f1_score: 0.6868\n",
      "Epoch 507/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8264 - f1_score: 0.6874\n",
      "Epoch 507: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 508/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8270 - f1_score: 0.6866\n",
      "Epoch 508: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3870 - accuracy: 0.8270 - f1_score: 0.6866\n",
      "Epoch 509/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6869\n",
      "Epoch 509: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6869\n",
      "Epoch 510/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 510: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8271 - f1_score: 0.6871\n",
      "Epoch 511/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8277 - f1_score: 0.6886\n",
      "Epoch 511: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 512/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8269 - f1_score: 0.6876\n",
      "Epoch 512: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8269 - f1_score: 0.6877\n",
      "Epoch 513/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8271 - f1_score: 0.6882\n",
      "Epoch 513: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8271 - f1_score: 0.6882\n",
      "Epoch 514/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6866\n",
      "Epoch 514: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8263 - f1_score: 0.6866\n",
      "Epoch 515/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8251 - f1_score: 0.6866\n",
      "Epoch 515: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8251 - f1_score: 0.6866\n",
      "Epoch 516/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.8251 - f1_score: 0.6864\n",
      "Epoch 516: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8251 - f1_score: 0.6864\n",
      "Epoch 517/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8268 - f1_score: 0.6873\n",
      "Epoch 517: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8269 - f1_score: 0.6874\n",
      "Epoch 518/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6866\n",
      "Epoch 518: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6865\n",
      "Epoch 519/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6867\n",
      "Epoch 519: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6867\n",
      "Epoch 520/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 520: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 521/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6871\n",
      "Epoch 521: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 522/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8266 - f1_score: 0.6869\n",
      "Epoch 522: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3866 - accuracy: 0.8266 - f1_score: 0.6869\n",
      "Epoch 523/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8277 - f1_score: 0.6878\n",
      "Epoch 523: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 524/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 524: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8258 - f1_score: 0.6870\n",
      "Epoch 525/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8263 - f1_score: 0.6864\n",
      "Epoch 525: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6865\n",
      "Epoch 526/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8259 - f1_score: 0.6873\n",
      "Epoch 526: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8260 - f1_score: 0.6873\n",
      "Epoch 527/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8247 - f1_score: 0.6862\n",
      "Epoch 527: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3893 - accuracy: 0.8247 - f1_score: 0.6862\n",
      "Epoch 528/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8266 - f1_score: 0.6876\n",
      "Epoch 528: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8267 - f1_score: 0.6876\n",
      "Epoch 529/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 529: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8275 - f1_score: 0.6879\n",
      "Epoch 530/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8264 - f1_score: 0.6879\n",
      "Epoch 530: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8264 - f1_score: 0.6879\n",
      "Epoch 531/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 531: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 532/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 532: accuracy did not improve from 0.82827\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8272 - f1_score: 0.6873\n",
      "Epoch 533/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8284 - f1_score: 0.6866\n",
      "Epoch 533: accuracy improved from 0.82827 to 0.82841, saving model to ./625-batch_size625\\weight-improvement2-533-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8284 - f1_score: 0.6866\n",
      "Epoch 534/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 534: accuracy did not improve from 0.82841\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 535/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8273 - f1_score: 0.6880\n",
      "Epoch 535: accuracy did not improve from 0.82841\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8273 - f1_score: 0.6880\n",
      "Epoch 536/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8284 - f1_score: 0.6890\n",
      "Epoch 536: accuracy improved from 0.82841 to 0.82847, saving model to ./625-batch_size625\\weight-improvement2-536-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3841 - accuracy: 0.8285 - f1_score: 0.6891\n",
      "Epoch 537/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8261 - f1_score: 0.6869\n",
      "Epoch 537: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8261 - f1_score: 0.6869\n",
      "Epoch 538/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8257 - f1_score: 0.6860\n",
      "Epoch 538: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3898 - accuracy: 0.8259 - f1_score: 0.6861\n",
      "Epoch 539/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 539: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 540/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6883\n",
      "Epoch 540: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6883\n",
      "Epoch 541/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8256 - f1_score: 0.6875\n",
      "Epoch 541: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8256 - f1_score: 0.6875\n",
      "Epoch 542/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8259 - f1_score: 0.6880\n",
      "Epoch 542: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8259 - f1_score: 0.6880\n",
      "Epoch 543/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 543: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 544/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8243 - f1_score: 0.6869\n",
      "Epoch 544: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3904 - accuracy: 0.8243 - f1_score: 0.6869\n",
      "Epoch 545/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8269 - f1_score: 0.6868\n",
      "Epoch 545: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8269 - f1_score: 0.6868\n",
      "Epoch 546/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 546: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 547/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8255 - f1_score: 0.6866\n",
      "Epoch 547: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8255 - f1_score: 0.6866\n",
      "Epoch 548/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8262 - f1_score: 0.6867\n",
      "Epoch 548: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3873 - accuracy: 0.8263 - f1_score: 0.6866\n",
      "Epoch 549/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8258 - f1_score: 0.6870\n",
      "Epoch 549: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8258 - f1_score: 0.6872\n",
      "Epoch 550/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8255 - f1_score: 0.6878\n",
      "Epoch 550: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3875 - accuracy: 0.8255 - f1_score: 0.6877\n",
      "Epoch 551/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8266 - f1_score: 0.6868\n",
      "Epoch 551: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8266 - f1_score: 0.6869\n",
      "Epoch 552/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8251 - f1_score: 0.6869\n",
      "Epoch 552: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3899 - accuracy: 0.8251 - f1_score: 0.6868\n",
      "Epoch 553/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8261 - f1_score: 0.6871\n",
      "Epoch 553: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8261 - f1_score: 0.6868\n",
      "Epoch 554/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8261 - f1_score: 0.6869\n",
      "Epoch 554: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8260 - f1_score: 0.6870\n",
      "Epoch 555/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 555: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 556/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.8246 - f1_score: 0.6869\n",
      "Epoch 556: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3905 - accuracy: 0.8246 - f1_score: 0.6869\n",
      "Epoch 557/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3916 - accuracy: 0.8237 - f1_score: 0.6869\n",
      "Epoch 557: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3916 - accuracy: 0.8237 - f1_score: 0.6869\n",
      "Epoch 558/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 558: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6872\n",
      "Epoch 559/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8265 - f1_score: 0.6870\n",
      "Epoch 559: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 560/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6873\n",
      "Epoch 560: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 561/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 561: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8270 - f1_score: 0.6869\n",
      "Epoch 562/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8267 - f1_score: 0.6878\n",
      "Epoch 562: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8266 - f1_score: 0.6878\n",
      "Epoch 563/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6887\n",
      "Epoch 563: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8267 - f1_score: 0.6887\n",
      "Epoch 564/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 564: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6876\n",
      "Epoch 565/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 565: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8269 - f1_score: 0.6867\n",
      "Epoch 566/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 566: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3845 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 567/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 567: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 568/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8258 - f1_score: 0.6866\n",
      "Epoch 568: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3885 - accuracy: 0.8258 - f1_score: 0.6866\n",
      "Epoch 569/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8264 - f1_score: 0.6882\n",
      "Epoch 569: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8264 - f1_score: 0.6882\n",
      "Epoch 570/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8260 - f1_score: 0.6864\n",
      "Epoch 570: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3891 - accuracy: 0.8260 - f1_score: 0.6864\n",
      "Epoch 571/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8255 - f1_score: 0.6859\n",
      "Epoch 571: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8255 - f1_score: 0.6859\n",
      "Epoch 572/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8270 - f1_score: 0.6861\n",
      "Epoch 572: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3878 - accuracy: 0.8270 - f1_score: 0.6860\n",
      "Epoch 573/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8262 - f1_score: 0.6860\n",
      "Epoch 573: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6861\n",
      "Epoch 574/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6869\n",
      "Epoch 574: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8259 - f1_score: 0.6868\n",
      "Epoch 575/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8257 - f1_score: 0.6865\n",
      "Epoch 575: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8258 - f1_score: 0.6865\n",
      "Epoch 576/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8257 - f1_score: 0.6867\n",
      "Epoch 576: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3882 - accuracy: 0.8257 - f1_score: 0.6867\n",
      "Epoch 577/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8253 - f1_score: 0.6867\n",
      "Epoch 577: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3890 - accuracy: 0.8253 - f1_score: 0.6867\n",
      "Epoch 578/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8257 - f1_score: 0.6866\n",
      "Epoch 578: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3894 - accuracy: 0.8257 - f1_score: 0.6866\n",
      "Epoch 579/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8250 - f1_score: 0.6873\n",
      "Epoch 579: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3893 - accuracy: 0.8250 - f1_score: 0.6873\n",
      "Epoch 580/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6864\n",
      "Epoch 580: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6864\n",
      "Epoch 581/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3921 - accuracy: 0.8243 - f1_score: 0.6856\n",
      "Epoch 581: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3921 - accuracy: 0.8243 - f1_score: 0.6856\n",
      "Epoch 582/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8249 - f1_score: 0.6848\n",
      "Epoch 582: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3897 - accuracy: 0.8249 - f1_score: 0.6848\n",
      "Epoch 583/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 583: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3870 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 584/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8253 - f1_score: 0.6865\n",
      "Epoch 584: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8253 - f1_score: 0.6865\n",
      "Epoch 585/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8262 - f1_score: 0.6872\n",
      "Epoch 585: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3870 - accuracy: 0.8262 - f1_score: 0.6872\n",
      "Epoch 586/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8264 - f1_score: 0.6867\n",
      "Epoch 586: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8264 - f1_score: 0.6866\n",
      "Epoch 587/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8260 - f1_score: 0.6869\n",
      "Epoch 587: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8261 - f1_score: 0.6870\n",
      "Epoch 588/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8263 - f1_score: 0.6872\n",
      "Epoch 588: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3871 - accuracy: 0.8263 - f1_score: 0.6872\n",
      "Epoch 589/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 589: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3864 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 590/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 590: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8267 - f1_score: 0.6868\n",
      "Epoch 591/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8266 - f1_score: 0.6871\n",
      "Epoch 591: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 592/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8265 - f1_score: 0.6865\n",
      "Epoch 592: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8265 - f1_score: 0.6865\n",
      "Epoch 593/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 593: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 594/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8284 - f1_score: 0.6866\n",
      "Epoch 594: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8284 - f1_score: 0.6866\n",
      "Epoch 595/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 595: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 596/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8256 - f1_score: 0.6861\n",
      "Epoch 596: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8256 - f1_score: 0.6861\n",
      "Epoch 597/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8259 - f1_score: 0.6857\n",
      "Epoch 597: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3887 - accuracy: 0.8259 - f1_score: 0.6857\n",
      "Epoch 598/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8253 - f1_score: 0.6863\n",
      "Epoch 598: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8253 - f1_score: 0.6862\n",
      "Epoch 599/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8256 - f1_score: 0.6868\n",
      "Epoch 599: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8256 - f1_score: 0.6869\n",
      "Epoch 600/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8261 - f1_score: 0.6859\n",
      "Epoch 600: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3885 - accuracy: 0.8262 - f1_score: 0.6860\n",
      "Epoch 601/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8249 - f1_score: 0.6869\n",
      "Epoch 601: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3896 - accuracy: 0.8248 - f1_score: 0.6869\n",
      "Epoch 602/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8256 - f1_score: 0.6869\n",
      "Epoch 602: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8257 - f1_score: 0.6870\n",
      "Epoch 603/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 603: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 604/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 604: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 605/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.8261 - f1_score: 0.6862\n",
      "Epoch 605: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8261 - f1_score: 0.6862\n",
      "Epoch 606/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 606: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 607/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8255 - f1_score: 0.6873\n",
      "Epoch 607: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8256 - f1_score: 0.6874\n",
      "Epoch 608/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8259 - f1_score: 0.6865\n",
      "Epoch 608: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8259 - f1_score: 0.6864\n",
      "Epoch 609/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8263 - f1_score: 0.6870\n",
      "Epoch 609: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8263 - f1_score: 0.6870\n",
      "Epoch 610/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8256 - f1_score: 0.6863\n",
      "Epoch 610: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8256 - f1_score: 0.6864\n",
      "Epoch 611/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8257 - f1_score: 0.6872\n",
      "Epoch 611: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8258 - f1_score: 0.6872\n",
      "Epoch 612/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8252 - f1_score: 0.6859\n",
      "Epoch 612: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3894 - accuracy: 0.8252 - f1_score: 0.6859\n",
      "Epoch 613/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8276 - f1_score: 0.6868\n",
      "Epoch 613: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 614/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8278 - f1_score: 0.6867\n",
      "Epoch 614: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8278 - f1_score: 0.6867\n",
      "Epoch 615/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8272 - f1_score: 0.6858\n",
      "Epoch 615: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8273 - f1_score: 0.6859\n",
      "Epoch 616/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 616: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 617/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8260 - f1_score: 0.6876\n",
      "Epoch 617: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8260 - f1_score: 0.6876\n",
      "Epoch 618/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6868\n",
      "Epoch 618: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8264 - f1_score: 0.6867\n",
      "Epoch 619/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8250 - f1_score: 0.6869\n",
      "Epoch 619: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8251 - f1_score: 0.6870\n",
      "Epoch 620/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 620: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 621/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 621: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 622/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.8253 - f1_score: 0.6869\n",
      "Epoch 622: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3889 - accuracy: 0.8253 - f1_score: 0.6869\n",
      "Epoch 623/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8251 - f1_score: 0.6872\n",
      "Epoch 623: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 624/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 624: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 625/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6886\n",
      "Epoch 625: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6887\n",
      "Epoch 626/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8255 - f1_score: 0.6870\n",
      "Epoch 626: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3891 - accuracy: 0.8255 - f1_score: 0.6870\n",
      "Epoch 627/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 627: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 628/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8245 - f1_score: 0.6869\n",
      "Epoch 628: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3896 - accuracy: 0.8246 - f1_score: 0.6870\n",
      "Epoch 629/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8247 - f1_score: 0.6868\n",
      "Epoch 629: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3887 - accuracy: 0.8248 - f1_score: 0.6869\n",
      "Epoch 630/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8264 - f1_score: 0.6884\n",
      "Epoch 630: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3870 - accuracy: 0.8264 - f1_score: 0.6884\n",
      "Epoch 631/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 631: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 632/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 632: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 633/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8264 - f1_score: 0.6874\n",
      "Epoch 633: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8265 - f1_score: 0.6872\n",
      "Epoch 634/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8269 - f1_score: 0.6877\n",
      "Epoch 634: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 635/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8274 - f1_score: 0.6877\n",
      "Epoch 635: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 636/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8262 - f1_score: 0.6869\n",
      "Epoch 636: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8263 - f1_score: 0.6869\n",
      "Epoch 637/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 637: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 638/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6862\n",
      "Epoch 638: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6862\n",
      "Epoch 639/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8260 - f1_score: 0.6862\n",
      "Epoch 639: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8260 - f1_score: 0.6862\n",
      "Epoch 640/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8252 - f1_score: 0.6865\n",
      "Epoch 640: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8252 - f1_score: 0.6865\n",
      "Epoch 641/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8263 - f1_score: 0.6868\n",
      "Epoch 641: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8262 - f1_score: 0.6867\n",
      "Epoch 642/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8260 - f1_score: 0.6868\n",
      "Epoch 642: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8260 - f1_score: 0.6868\n",
      "Epoch 643/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8271 - f1_score: 0.6874\n",
      "Epoch 643: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 644/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8264 - f1_score: 0.6879\n",
      "Epoch 644: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3862 - accuracy: 0.8264 - f1_score: 0.6879\n",
      "Epoch 645/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8254 - f1_score: 0.6874\n",
      "Epoch 645: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8254 - f1_score: 0.6875\n",
      "Epoch 646/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 646: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8260 - f1_score: 0.6871\n",
      "Epoch 647/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8258 - f1_score: 0.6878\n",
      "Epoch 647: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8258 - f1_score: 0.6878\n",
      "Epoch 648/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8256 - f1_score: 0.6871\n",
      "Epoch 648: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8255 - f1_score: 0.6871\n",
      "Epoch 649/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8262 - f1_score: 0.6867\n",
      "Epoch 649: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6867\n",
      "Epoch 650/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8249 - f1_score: 0.6869\n",
      "Epoch 650: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8250 - f1_score: 0.6869\n",
      "Epoch 651/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6888\n",
      "Epoch 651: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 652/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8261 - f1_score: 0.6867\n",
      "Epoch 652: accuracy did not improve from 0.82847\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8260 - f1_score: 0.6867\n",
      "Epoch 653/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6890\n",
      "Epoch 653: accuracy improved from 0.82847 to 0.82851, saving model to ./625-batch_size625\\weight-improvement2-653-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6889\n",
      "Epoch 654/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 654: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6883\n",
      "Epoch 655/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8265 - f1_score: 0.6882\n",
      "Epoch 655: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8265 - f1_score: 0.6882\n",
      "Epoch 656/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6879\n",
      "Epoch 656: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 657/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6869\n",
      "Epoch 657: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6869\n",
      "Epoch 658/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 658: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8267 - f1_score: 0.6871\n",
      "Epoch 659/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8244 - f1_score: 0.6865\n",
      "Epoch 659: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3896 - accuracy: 0.8245 - f1_score: 0.6865\n",
      "Epoch 660/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 660: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3879 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 661/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8270 - f1_score: 0.6866\n",
      "Epoch 661: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8270 - f1_score: 0.6866\n",
      "Epoch 662/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6871\n",
      "Epoch 662: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 663/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8266 - f1_score: 0.6869\n",
      "Epoch 663: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8265 - f1_score: 0.6868\n",
      "Epoch 664/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6871\n",
      "Epoch 664: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8266 - f1_score: 0.6870\n",
      "Epoch 665/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8265 - f1_score: 0.6862\n",
      "Epoch 665: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8265 - f1_score: 0.6862\n",
      "Epoch 666/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8266 - f1_score: 0.6879\n",
      "Epoch 666: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3848 - accuracy: 0.8266 - f1_score: 0.6879\n",
      "Epoch 667/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6881\n",
      "Epoch 667: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8274 - f1_score: 0.6881\n",
      "Epoch 668/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 668: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 669/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 669: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 670/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8266 - f1_score: 0.6863\n",
      "Epoch 670: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8266 - f1_score: 0.6863\n",
      "Epoch 671/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8254 - f1_score: 0.6874\n",
      "Epoch 671: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8254 - f1_score: 0.6874\n",
      "Epoch 672/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 672: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 673/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 673: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 674/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 674: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 675/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 675: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 676/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 676: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 677/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 677: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 678/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 678: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3857 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 679/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8265 - f1_score: 0.6865\n",
      "Epoch 679: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8265 - f1_score: 0.6865\n",
      "Epoch 680/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8262 - f1_score: 0.6861\n",
      "Epoch 680: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3900 - accuracy: 0.8262 - f1_score: 0.6861\n",
      "Epoch 681/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 681: accuracy did not improve from 0.82851\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 682/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 682: accuracy improved from 0.82851 to 0.82872, saving model to ./625-batch_size625\\weight-improvement2-682-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3846 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 683/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6869\n",
      "Epoch 683: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6869\n",
      "Epoch 684/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8253 - f1_score: 0.6855\n",
      "Epoch 684: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3890 - accuracy: 0.8253 - f1_score: 0.6855\n",
      "Epoch 685/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3932 - accuracy: 0.8228 - f1_score: 0.6856\n",
      "Epoch 685: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3932 - accuracy: 0.8228 - f1_score: 0.6856\n",
      "Epoch 686/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8264 - f1_score: 0.6862\n",
      "Epoch 686: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3879 - accuracy: 0.8264 - f1_score: 0.6862\n",
      "Epoch 687/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8258 - f1_score: 0.6852\n",
      "Epoch 687: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3890 - accuracy: 0.8257 - f1_score: 0.6852\n",
      "Epoch 688/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 688: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 689/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 689: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 690/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 690: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 691/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 691: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3867 - accuracy: 0.8265 - f1_score: 0.6872\n",
      "Epoch 692/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8278 - f1_score: 0.6872\n",
      "Epoch 692: accuracy did not improve from 0.82872\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3861 - accuracy: 0.8278 - f1_score: 0.6872\n",
      "Epoch 693/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6877\n",
      "Epoch 693: accuracy improved from 0.82872 to 0.82927, saving model to ./625-batch_size625\\weight-improvement2-693-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3837 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 694/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8291 - f1_score: 0.6874\n",
      "Epoch 694: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8291 - f1_score: 0.6874\n",
      "Epoch 695/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8290 - f1_score: 0.6888\n",
      "Epoch 695: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6888\n",
      "Epoch 696/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8278 - f1_score: 0.6872\n",
      "Epoch 696: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3855 - accuracy: 0.8278 - f1_score: 0.6872\n",
      "Epoch 697/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8275 - f1_score: 0.6866\n",
      "Epoch 697: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8274 - f1_score: 0.6866\n",
      "Epoch 698/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8274 - f1_score: 0.6865\n",
      "Epoch 698: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3869 - accuracy: 0.8274 - f1_score: 0.6866\n",
      "Epoch 699/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8253 - f1_score: 0.6870\n",
      "Epoch 699: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3877 - accuracy: 0.8252 - f1_score: 0.6869\n",
      "Epoch 700/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 700: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 701/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8254 - f1_score: 0.6863\n",
      "Epoch 701: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3892 - accuracy: 0.8253 - f1_score: 0.6863\n",
      "Epoch 702/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8283 - f1_score: 0.6867\n",
      "Epoch 702: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3852 - accuracy: 0.8284 - f1_score: 0.6867\n",
      "Epoch 703/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6872\n",
      "Epoch 703: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 704/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6891\n",
      "Epoch 704: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6890\n",
      "Epoch 705/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8260 - f1_score: 0.6873\n",
      "Epoch 705: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3876 - accuracy: 0.8260 - f1_score: 0.6873\n",
      "Epoch 706/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8245 - f1_score: 0.6871\n",
      "Epoch 706: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3895 - accuracy: 0.8245 - f1_score: 0.6871\n",
      "Epoch 707/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 707: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 708/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8283 - f1_score: 0.6879\n",
      "Epoch 708: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 709/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8275 - f1_score: 0.6885\n",
      "Epoch 709: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8274 - f1_score: 0.6884\n",
      "Epoch 710/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6888\n",
      "Epoch 710: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6889\n",
      "Epoch 711/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 711: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 712/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 712: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 713/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8263 - f1_score: 0.6868\n",
      "Epoch 713: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3874 - accuracy: 0.8263 - f1_score: 0.6867\n",
      "Epoch 714/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 714: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 715/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8265 - f1_score: 0.6865\n",
      "Epoch 715: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8266 - f1_score: 0.6864\n",
      "Epoch 716/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8272 - f1_score: 0.6881\n",
      "Epoch 716: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3851 - accuracy: 0.8272 - f1_score: 0.6881\n",
      "Epoch 717/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8264 - f1_score: 0.6871\n",
      "Epoch 717: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8264 - f1_score: 0.6870\n",
      "Epoch 718/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8287 - f1_score: 0.6870\n",
      "Epoch 718: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8286 - f1_score: 0.6871\n",
      "Epoch 719/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 719: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 720/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6869\n",
      "Epoch 720: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6869\n",
      "Epoch 721/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 721: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 722/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 722: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 723/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 723: accuracy did not improve from 0.82927\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8274 - f1_score: 0.6870\n",
      "Epoch 724/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 724: accuracy improved from 0.82927 to 0.82960, saving model to ./625-batch_size625\\weight-improvement2-724-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3836 - accuracy: 0.8296 - f1_score: 0.6878\n",
      "Epoch 725/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 725: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8277 - f1_score: 0.6878\n",
      "Epoch 726/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 726: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 727/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8277 - f1_score: 0.6873\n",
      "Epoch 727: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 728/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 728: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 729/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6880\n",
      "Epoch 729: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6881\n",
      "Epoch 730/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8281 - f1_score: 0.6871\n",
      "Epoch 730: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8280 - f1_score: 0.6870\n",
      "Epoch 731/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 731: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 732/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6870\n",
      "Epoch 732: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8271 - f1_score: 0.6870\n",
      "Epoch 733/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8293 - f1_score: 0.6866\n",
      "Epoch 733: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3846 - accuracy: 0.8294 - f1_score: 0.6867\n",
      "Epoch 734/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 734: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 735/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6868\n",
      "Epoch 735: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6869\n",
      "Epoch 736/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 736: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3870 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 737/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3899 - accuracy: 0.8257 - f1_score: 0.6858\n",
      "Epoch 737: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3899 - accuracy: 0.8257 - f1_score: 0.6859\n",
      "Epoch 738/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8285 - f1_score: 0.6874\n",
      "Epoch 738: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3845 - accuracy: 0.8286 - f1_score: 0.6874\n",
      "Epoch 739/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 739: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 740/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6876\n",
      "Epoch 740: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6876\n",
      "Epoch 741/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6886\n",
      "Epoch 741: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 742/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 742: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8278 - f1_score: 0.6881\n",
      "Epoch 743/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 743: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8275 - f1_score: 0.6875\n",
      "Epoch 744/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 744: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 745/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 745: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 746/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8271 - f1_score: 0.6862\n",
      "Epoch 746: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3872 - accuracy: 0.8271 - f1_score: 0.6864\n",
      "Epoch 747/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 747: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3853 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 748/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8287 - f1_score: 0.6867\n",
      "Epoch 748: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8287 - f1_score: 0.6867\n",
      "Epoch 749/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 749: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3838 - accuracy: 0.8289 - f1_score: 0.6880\n",
      "Epoch 750/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 750: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 751/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8272 - f1_score: 0.6869\n",
      "Epoch 751: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8273 - f1_score: 0.6867\n",
      "Epoch 752/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 752: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 753/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8282 - f1_score: 0.6870\n",
      "Epoch 753: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 754/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 754: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 755/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6871\n",
      "Epoch 755: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6871\n",
      "Epoch 756/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8277 - f1_score: 0.6875\n",
      "Epoch 756: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8277 - f1_score: 0.6875\n",
      "Epoch 757/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6871\n",
      "Epoch 757: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6871\n",
      "Epoch 758/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 758: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 759/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 759: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3856 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 760/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8271 - f1_score: 0.6867\n",
      "Epoch 760: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3870 - accuracy: 0.8271 - f1_score: 0.6867\n",
      "Epoch 761/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6876\n",
      "Epoch 761: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 762/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 762: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 763/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8262 - f1_score: 0.6868\n",
      "Epoch 763: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3890 - accuracy: 0.8262 - f1_score: 0.6869\n",
      "Epoch 764/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 764: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 765/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 765: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3862 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 766/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8296 - f1_score: 0.6880\n",
      "Epoch 766: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3838 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 767/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8267 - f1_score: 0.6861\n",
      "Epoch 767: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6863\n",
      "Epoch 768/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6860\n",
      "Epoch 768: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6860\n",
      "Epoch 769/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8278 - f1_score: 0.6872\n",
      "Epoch 769: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3870 - accuracy: 0.8277 - f1_score: 0.6872\n",
      "Epoch 770/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8254 - f1_score: 0.6879\n",
      "Epoch 770: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3895 - accuracy: 0.8254 - f1_score: 0.6879\n",
      "Epoch 771/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8269 - f1_score: 0.6874\n",
      "Epoch 771: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3876 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 772/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8264 - f1_score: 0.6869\n",
      "Epoch 772: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3884 - accuracy: 0.8265 - f1_score: 0.6869\n",
      "Epoch 773/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8281 - f1_score: 0.6867\n",
      "Epoch 773: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3864 - accuracy: 0.8280 - f1_score: 0.6869\n",
      "Epoch 774/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8259 - f1_score: 0.6863\n",
      "Epoch 774: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8259 - f1_score: 0.6863\n",
      "Epoch 775/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 775: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3849 - accuracy: 0.8271 - f1_score: 0.6876\n",
      "Epoch 776/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8261 - f1_score: 0.6871\n",
      "Epoch 776: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3862 - accuracy: 0.8261 - f1_score: 0.6871\n",
      "Epoch 777/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 777: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 778/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 778: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6876\n",
      "Epoch 779/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6881\n",
      "Epoch 779: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8278 - f1_score: 0.6881\n",
      "Epoch 780/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 780: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 781/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 781: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3866 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 782/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8272 - f1_score: 0.6873\n",
      "Epoch 782: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6872\n",
      "Epoch 783/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8263 - f1_score: 0.6863\n",
      "Epoch 783: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3888 - accuracy: 0.8263 - f1_score: 0.6864\n",
      "Epoch 784/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 784: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3855 - accuracy: 0.8272 - f1_score: 0.6872\n",
      "Epoch 785/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 785: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 786/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 786: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3849 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 787/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8279 - f1_score: 0.6869\n",
      "Epoch 787: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6868\n",
      "Epoch 788/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 788: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 789/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 789: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3862 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 790/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 790: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 791/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8273 - f1_score: 0.6888\n",
      "Epoch 791: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8273 - f1_score: 0.6888\n",
      "Epoch 792/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6889\n",
      "Epoch 792: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 793/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8284 - f1_score: 0.6880\n",
      "Epoch 793: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6881\n",
      "Epoch 794/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8268 - f1_score: 0.6868\n",
      "Epoch 794: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 795/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 795: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 796/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 796: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 797/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 797: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3873 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 798/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8260 - f1_score: 0.6875\n",
      "Epoch 798: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3873 - accuracy: 0.8260 - f1_score: 0.6875\n",
      "Epoch 799/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8260 - f1_score: 0.6878\n",
      "Epoch 799: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3874 - accuracy: 0.8259 - f1_score: 0.6876\n",
      "Epoch 800/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8250 - f1_score: 0.6867\n",
      "Epoch 800: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8250 - f1_score: 0.6868\n",
      "Epoch 801/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 801: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 802/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8286 - f1_score: 0.6867\n",
      "Epoch 802: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8286 - f1_score: 0.6867\n",
      "Epoch 803/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 803: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8274 - f1_score: 0.6871\n",
      "Epoch 804/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 804: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 805/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8290 - f1_score: 0.6876\n",
      "Epoch 805: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 806/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 806: accuracy did not improve from 0.82960\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8267 - f1_score: 0.6871\n",
      "Epoch 807/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8306 - f1_score: 0.6879\n",
      "Epoch 807: accuracy improved from 0.82960 to 0.83064, saving model to ./625-batch_size625\\weight-improvement2-807-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3819 - accuracy: 0.8306 - f1_score: 0.6880\n",
      "Epoch 808/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6885\n",
      "Epoch 808: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6885\n",
      "Epoch 809/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 809: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3836 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 810/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8288 - f1_score: 0.6870\n",
      "Epoch 810: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8287 - f1_score: 0.6869\n",
      "Epoch 811/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8274 - f1_score: 0.6867\n",
      "Epoch 811: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8274 - f1_score: 0.6867\n",
      "Epoch 812/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 812: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 813/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8261 - f1_score: 0.6865\n",
      "Epoch 813: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8262 - f1_score: 0.6864\n",
      "Epoch 814/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8266 - f1_score: 0.6866\n",
      "Epoch 814: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6866\n",
      "Epoch 815/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6861\n",
      "Epoch 815: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6861\n",
      "Epoch 816/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8287 - f1_score: 0.6870\n",
      "Epoch 816: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8288 - f1_score: 0.6870\n",
      "Epoch 817/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8287 - f1_score: 0.6876\n",
      "Epoch 817: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 818/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 818: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3832 - accuracy: 0.8286 - f1_score: 0.6879\n",
      "Epoch 819/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 819: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 820/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8282 - f1_score: 0.6869\n",
      "Epoch 820: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8282 - f1_score: 0.6869\n",
      "Epoch 821/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 821: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3830 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 822/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 822: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 823/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 823: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 824/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8254 - f1_score: 0.6865\n",
      "Epoch 824: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8254 - f1_score: 0.6865\n",
      "Epoch 825/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 825: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 826/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 826: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 827/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6883\n",
      "Epoch 827: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6883\n",
      "Epoch 828/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8266 - f1_score: 0.6867\n",
      "Epoch 828: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8265 - f1_score: 0.6865\n",
      "Epoch 829/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8267 - f1_score: 0.6866\n",
      "Epoch 829: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8267 - f1_score: 0.6865\n",
      "Epoch 830/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 830: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 831/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 831: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 832/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8284 - f1_score: 0.6870\n",
      "Epoch 832: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3851 - accuracy: 0.8284 - f1_score: 0.6869\n",
      "Epoch 833/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8288 - f1_score: 0.6866\n",
      "Epoch 833: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8286 - f1_score: 0.6864\n",
      "Epoch 834/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6866\n",
      "Epoch 834: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8276 - f1_score: 0.6866\n",
      "Epoch 835/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 835: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 836/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 836: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 837/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8284 - f1_score: 0.6873\n",
      "Epoch 837: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8284 - f1_score: 0.6873\n",
      "Epoch 838/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 838: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6870\n",
      "Epoch 839/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 839: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 840/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 840: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 841/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6865\n",
      "Epoch 841: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6865\n",
      "Epoch 842/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6868\n",
      "Epoch 842: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6868\n",
      "Epoch 843/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8291 - f1_score: 0.6869\n",
      "Epoch 843: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8290 - f1_score: 0.6869\n",
      "Epoch 844/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 844: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6874\n",
      "Epoch 845/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 845: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 846/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 846: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 847/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 847: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 848/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8260 - f1_score: 0.6874\n",
      "Epoch 848: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8261 - f1_score: 0.6875\n",
      "Epoch 849/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.8257 - f1_score: 0.6861\n",
      "Epoch 849: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3894 - accuracy: 0.8257 - f1_score: 0.6861\n",
      "Epoch 850/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8271 - f1_score: 0.6867\n",
      "Epoch 850: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8271 - f1_score: 0.6867\n",
      "Epoch 851/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 851: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8269 - f1_score: 0.6877\n",
      "Epoch 852/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 852: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 853/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 853: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 854/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8279 - f1_score: 0.6864\n",
      "Epoch 854: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8279 - f1_score: 0.6863\n",
      "Epoch 855/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 855: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 856/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 856: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6870\n",
      "Epoch 857/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8271 - f1_score: 0.6866\n",
      "Epoch 857: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8271 - f1_score: 0.6866\n",
      "Epoch 858/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8273 - f1_score: 0.6869\n",
      "Epoch 858: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8272 - f1_score: 0.6869\n",
      "Epoch 859/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8266 - f1_score: 0.6857\n",
      "Epoch 859: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3883 - accuracy: 0.8267 - f1_score: 0.6856\n",
      "Epoch 860/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8285 - f1_score: 0.6865\n",
      "Epoch 860: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6865\n",
      "Epoch 861/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6874\n",
      "Epoch 861: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3844 - accuracy: 0.8277 - f1_score: 0.6872\n",
      "Epoch 862/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 862: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 863/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 863: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 864/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6869\n",
      "Epoch 864: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6869\n",
      "Epoch 865/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8272 - f1_score: 0.6865\n",
      "Epoch 865: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6865\n",
      "Epoch 866/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6864\n",
      "Epoch 866: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8270 - f1_score: 0.6864\n",
      "Epoch 867/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8276 - f1_score: 0.6869\n",
      "Epoch 867: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 868/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6863\n",
      "Epoch 868: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8286 - f1_score: 0.6864\n",
      "Epoch 869/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8286 - f1_score: 0.6867\n",
      "Epoch 869: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8285 - f1_score: 0.6867\n",
      "Epoch 870/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6876\n",
      "Epoch 870: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 871/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 871: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 872/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8270 - f1_score: 0.6883\n",
      "Epoch 872: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8269 - f1_score: 0.6882\n",
      "Epoch 873/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 873: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 874/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 874: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 875/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 875: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3825 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 876/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8270 - f1_score: 0.6880\n",
      "Epoch 876: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8270 - f1_score: 0.6880\n",
      "Epoch 877/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8269 - f1_score: 0.6883\n",
      "Epoch 877: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8269 - f1_score: 0.6883\n",
      "Epoch 878/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8282 - f1_score: 0.6885\n",
      "Epoch 878: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8282 - f1_score: 0.6885\n",
      "Epoch 879/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 879: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3835 - accuracy: 0.8284 - f1_score: 0.6885\n",
      "Epoch 880/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8270 - f1_score: 0.6880\n",
      "Epoch 880: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8271 - f1_score: 0.6880\n",
      "Epoch 881/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8270 - f1_score: 0.6877\n",
      "Epoch 881: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8270 - f1_score: 0.6877\n",
      "Epoch 882/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8281 - f1_score: 0.6894\n",
      "Epoch 882: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8281 - f1_score: 0.6893\n",
      "Epoch 883/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8272 - f1_score: 0.6871\n",
      "Epoch 883: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6871\n",
      "Epoch 884/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 884: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 885/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 885: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 886/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 886: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 887/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8275 - f1_score: 0.6879\n",
      "Epoch 887: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8275 - f1_score: 0.6879\n",
      "Epoch 888/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8258 - f1_score: 0.6871\n",
      "Epoch 888: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8259 - f1_score: 0.6871\n",
      "Epoch 889/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6869\n",
      "Epoch 889: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6868\n",
      "Epoch 890/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6868\n",
      "Epoch 890: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6868\n",
      "Epoch 891/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8273 - f1_score: 0.6868\n",
      "Epoch 891: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8273 - f1_score: 0.6868\n",
      "Epoch 892/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8274 - f1_score: 0.6871\n",
      "Epoch 892: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 893/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8265 - f1_score: 0.6873\n",
      "Epoch 893: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8265 - f1_score: 0.6873\n",
      "Epoch 894/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6867\n",
      "Epoch 894: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6865\n",
      "Epoch 895/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8248 - f1_score: 0.6869\n",
      "Epoch 895: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8248 - f1_score: 0.6868\n",
      "Epoch 896/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8254 - f1_score: 0.6873\n",
      "Epoch 896: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8254 - f1_score: 0.6873\n",
      "Epoch 897/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 897: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 898/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6865\n",
      "Epoch 898: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6865\n",
      "Epoch 899/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6869\n",
      "Epoch 899: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6869\n",
      "Epoch 900/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8272 - f1_score: 0.6868\n",
      "Epoch 900: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6868\n",
      "Epoch 901/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 901: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 902/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8271 - f1_score: 0.6870\n",
      "Epoch 902: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 903/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8282 - f1_score: 0.6866\n",
      "Epoch 903: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6866\n",
      "Epoch 904/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 904: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3834 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 905/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6870\n",
      "Epoch 905: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6869\n",
      "Epoch 906/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 906: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8278 - f1_score: 0.6879\n",
      "Epoch 907/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 907: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 908/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 908: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3825 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 909/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 909: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 910/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 910: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3829 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 911/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 911: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 912/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8293 - f1_score: 0.6870\n",
      "Epoch 912: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8293 - f1_score: 0.6871\n",
      "Epoch 913/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8292 - f1_score: 0.6875\n",
      "Epoch 913: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8292 - f1_score: 0.6875\n",
      "Epoch 914/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 914: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 915/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 915: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 916/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 916: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 917/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8289 - f1_score: 0.6884\n",
      "Epoch 917: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 918/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8299 - f1_score: 0.6877\n",
      "Epoch 918: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3824 - accuracy: 0.8299 - f1_score: 0.6877\n",
      "Epoch 919/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 919: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 920/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 920: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3831 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 921/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 921: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8279 - f1_score: 0.6874\n",
      "Epoch 922/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 922: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 923/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8287 - f1_score: 0.6865\n",
      "Epoch 923: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6865\n",
      "Epoch 924/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8296 - f1_score: 0.6873\n",
      "Epoch 924: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3830 - accuracy: 0.8296 - f1_score: 0.6874\n",
      "Epoch 925/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8282 - f1_score: 0.6867\n",
      "Epoch 925: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8281 - f1_score: 0.6867\n",
      "Epoch 926/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8284 - f1_score: 0.6867\n",
      "Epoch 926: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8284 - f1_score: 0.6867\n",
      "Epoch 927/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6866\n",
      "Epoch 927: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8285 - f1_score: 0.6868\n",
      "Epoch 928/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 928: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8271 - f1_score: 0.6870\n",
      "Epoch 929/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 929: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 930/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 930: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 931/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6859\n",
      "Epoch 931: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8274 - f1_score: 0.6860\n",
      "Epoch 932/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8298 - f1_score: 0.6866\n",
      "Epoch 932: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3830 - accuracy: 0.8298 - f1_score: 0.6865\n",
      "Epoch 933/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 933: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 934/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 934: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3821 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 935/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8275 - f1_score: 0.6883\n",
      "Epoch 935: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8275 - f1_score: 0.6883\n",
      "Epoch 936/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6869\n",
      "Epoch 936: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8275 - f1_score: 0.6868\n",
      "Epoch 937/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 937: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6877\n",
      "Epoch 938/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8286 - f1_score: 0.6865\n",
      "Epoch 938: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8285 - f1_score: 0.6865\n",
      "Epoch 939/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 939: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3832 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 940/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 940: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 941/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 941: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 942/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6866\n",
      "Epoch 942: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6865\n",
      "Epoch 943/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8278 - f1_score: 0.6870\n",
      "Epoch 943: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6869\n",
      "Epoch 944/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 944: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 945/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 945: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 946/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 946: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6871\n",
      "Epoch 947/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 947: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 948/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6871\n",
      "Epoch 948: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3821 - accuracy: 0.8298 - f1_score: 0.6872\n",
      "Epoch 949/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8293 - f1_score: 0.6872\n",
      "Epoch 949: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8293 - f1_score: 0.6872\n",
      "Epoch 950/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 950: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 951/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8274 - f1_score: 0.6858\n",
      "Epoch 951: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8274 - f1_score: 0.6859\n",
      "Epoch 952/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6866\n",
      "Epoch 952: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8283 - f1_score: 0.6868\n",
      "Epoch 953/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 953: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 954/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 954: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 955/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 955: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3831 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 956/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6866\n",
      "Epoch 956: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6866\n",
      "Epoch 957/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6874\n",
      "Epoch 957: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3861 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 958/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 958: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6879\n",
      "Epoch 959/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 959: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3870 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 960/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8269 - f1_score: 0.6872\n",
      "Epoch 960: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 961/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 961: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8282 - f1_score: 0.6870\n",
      "Epoch 962/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6862\n",
      "Epoch 962: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6863\n",
      "Epoch 963/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8281 - f1_score: 0.6870\n",
      "Epoch 963: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8281 - f1_score: 0.6870\n",
      "Epoch 964/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 964: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 965/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 965: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6872\n",
      "Epoch 966/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8284 - f1_score: 0.6873\n",
      "Epoch 966: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3857 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 967/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 967: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 968/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 968: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6877\n",
      "Epoch 969/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 969: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 970/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8290 - f1_score: 0.6874\n",
      "Epoch 970: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8290 - f1_score: 0.6874\n",
      "Epoch 971/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 971: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 972/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 972: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 973/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 973: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 974/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 974: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 975/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 975: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 976/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6876\n",
      "Epoch 976: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 977/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6883\n",
      "Epoch 977: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 978/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6870\n",
      "Epoch 978: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8271 - f1_score: 0.6870\n",
      "Epoch 979/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 979: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 980/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 980: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 981/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6892\n",
      "Epoch 981: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6892\n",
      "Epoch 982/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 982: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 983/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 983: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 984/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8286 - f1_score: 0.6879\n",
      "Epoch 984: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 985/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 985: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 986/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 986: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 987/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8266 - f1_score: 0.6867\n",
      "Epoch 987: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8265 - f1_score: 0.6867\n",
      "Epoch 988/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 988: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 989/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 989: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 990/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 990: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8274 - f1_score: 0.6874\n",
      "Epoch 991/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 991: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3840 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 992/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8293 - f1_score: 0.6880\n",
      "Epoch 992: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 993/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 993: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8289 - f1_score: 0.6873\n",
      "Epoch 994/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6877\n",
      "Epoch 994: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 995/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6874\n",
      "Epoch 995: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6874\n",
      "Epoch 996/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6877\n",
      "Epoch 996: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 997/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 997: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6873\n",
      "Epoch 998/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6871\n",
      "Epoch 998: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6872\n",
      "Epoch 999/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 999: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8277 - f1_score: 0.6873\n",
      "Epoch 1000/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8270 - f1_score: 0.6870\n",
      "Epoch 1000: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8270 - f1_score: 0.6870\n",
      "Epoch 1001/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8249 - f1_score: 0.6864\n",
      "Epoch 1001: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8250 - f1_score: 0.6863\n",
      "Epoch 1002/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6862\n",
      "Epoch 1002: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6863\n",
      "Epoch 1003/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6880\n",
      "Epoch 1003: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6880\n",
      "Epoch 1004/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6873\n",
      "Epoch 1004: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6875\n",
      "Epoch 1005/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 1005: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 1006/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8258 - f1_score: 0.6866\n",
      "Epoch 1006: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3868 - accuracy: 0.8259 - f1_score: 0.6865\n",
      "Epoch 1007/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8264 - f1_score: 0.6861\n",
      "Epoch 1007: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3873 - accuracy: 0.8264 - f1_score: 0.6862\n",
      "Epoch 1008/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6874\n",
      "Epoch 1008: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6874\n",
      "Epoch 1009/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 1009: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3821 - accuracy: 0.8298 - f1_score: 0.6889\n",
      "Epoch 1010/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 1010: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 1011/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 1011: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3832 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 1012/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8284 - f1_score: 0.6872\n",
      "Epoch 1012: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3855 - accuracy: 0.8284 - f1_score: 0.6872\n",
      "Epoch 1013/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 1013: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 1014/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6883\n",
      "Epoch 1014: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 1015/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 1015: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 1016/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 1016: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 1017/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 1017: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 1018/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8289 - f1_score: 0.6878\n",
      "Epoch 1018: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 1019/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8253 - f1_score: 0.6872\n",
      "Epoch 1019: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 1020/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8265 - f1_score: 0.6874\n",
      "Epoch 1020: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8265 - f1_score: 0.6874\n",
      "Epoch 1021/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 1021: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 1022/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8278 - f1_score: 0.6865\n",
      "Epoch 1022: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8277 - f1_score: 0.6865\n",
      "Epoch 1023/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 1023: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8274 - f1_score: 0.6869\n",
      "Epoch 1024/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 1024: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 1025/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1025: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 1026/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 1026: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6873\n",
      "Epoch 1027/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8300 - f1_score: 0.6873\n",
      "Epoch 1027: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3829 - accuracy: 0.8300 - f1_score: 0.6872\n",
      "Epoch 1028/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6876\n",
      "Epoch 1028: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 1029/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8245 - f1_score: 0.6867\n",
      "Epoch 1029: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8246 - f1_score: 0.6866\n",
      "Epoch 1030/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 1030: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 1031/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8289 - f1_score: 0.6880\n",
      "Epoch 1031: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6880\n",
      "Epoch 1032/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1032: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1033/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 1033: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 1034/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 1034: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 1035/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8273 - f1_score: 0.6869\n",
      "Epoch 1035: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8273 - f1_score: 0.6869\n",
      "Epoch 1036/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 1036: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6878\n",
      "Epoch 1037/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 1037: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 1038/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 1038: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 1039/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 1039: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 1040/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8278 - f1_score: 0.6889\n",
      "Epoch 1040: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6889\n",
      "Epoch 1041/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 1041: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 1042/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6865\n",
      "Epoch 1042: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8283 - f1_score: 0.6866\n",
      "Epoch 1043/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 1043: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 1044/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 1044: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6871\n",
      "Epoch 1045/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8262 - f1_score: 0.6865\n",
      "Epoch 1045: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8262 - f1_score: 0.6865\n",
      "Epoch 1046/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8260 - f1_score: 0.6874\n",
      "Epoch 1046: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8259 - f1_score: 0.6874\n",
      "Epoch 1047/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 1047: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 1048/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 1048: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 1049/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 1049: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 1050/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 1050: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 1051/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 1051: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 1052/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 1052: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 1053/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8251 - f1_score: 0.6869\n",
      "Epoch 1053: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8251 - f1_score: 0.6869\n",
      "Epoch 1054/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8269 - f1_score: 0.6880\n",
      "Epoch 1054: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8268 - f1_score: 0.6880\n",
      "Epoch 1055/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8268 - f1_score: 0.6871\n",
      "Epoch 1055: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8268 - f1_score: 0.6872\n",
      "Epoch 1056/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 1056: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 1057/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 1057: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 1058/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 1058: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 1059/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 1059: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8277 - f1_score: 0.6868\n",
      "Epoch 1060/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8258 - f1_score: 0.6870\n",
      "Epoch 1060: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8258 - f1_score: 0.6869\n",
      "Epoch 1061/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1061: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8276 - f1_score: 0.6873\n",
      "Epoch 1062/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8281 - f1_score: 0.6870\n",
      "Epoch 1062: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3863 - accuracy: 0.8280 - f1_score: 0.6869\n",
      "Epoch 1063/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8278 - f1_score: 0.6863\n",
      "Epoch 1063: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8278 - f1_score: 0.6863\n",
      "Epoch 1064/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1064: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1065/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6868\n",
      "Epoch 1065: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6867\n",
      "Epoch 1066/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8298 - f1_score: 0.6878\n",
      "Epoch 1066: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3830 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 1067/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 1067: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3832 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 1068/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8276 - f1_score: 0.6879\n",
      "Epoch 1068: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8276 - f1_score: 0.6879\n",
      "Epoch 1069/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8280 - f1_score: 0.6869\n",
      "Epoch 1069: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8280 - f1_score: 0.6869\n",
      "Epoch 1070/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8285 - f1_score: 0.6885\n",
      "Epoch 1070: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3827 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 1071/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8268 - f1_score: 0.6884\n",
      "Epoch 1071: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8269 - f1_score: 0.6885\n",
      "Epoch 1072/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8276 - f1_score: 0.6869\n",
      "Epoch 1072: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3869 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 1073/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 1073: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3831 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 1074/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 1074: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 1075/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6869\n",
      "Epoch 1075: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6869\n",
      "Epoch 1076/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8263 - f1_score: 0.6866\n",
      "Epoch 1076: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8263 - f1_score: 0.6865\n",
      "Epoch 1077/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8269 - f1_score: 0.6868\n",
      "Epoch 1077: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 1078/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 1078: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8286 - f1_score: 0.6874\n",
      "Epoch 1079/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 1079: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 1080/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8284 - f1_score: 0.6873\n",
      "Epoch 1080: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6873\n",
      "Epoch 1081/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8259 - f1_score: 0.6865\n",
      "Epoch 1081: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3886 - accuracy: 0.8258 - f1_score: 0.6866\n",
      "Epoch 1082/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8276 - f1_score: 0.6882\n",
      "Epoch 1082: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3847 - accuracy: 0.8276 - f1_score: 0.6883\n",
      "Epoch 1083/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 1083: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 1084/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 1084: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 1085/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8273 - f1_score: 0.6876\n",
      "Epoch 1085: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8274 - f1_score: 0.6877\n",
      "Epoch 1086/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 1086: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 1087/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8255 - f1_score: 0.6871\n",
      "Epoch 1087: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8255 - f1_score: 0.6870\n",
      "Epoch 1088/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8276 - f1_score: 0.6871\n",
      "Epoch 1088: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 1089/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 1089: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 1090/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 1090: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 1091/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6880\n",
      "Epoch 1091: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 1092/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 1092: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 1093/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8290 - f1_score: 0.6875\n",
      "Epoch 1093: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8291 - f1_score: 0.6876\n",
      "Epoch 1094/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 1094: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6880\n",
      "Epoch 1095/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 1095: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8275 - f1_score: 0.6872\n",
      "Epoch 1096/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 1096: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 1097/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8256 - f1_score: 0.6875\n",
      "Epoch 1097: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8257 - f1_score: 0.6874\n",
      "Epoch 1098/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8256 - f1_score: 0.6875\n",
      "Epoch 1098: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3875 - accuracy: 0.8255 - f1_score: 0.6875\n",
      "Epoch 1099/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3878 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 1099: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 1100/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8274 - f1_score: 0.6874\n",
      "Epoch 1100: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 1101/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8271 - f1_score: 0.6871\n",
      "Epoch 1101: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3878 - accuracy: 0.8271 - f1_score: 0.6871\n",
      "Epoch 1102/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 1102: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 1103/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8286 - f1_score: 0.6874\n",
      "Epoch 1103: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1104/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1104: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8278 - f1_score: 0.6877\n",
      "Epoch 1105/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8279 - f1_score: 0.6889\n",
      "Epoch 1105: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8279 - f1_score: 0.6888\n",
      "Epoch 1106/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8277 - f1_score: 0.6868\n",
      "Epoch 1106: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8277 - f1_score: 0.6868\n",
      "Epoch 1107/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 1107: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 1108/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 1108: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 1109/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8264 - f1_score: 0.6870\n",
      "Epoch 1109: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3875 - accuracy: 0.8264 - f1_score: 0.6869\n",
      "Epoch 1110/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8263 - f1_score: 0.6870\n",
      "Epoch 1110: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8264 - f1_score: 0.6871\n",
      "Epoch 1111/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1111: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3863 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1112/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 1112: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6882\n",
      "Epoch 1113/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8270 - f1_score: 0.6867\n",
      "Epoch 1113: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3875 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 1114/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6868\n",
      "Epoch 1114: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6867\n",
      "Epoch 1115/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8277 - f1_score: 0.6870\n",
      "Epoch 1115: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8277 - f1_score: 0.6870\n",
      "Epoch 1116/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 1116: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6871\n",
      "Epoch 1117/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8294 - f1_score: 0.6870\n",
      "Epoch 1117: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8293 - f1_score: 0.6869\n",
      "Epoch 1118/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8280 - f1_score: 0.6866\n",
      "Epoch 1118: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8280 - f1_score: 0.6866\n",
      "Epoch 1119/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8266 - f1_score: 0.6863\n",
      "Epoch 1119: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8266 - f1_score: 0.6863\n",
      "Epoch 1120/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 1120: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3867 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 1121/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 1121: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 1122/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 1122: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 1123/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 1123: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 1124/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 1124: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 1125/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 1125: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 1126/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 1126: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1127/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 1127: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 1128/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8277 - f1_score: 0.6868\n",
      "Epoch 1128: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3865 - accuracy: 0.8278 - f1_score: 0.6867\n",
      "Epoch 1129/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 1129: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8278 - f1_score: 0.6870\n",
      "Epoch 1130/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 1130: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 1131/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 1131: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 1132/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 1132: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 1133/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 1133: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 1134/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8283 - f1_score: 0.6867\n",
      "Epoch 1134: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8283 - f1_score: 0.6867\n",
      "Epoch 1135/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 1135: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 1136/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6866\n",
      "Epoch 1136: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6865\n",
      "Epoch 1137/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8268 - f1_score: 0.6856\n",
      "Epoch 1137: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8267 - f1_score: 0.6856\n",
      "Epoch 1138/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8292 - f1_score: 0.6865\n",
      "Epoch 1138: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8292 - f1_score: 0.6865\n",
      "Epoch 1139/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8277 - f1_score: 0.6867\n",
      "Epoch 1139: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8278 - f1_score: 0.6867\n",
      "Epoch 1140/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6873\n",
      "Epoch 1140: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6873\n",
      "Epoch 1141/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8273 - f1_score: 0.6866\n",
      "Epoch 1141: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6866\n",
      "Epoch 1142/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 1142: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8276 - f1_score: 0.6873\n",
      "Epoch 1143/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8272 - f1_score: 0.6867\n",
      "Epoch 1143: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3873 - accuracy: 0.8273 - f1_score: 0.6867\n",
      "Epoch 1144/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 1144: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 1145/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 1145: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 1146/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6880\n",
      "Epoch 1146: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6880\n",
      "Epoch 1147/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8288 - f1_score: 0.6869\n",
      "Epoch 1147: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8288 - f1_score: 0.6870\n",
      "Epoch 1148/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6864\n",
      "Epoch 1148: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6865\n",
      "Epoch 1149/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 1149: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8267 - f1_score: 0.6868\n",
      "Epoch 1150/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8285 - f1_score: 0.6874\n",
      "Epoch 1150: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8285 - f1_score: 0.6874\n",
      "Epoch 1151/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 1151: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3831 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 1152/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 1152: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3820 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 1153/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 1153: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 1154/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 1154: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6881\n",
      "Epoch 1155/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 1155: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 1156/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 1156: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8284 - f1_score: 0.6873\n",
      "Epoch 1157/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 1157: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 1158/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 1158: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6867\n",
      "Epoch 1159/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 1159: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 1160/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1160: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1161/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8265 - f1_score: 0.6878\n",
      "Epoch 1161: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8265 - f1_score: 0.6877\n",
      "Epoch 1162/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 1162: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 1163/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6879\n",
      "Epoch 1163: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 1164/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 1164: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 1165/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 1165: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 1166/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 1166: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 1167/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 1167: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1168/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 1168: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 1169/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8284 - f1_score: 0.6875\n",
      "Epoch 1169: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 1170/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 1170: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6880\n",
      "Epoch 1171/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8283 - f1_score: 0.6865\n",
      "Epoch 1171: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8283 - f1_score: 0.6865\n",
      "Epoch 1172/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 1172: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 1173/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8268 - f1_score: 0.6859\n",
      "Epoch 1173: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3876 - accuracy: 0.8269 - f1_score: 0.6858\n",
      "Epoch 1174/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8273 - f1_score: 0.6878\n",
      "Epoch 1174: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8273 - f1_score: 0.6878\n",
      "Epoch 1175/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 1175: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 1176/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8283 - f1_score: 0.6863\n",
      "Epoch 1176: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8283 - f1_score: 0.6863\n",
      "Epoch 1177/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8286 - f1_score: 0.6869\n",
      "Epoch 1177: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8287 - f1_score: 0.6869\n",
      "Epoch 1178/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1178: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 1179/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8262 - f1_score: 0.6870\n",
      "Epoch 1179: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8262 - f1_score: 0.6870\n",
      "Epoch 1180/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8278 - f1_score: 0.6865\n",
      "Epoch 1180: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8279 - f1_score: 0.6865\n",
      "Epoch 1181/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8263 - f1_score: 0.6870\n",
      "Epoch 1181: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3866 - accuracy: 0.8262 - f1_score: 0.6870\n",
      "Epoch 1182/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 1182: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 1183/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8269 - f1_score: 0.6866\n",
      "Epoch 1183: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3869 - accuracy: 0.8270 - f1_score: 0.6865\n",
      "Epoch 1184/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8262 - f1_score: 0.6880\n",
      "Epoch 1184: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8262 - f1_score: 0.6878\n",
      "Epoch 1185/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8265 - f1_score: 0.6867\n",
      "Epoch 1185: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8265 - f1_score: 0.6868\n",
      "Epoch 1186/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 1186: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 1187/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8283 - f1_score: 0.6872\n",
      "Epoch 1187: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 1188/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8267 - f1_score: 0.6880\n",
      "Epoch 1188: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8267 - f1_score: 0.6880\n",
      "Epoch 1189/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6868\n",
      "Epoch 1189: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6868\n",
      "Epoch 1190/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8254 - f1_score: 0.6858\n",
      "Epoch 1190: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3893 - accuracy: 0.8254 - f1_score: 0.6857\n",
      "Epoch 1191/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8270 - f1_score: 0.6867\n",
      "Epoch 1191: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3871 - accuracy: 0.8270 - f1_score: 0.6867\n",
      "Epoch 1192/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 1192: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 1193/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8262 - f1_score: 0.6866\n",
      "Epoch 1193: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3883 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 1194/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8253 - f1_score: 0.6856\n",
      "Epoch 1194: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3895 - accuracy: 0.8253 - f1_score: 0.6856\n",
      "Epoch 1195/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 1195: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 1196/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6871\n",
      "Epoch 1196: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6871\n",
      "Epoch 1197/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8276 - f1_score: 0.6882\n",
      "Epoch 1197: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6882\n",
      "Epoch 1198/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 1198: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 1199/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 1199: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8274 - f1_score: 0.6871\n",
      "Epoch 1200/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 1200: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3881 - accuracy: 0.8261 - f1_score: 0.6867\n",
      "Epoch 1201/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8272 - f1_score: 0.6870\n",
      "Epoch 1201: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3867 - accuracy: 0.8274 - f1_score: 0.6871\n",
      "Epoch 1202/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1202: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1203/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8273 - f1_score: 0.6876\n",
      "Epoch 1203: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 1204/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8276 - f1_score: 0.6871\n",
      "Epoch 1204: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3866 - accuracy: 0.8277 - f1_score: 0.6872\n",
      "Epoch 1205/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1205: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6875\n",
      "Epoch 1206/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8282 - f1_score: 0.6864\n",
      "Epoch 1206: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3857 - accuracy: 0.8281 - f1_score: 0.6865\n",
      "Epoch 1207/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8273 - f1_score: 0.6867\n",
      "Epoch 1207: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8273 - f1_score: 0.6867\n",
      "Epoch 1208/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 1208: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3887 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 1209/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8282 - f1_score: 0.6870\n",
      "Epoch 1209: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8283 - f1_score: 0.6869\n",
      "Epoch 1210/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6873\n",
      "Epoch 1210: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6873\n",
      "Epoch 1211/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6876\n",
      "Epoch 1211: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6876\n",
      "Epoch 1212/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6879\n",
      "Epoch 1212: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6879\n",
      "Epoch 1213/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 1213: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 1214/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 1214: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8275 - f1_score: 0.6881\n",
      "Epoch 1215/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 1215: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6881\n",
      "Epoch 1216/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 1216: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 1217/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1217: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1218/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8276 - f1_score: 0.6866\n",
      "Epoch 1218: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8276 - f1_score: 0.6866\n",
      "Epoch 1219/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 1219: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8272 - f1_score: 0.6873\n",
      "Epoch 1220/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8278 - f1_score: 0.6869\n",
      "Epoch 1220: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3871 - accuracy: 0.8277 - f1_score: 0.6866\n",
      "Epoch 1221/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8271 - f1_score: 0.6849\n",
      "Epoch 1221: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8271 - f1_score: 0.6849\n",
      "Epoch 1222/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8254 - f1_score: 0.6854\n",
      "Epoch 1222: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3896 - accuracy: 0.8254 - f1_score: 0.6854\n",
      "Epoch 1223/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 1223: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 1224/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 1224: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 1225/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8273 - f1_score: 0.6859\n",
      "Epoch 1225: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6860\n",
      "Epoch 1226/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 1226: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 1227/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6872\n",
      "Epoch 1227: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6872\n",
      "Epoch 1228/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8267 - f1_score: 0.6862\n",
      "Epoch 1228: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3877 - accuracy: 0.8267 - f1_score: 0.6862\n",
      "Epoch 1229/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6868\n",
      "Epoch 1229: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6868\n",
      "Epoch 1230/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8260 - f1_score: 0.6864\n",
      "Epoch 1230: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3880 - accuracy: 0.8261 - f1_score: 0.6864\n",
      "Epoch 1231/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8263 - f1_score: 0.6878\n",
      "Epoch 1231: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3872 - accuracy: 0.8262 - f1_score: 0.6877\n",
      "Epoch 1232/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6870\n",
      "Epoch 1232: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6870\n",
      "Epoch 1233/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 1233: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 1234/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8278 - f1_score: 0.6867\n",
      "Epoch 1234: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8278 - f1_score: 0.6866\n",
      "Epoch 1235/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 1235: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 1236/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8259 - f1_score: 0.6871\n",
      "Epoch 1236: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3880 - accuracy: 0.8259 - f1_score: 0.6871\n",
      "Epoch 1237/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 1237: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6874\n",
      "Epoch 1238/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 1238: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 1239/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8267 - f1_score: 0.6868\n",
      "Epoch 1239: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6868\n",
      "Epoch 1240/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8257 - f1_score: 0.6869\n",
      "Epoch 1240: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3869 - accuracy: 0.8257 - f1_score: 0.6868\n",
      "Epoch 1241/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 1241: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1242/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8278 - f1_score: 0.6879\n",
      "Epoch 1242: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 1243/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8263 - f1_score: 0.6862\n",
      "Epoch 1243: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8264 - f1_score: 0.6862\n",
      "Epoch 1244/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6863\n",
      "Epoch 1244: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6862\n",
      "Epoch 1245/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1245: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 1246/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8276 - f1_score: 0.6885\n",
      "Epoch 1246: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8275 - f1_score: 0.6884\n",
      "Epoch 1247/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6877\n",
      "Epoch 1247: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 1248/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8253 - f1_score: 0.6874\n",
      "Epoch 1248: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8254 - f1_score: 0.6874\n",
      "Epoch 1249/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8250 - f1_score: 0.6862\n",
      "Epoch 1249: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3894 - accuracy: 0.8250 - f1_score: 0.6862\n",
      "Epoch 1250/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8258 - f1_score: 0.6873\n",
      "Epoch 1250: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8258 - f1_score: 0.6873\n",
      "Epoch 1251/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 1251: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 1252/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 1252: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 1253/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6869\n",
      "Epoch 1253: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 1254/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 1254: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 1255/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8252 - f1_score: 0.6861\n",
      "Epoch 1255: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8252 - f1_score: 0.6861\n",
      "Epoch 1256/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 1256: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 1257/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 1257: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8271 - f1_score: 0.6867\n",
      "Epoch 1258/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.8256 - f1_score: 0.6861\n",
      "Epoch 1258: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8256 - f1_score: 0.6861\n",
      "Epoch 1259/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8261 - f1_score: 0.6863\n",
      "Epoch 1259: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8261 - f1_score: 0.6862\n",
      "Epoch 1260/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8252 - f1_score: 0.6864\n",
      "Epoch 1260: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8251 - f1_score: 0.6864\n",
      "Epoch 1261/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 1261: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8264 - f1_score: 0.6874\n",
      "Epoch 1262/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8274 - f1_score: 0.6868\n",
      "Epoch 1262: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8275 - f1_score: 0.6868\n",
      "Epoch 1263/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8267 - f1_score: 0.6865\n",
      "Epoch 1263: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8267 - f1_score: 0.6865\n",
      "Epoch 1264/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8249 - f1_score: 0.6871\n",
      "Epoch 1264: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3901 - accuracy: 0.8249 - f1_score: 0.6871\n",
      "Epoch 1265/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 1265: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 1266/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6882\n",
      "Epoch 1266: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8268 - f1_score: 0.6883\n",
      "Epoch 1267/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8258 - f1_score: 0.6871\n",
      "Epoch 1267: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8259 - f1_score: 0.6871\n",
      "Epoch 1268/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6874\n",
      "Epoch 1268: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 1269/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 1269: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8279 - f1_score: 0.6876\n",
      "Epoch 1270/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8258 - f1_score: 0.6860\n",
      "Epoch 1270: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8258 - f1_score: 0.6861\n",
      "Epoch 1271/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8256 - f1_score: 0.6861\n",
      "Epoch 1271: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8255 - f1_score: 0.6860\n",
      "Epoch 1272/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 1272: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 1273/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 1273: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1274/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 1274: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 1275/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6879\n",
      "Epoch 1275: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6880\n",
      "Epoch 1276/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8262 - f1_score: 0.6868\n",
      "Epoch 1276: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8262 - f1_score: 0.6868\n",
      "Epoch 1277/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8263 - f1_score: 0.6874\n",
      "Epoch 1277: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8264 - f1_score: 0.6874\n",
      "Epoch 1278/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6876\n",
      "Epoch 1278: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6877\n",
      "Epoch 1279/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6878\n",
      "Epoch 1279: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6878\n",
      "Epoch 1280/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6871\n",
      "Epoch 1280: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 1281/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6871\n",
      "Epoch 1281: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8264 - f1_score: 0.6870\n",
      "Epoch 1282/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8261 - f1_score: 0.6863\n",
      "Epoch 1282: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8262 - f1_score: 0.6864\n",
      "Epoch 1283/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8269 - f1_score: 0.6877\n",
      "Epoch 1283: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 1284/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8262 - f1_score: 0.6869\n",
      "Epoch 1284: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3885 - accuracy: 0.8262 - f1_score: 0.6869\n",
      "Epoch 1285/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6863\n",
      "Epoch 1285: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6863\n",
      "Epoch 1286/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8265 - f1_score: 0.6861\n",
      "Epoch 1286: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8265 - f1_score: 0.6861\n",
      "Epoch 1287/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8269 - f1_score: 0.6860\n",
      "Epoch 1287: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8269 - f1_score: 0.6860\n",
      "Epoch 1288/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8270 - f1_score: 0.6879\n",
      "Epoch 1288: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8270 - f1_score: 0.6879\n",
      "Epoch 1289/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6870\n",
      "Epoch 1289: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6870\n",
      "Epoch 1290/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6872\n",
      "Epoch 1290: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6872\n",
      "Epoch 1291/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6864\n",
      "Epoch 1291: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6864\n",
      "Epoch 1292/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8278 - f1_score: 0.6868\n",
      "Epoch 1292: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8277 - f1_score: 0.6867\n",
      "Epoch 1293/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 1293: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 1294/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8245 - f1_score: 0.6870\n",
      "Epoch 1294: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3909 - accuracy: 0.8245 - f1_score: 0.6869\n",
      "Epoch 1295/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8258 - f1_score: 0.6871\n",
      "Epoch 1295: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8258 - f1_score: 0.6872\n",
      "Epoch 1296/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8254 - f1_score: 0.6865\n",
      "Epoch 1296: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3893 - accuracy: 0.8254 - f1_score: 0.6864\n",
      "Epoch 1297/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6867\n",
      "Epoch 1297: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6867\n",
      "Epoch 1298/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 1298: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 1299/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8260 - f1_score: 0.6868\n",
      "Epoch 1299: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8260 - f1_score: 0.6868\n",
      "Epoch 1300/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 1300: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 1301/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1301: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8272 - f1_score: 0.6876\n",
      "Epoch 1302/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.8245 - f1_score: 0.6858\n",
      "Epoch 1302: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3897 - accuracy: 0.8245 - f1_score: 0.6858\n",
      "Epoch 1303/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8251 - f1_score: 0.6866\n",
      "Epoch 1303: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8250 - f1_score: 0.6866\n",
      "Epoch 1304/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8231 - f1_score: 0.6850\n",
      "Epoch 1304: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3922 - accuracy: 0.8231 - f1_score: 0.6849\n",
      "Epoch 1305/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6864\n",
      "Epoch 1305: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6864\n",
      "Epoch 1306/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8251 - f1_score: 0.6858\n",
      "Epoch 1306: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8250 - f1_score: 0.6859\n",
      "Epoch 1307/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6859\n",
      "Epoch 1307: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6858\n",
      "Epoch 1308/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 1308: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1309/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6867\n",
      "Epoch 1309: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6867\n",
      "Epoch 1310/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 1310: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 1311/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8287 - f1_score: 0.6876\n",
      "Epoch 1311: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8287 - f1_score: 0.6876\n",
      "Epoch 1312/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8269 - f1_score: 0.6877\n",
      "Epoch 1312: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8269 - f1_score: 0.6877\n",
      "Epoch 1313/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6865\n",
      "Epoch 1313: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8267 - f1_score: 0.6865\n",
      "Epoch 1314/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6868\n",
      "Epoch 1314: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6868\n",
      "Epoch 1315/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 1315: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 1316/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 1316: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8268 - f1_score: 0.6878\n",
      "Epoch 1317/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8272 - f1_score: 0.6869\n",
      "Epoch 1317: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 1318/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8274 - f1_score: 0.6883\n",
      "Epoch 1318: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8276 - f1_score: 0.6884\n",
      "Epoch 1319/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8278 - f1_score: 0.6892\n",
      "Epoch 1319: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8278 - f1_score: 0.6891\n",
      "Epoch 1320/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6884\n",
      "Epoch 1320: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6883\n",
      "Epoch 1321/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8257 - f1_score: 0.6877\n",
      "Epoch 1321: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8257 - f1_score: 0.6877\n",
      "Epoch 1322/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 1322: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 1323/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8275 - f1_score: 0.6884\n",
      "Epoch 1323: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8275 - f1_score: 0.6884\n",
      "Epoch 1324/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6880\n",
      "Epoch 1324: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6880\n",
      "Epoch 1325/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8273 - f1_score: 0.6866\n",
      "Epoch 1325: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8273 - f1_score: 0.6867\n",
      "Epoch 1326/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6884\n",
      "Epoch 1326: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8269 - f1_score: 0.6883\n",
      "Epoch 1327/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8259 - f1_score: 0.6883\n",
      "Epoch 1327: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8258 - f1_score: 0.6883\n",
      "Epoch 1328/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8269 - f1_score: 0.6868\n",
      "Epoch 1328: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8269 - f1_score: 0.6868\n",
      "Epoch 1329/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 1329: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 1330/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8266 - f1_score: 0.6881\n",
      "Epoch 1330: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8266 - f1_score: 0.6880\n",
      "Epoch 1331/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6877\n",
      "Epoch 1331: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6877\n",
      "Epoch 1332/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1332: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1333/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8266 - f1_score: 0.6869\n",
      "Epoch 1333: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8266 - f1_score: 0.6868\n",
      "Epoch 1334/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8253 - f1_score: 0.6854\n",
      "Epoch 1334: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3911 - accuracy: 0.8253 - f1_score: 0.6854\n",
      "Epoch 1335/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8250 - f1_score: 0.6852\n",
      "Epoch 1335: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3903 - accuracy: 0.8250 - f1_score: 0.6852\n",
      "Epoch 1336/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8258 - f1_score: 0.6886\n",
      "Epoch 1336: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8258 - f1_score: 0.6886\n",
      "Epoch 1337/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8266 - f1_score: 0.6876\n",
      "Epoch 1337: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8266 - f1_score: 0.6876\n",
      "Epoch 1338/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 1338: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 1339/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1339: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1340/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 1340: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 1341/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8264 - f1_score: 0.6868\n",
      "Epoch 1341: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8264 - f1_score: 0.6869\n",
      "Epoch 1342/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6870\n",
      "Epoch 1342: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6870\n",
      "Epoch 1343/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 1343: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 1344/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 1344: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 1345/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 1345: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 1346/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 1346: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 1347/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 1347: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 1348/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8287 - f1_score: 0.6889\n",
      "Epoch 1348: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3834 - accuracy: 0.8289 - f1_score: 0.6890\n",
      "Epoch 1349/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 1349: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 1350/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8281 - f1_score: 0.6881\n",
      "Epoch 1350: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8281 - f1_score: 0.6881\n",
      "Epoch 1351/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8267 - f1_score: 0.6866\n",
      "Epoch 1351: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8267 - f1_score: 0.6866\n",
      "Epoch 1352/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3878 - accuracy: 0.8270 - f1_score: 0.6860\n",
      "Epoch 1352: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8270 - f1_score: 0.6860\n",
      "Epoch 1353/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 1353: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 1354/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 1354: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 1355/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 1355: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6873\n",
      "Epoch 1356/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8271 - f1_score: 0.6881\n",
      "Epoch 1356: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8271 - f1_score: 0.6881\n",
      "Epoch 1357/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 1357: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 1358/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6871\n",
      "Epoch 1358: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8276 - f1_score: 0.6871\n",
      "Epoch 1359/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3897 - accuracy: 0.8248 - f1_score: 0.6866\n",
      "Epoch 1359: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3897 - accuracy: 0.8248 - f1_score: 0.6866\n",
      "Epoch 1360/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 1360: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 1361/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 1361: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 1362/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 1362: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 1363/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8273 - f1_score: 0.6876\n",
      "Epoch 1363: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 1364/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6873\n",
      "Epoch 1364: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 1365/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 1365: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8268 - f1_score: 0.6868\n",
      "Epoch 1366/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8279 - f1_score: 0.6857\n",
      "Epoch 1366: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8279 - f1_score: 0.6857\n",
      "Epoch 1367/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6862\n",
      "Epoch 1367: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6862\n",
      "Epoch 1368/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8275 - f1_score: 0.6879\n",
      "Epoch 1368: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8275 - f1_score: 0.6880\n",
      "Epoch 1369/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6871\n",
      "Epoch 1369: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6871\n",
      "Epoch 1370/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1370: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 1371/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 1371: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 1372/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6880\n",
      "Epoch 1372: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6880\n",
      "Epoch 1373/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6871\n",
      "Epoch 1373: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6871\n",
      "Epoch 1374/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 1374: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8278 - f1_score: 0.6877\n",
      "Epoch 1375/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 1375: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 1376/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 1376: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3828 - accuracy: 0.8293 - f1_score: 0.6876\n",
      "Epoch 1377/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8292 - f1_score: 0.6871\n",
      "Epoch 1377: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8293 - f1_score: 0.6872\n",
      "Epoch 1378/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8293 - f1_score: 0.6868\n",
      "Epoch 1378: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6869\n",
      "Epoch 1379/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 1379: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 1380/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6881\n",
      "Epoch 1380: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6881\n",
      "Epoch 1381/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6884\n",
      "Epoch 1381: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6885\n",
      "Epoch 1382/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 1382: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 1383/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8249 - f1_score: 0.6870\n",
      "Epoch 1383: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8249 - f1_score: 0.6870\n",
      "Epoch 1384/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8262 - f1_score: 0.6876\n",
      "Epoch 1384: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6876\n",
      "Epoch 1385/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 1385: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1386/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8274 - f1_score: 0.6871\n",
      "Epoch 1386: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 1387/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6873\n",
      "Epoch 1387: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6873\n",
      "Epoch 1388/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 1388: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 1389/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 1389: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 1390/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8284 - f1_score: 0.6866\n",
      "Epoch 1390: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8284 - f1_score: 0.6866\n",
      "Epoch 1391/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8289 - f1_score: 0.6873\n",
      "Epoch 1391: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8290 - f1_score: 0.6871\n",
      "Epoch 1392/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 1392: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 1393/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8258 - f1_score: 0.6878\n",
      "Epoch 1393: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8259 - f1_score: 0.6878\n",
      "Epoch 1394/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8262 - f1_score: 0.6873\n",
      "Epoch 1394: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8263 - f1_score: 0.6874\n",
      "Epoch 1395/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8266 - f1_score: 0.6880\n",
      "Epoch 1395: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8266 - f1_score: 0.6878\n",
      "Epoch 1396/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.8265 - f1_score: 0.6864\n",
      "Epoch 1396: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8265 - f1_score: 0.6864\n",
      "Epoch 1397/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8264 - f1_score: 0.6874\n",
      "Epoch 1397: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8264 - f1_score: 0.6874\n",
      "Epoch 1398/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8257 - f1_score: 0.6876\n",
      "Epoch 1398: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8258 - f1_score: 0.6876\n",
      "Epoch 1399/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6877\n",
      "Epoch 1399: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6877\n",
      "Epoch 1400/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8257 - f1_score: 0.6864\n",
      "Epoch 1400: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8256 - f1_score: 0.6864\n",
      "Epoch 1401/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8272 - f1_score: 0.6868\n",
      "Epoch 1401: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8273 - f1_score: 0.6868\n",
      "Epoch 1402/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 1402: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1403/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 1403: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 1404/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 1404: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 1405/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8267 - f1_score: 0.6868\n",
      "Epoch 1405: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6869\n",
      "Epoch 1406/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1406: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1407/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 1407: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 1408/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 1408: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 1409/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8268 - f1_score: 0.6871\n",
      "Epoch 1409: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 1410/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8262 - f1_score: 0.6866\n",
      "Epoch 1410: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8262 - f1_score: 0.6866\n",
      "Epoch 1411/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8266 - f1_score: 0.6864\n",
      "Epoch 1411: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8265 - f1_score: 0.6863\n",
      "Epoch 1412/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 1412: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 1413/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8291 - f1_score: 0.6869\n",
      "Epoch 1413: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8290 - f1_score: 0.6869\n",
      "Epoch 1414/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6867\n",
      "Epoch 1414: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8273 - f1_score: 0.6867\n",
      "Epoch 1415/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8271 - f1_score: 0.6865\n",
      "Epoch 1415: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8271 - f1_score: 0.6865\n",
      "Epoch 1416/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8263 - f1_score: 0.6875\n",
      "Epoch 1416: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 1417/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 1417: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 1418/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 1418: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 1419/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 1419: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 1420/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8283 - f1_score: 0.6872\n",
      "Epoch 1420: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 1421/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8267 - f1_score: 0.6873\n",
      "Epoch 1421: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8267 - f1_score: 0.6873\n",
      "Epoch 1422/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8265 - f1_score: 0.6873\n",
      "Epoch 1422: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 1423/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 1423: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 1424/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 1424: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 1425/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8272 - f1_score: 0.6873\n",
      "Epoch 1425: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8272 - f1_score: 0.6872\n",
      "Epoch 1426/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 1426: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 1427/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8262 - f1_score: 0.6872\n",
      "Epoch 1427: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8262 - f1_score: 0.6871\n",
      "Epoch 1428/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 1428: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3887 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 1429/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 1429: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 1430/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8262 - f1_score: 0.6882\n",
      "Epoch 1430: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8262 - f1_score: 0.6882\n",
      "Epoch 1431/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8262 - f1_score: 0.6872\n",
      "Epoch 1431: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8262 - f1_score: 0.6872\n",
      "Epoch 1432/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8267 - f1_score: 0.6872\n",
      "Epoch 1432: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8267 - f1_score: 0.6872\n",
      "Epoch 1433/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6867\n",
      "Epoch 1433: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6869\n",
      "Epoch 1434/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 1434: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 1435/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8269 - f1_score: 0.6872\n",
      "Epoch 1435: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6872\n",
      "Epoch 1436/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8265 - f1_score: 0.6870\n",
      "Epoch 1436: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8265 - f1_score: 0.6870\n",
      "Epoch 1437/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6874\n",
      "Epoch 1437: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 1438/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 1438: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8259 - f1_score: 0.6866\n",
      "Epoch 1439/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8275 - f1_score: 0.6872\n",
      "Epoch 1439: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8276 - f1_score: 0.6871\n",
      "Epoch 1440/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8279 - f1_score: 0.6867\n",
      "Epoch 1440: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8279 - f1_score: 0.6867\n",
      "Epoch 1441/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1441: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 1442/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8259 - f1_score: 0.6872\n",
      "Epoch 1442: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8259 - f1_score: 0.6871\n",
      "Epoch 1443/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6879\n",
      "Epoch 1443: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8263 - f1_score: 0.6878\n",
      "Epoch 1444/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6879\n",
      "Epoch 1444: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6879\n",
      "Epoch 1445/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 1445: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 1446/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8264 - f1_score: 0.6882\n",
      "Epoch 1446: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8264 - f1_score: 0.6882\n",
      "Epoch 1447/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8270 - f1_score: 0.6863\n",
      "Epoch 1447: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3879 - accuracy: 0.8269 - f1_score: 0.6862\n",
      "Epoch 1448/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8265 - f1_score: 0.6881\n",
      "Epoch 1448: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8264 - f1_score: 0.6881\n",
      "Epoch 1449/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6877\n",
      "Epoch 1449: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6877\n",
      "Epoch 1450/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6876\n",
      "Epoch 1450: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 1451/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8246 - f1_score: 0.6856\n",
      "Epoch 1451: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8246 - f1_score: 0.6855\n",
      "Epoch 1452/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8274 - f1_score: 0.6883\n",
      "Epoch 1452: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 1453/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 1453: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 1454/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8261 - f1_score: 0.6875\n",
      "Epoch 1454: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8260 - f1_score: 0.6876\n",
      "Epoch 1455/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8271 - f1_score: 0.6880\n",
      "Epoch 1455: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8271 - f1_score: 0.6879\n",
      "Epoch 1456/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8265 - f1_score: 0.6868\n",
      "Epoch 1456: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8265 - f1_score: 0.6868\n",
      "Epoch 1457/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1457: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8271 - f1_score: 0.6874\n",
      "Epoch 1458/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8275 - f1_score: 0.6879\n",
      "Epoch 1458: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8275 - f1_score: 0.6879\n",
      "Epoch 1459/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1459: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1460/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6882\n",
      "Epoch 1460: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6882\n",
      "Epoch 1461/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8267 - f1_score: 0.6876\n",
      "Epoch 1461: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 1462/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8272 - f1_score: 0.6888\n",
      "Epoch 1462: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8271 - f1_score: 0.6888\n",
      "Epoch 1463/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8250 - f1_score: 0.6884\n",
      "Epoch 1463: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8251 - f1_score: 0.6884\n",
      "Epoch 1464/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 1464: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 1465/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8288 - f1_score: 0.6871\n",
      "Epoch 1465: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8288 - f1_score: 0.6871\n",
      "Epoch 1466/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8270 - f1_score: 0.6877\n",
      "Epoch 1466: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8271 - f1_score: 0.6876\n",
      "Epoch 1467/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8278 - f1_score: 0.6881\n",
      "Epoch 1467: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 1468/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8270 - f1_score: 0.6878\n",
      "Epoch 1468: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6878\n",
      "Epoch 1469/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8252 - f1_score: 0.6877\n",
      "Epoch 1469: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3895 - accuracy: 0.8253 - f1_score: 0.6878\n",
      "Epoch 1470/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8264 - f1_score: 0.6877\n",
      "Epoch 1470: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8265 - f1_score: 0.6878\n",
      "Epoch 1471/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6875\n",
      "Epoch 1471: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1472/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 1472: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 1473/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 1473: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 1474/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 1474: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 1475/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 1475: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 1476/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 1476: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 1477/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8253 - f1_score: 0.6866\n",
      "Epoch 1477: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3893 - accuracy: 0.8253 - f1_score: 0.6866\n",
      "Epoch 1478/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 1478: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 1479/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 1479: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 1480/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 1480: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 1481/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8293 - f1_score: 0.6871\n",
      "Epoch 1481: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8293 - f1_score: 0.6871\n",
      "Epoch 1482/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8271 - f1_score: 0.6871\n",
      "Epoch 1482: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6871\n",
      "Epoch 1483/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6882\n",
      "Epoch 1483: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6882\n",
      "Epoch 1484/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8260 - f1_score: 0.6873\n",
      "Epoch 1484: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3880 - accuracy: 0.8260 - f1_score: 0.6874\n",
      "Epoch 1485/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1485: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 1486/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8278 - f1_score: 0.6868\n",
      "Epoch 1486: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6866\n",
      "Epoch 1487/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 1487: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6869\n",
      "Epoch 1488/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6867\n",
      "Epoch 1488: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6867\n",
      "Epoch 1489/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8264 - f1_score: 0.6869\n",
      "Epoch 1489: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8264 - f1_score: 0.6868\n",
      "Epoch 1490/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 1490: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6876\n",
      "Epoch 1491/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6884\n",
      "Epoch 1491: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6884\n",
      "Epoch 1492/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8288 - f1_score: 0.6866\n",
      "Epoch 1492: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8288 - f1_score: 0.6866\n",
      "Epoch 1493/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 1493: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6877\n",
      "Epoch 1494/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8262 - f1_score: 0.6857\n",
      "Epoch 1494: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3884 - accuracy: 0.8264 - f1_score: 0.6857\n",
      "Epoch 1495/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 1495: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1496/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6868\n",
      "Epoch 1496: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 1497/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8259 - f1_score: 0.6870\n",
      "Epoch 1497: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8259 - f1_score: 0.6869\n",
      "Epoch 1498/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6877\n",
      "Epoch 1498: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8263 - f1_score: 0.6876\n",
      "Epoch 1499/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8264 - f1_score: 0.6876\n",
      "Epoch 1499: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8263 - f1_score: 0.6876\n",
      "Epoch 1500/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 1500: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 1501/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 1501: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 1502/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 1502: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 1503/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8292 - f1_score: 0.6874\n",
      "Epoch 1503: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8291 - f1_score: 0.6874\n",
      "Epoch 1504/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 1504: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 1505/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8272 - f1_score: 0.6876\n",
      "Epoch 1505: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8272 - f1_score: 0.6876\n",
      "Epoch 1506/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 1506: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8286 - f1_score: 0.6874\n",
      "Epoch 1507/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6870\n",
      "Epoch 1507: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6870\n",
      "Epoch 1508/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8274 - f1_score: 0.6869\n",
      "Epoch 1508: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3875 - accuracy: 0.8274 - f1_score: 0.6869\n",
      "Epoch 1509/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 1509: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 1510/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 1510: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8275 - f1_score: 0.6875\n",
      "Epoch 1511/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 1511: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 1512/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8266 - f1_score: 0.6876\n",
      "Epoch 1512: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3886 - accuracy: 0.8266 - f1_score: 0.6877\n",
      "Epoch 1513/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 1513: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 1514/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8279 - f1_score: 0.6868\n",
      "Epoch 1514: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8279 - f1_score: 0.6867\n",
      "Epoch 1515/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 1515: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 1516/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6874\n",
      "Epoch 1516: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6874\n",
      "Epoch 1517/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 1517: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6878\n",
      "Epoch 1518/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8268 - f1_score: 0.6880\n",
      "Epoch 1518: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8267 - f1_score: 0.6880\n",
      "Epoch 1519/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8259 - f1_score: 0.6876\n",
      "Epoch 1519: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8259 - f1_score: 0.6877\n",
      "Epoch 1520/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8249 - f1_score: 0.6884\n",
      "Epoch 1520: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3883 - accuracy: 0.8249 - f1_score: 0.6884\n",
      "Epoch 1521/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 1521: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3890 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 1522/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8263 - f1_score: 0.6872\n",
      "Epoch 1522: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8264 - f1_score: 0.6872\n",
      "Epoch 1523/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 1523: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 1524/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8271 - f1_score: 0.6870\n",
      "Epoch 1524: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8270 - f1_score: 0.6869\n",
      "Epoch 1525/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6867\n",
      "Epoch 1525: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 1526/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6870\n",
      "Epoch 1526: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6870\n",
      "Epoch 1527/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 1527: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 1528/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 1528: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 1529/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8274 - f1_score: 0.6874\n",
      "Epoch 1529: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 1530/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 1530: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 1531/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8263 - f1_score: 0.6865\n",
      "Epoch 1531: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8264 - f1_score: 0.6864\n",
      "Epoch 1532/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 1532: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8271 - f1_score: 0.6870\n",
      "Epoch 1533/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8290 - f1_score: 0.6870\n",
      "Epoch 1533: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8290 - f1_score: 0.6870\n",
      "Epoch 1534/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 1534: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 1535/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 1535: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1536/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8261 - f1_score: 0.6869\n",
      "Epoch 1536: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8260 - f1_score: 0.6869\n",
      "Epoch 1537/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 1537: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8280 - f1_score: 0.6883\n",
      "Epoch 1538/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 1538: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 1539/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6877\n",
      "Epoch 1539: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6877\n",
      "Epoch 1540/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 1540: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 1541/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8253 - f1_score: 0.6865\n",
      "Epoch 1541: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3896 - accuracy: 0.8252 - f1_score: 0.6866\n",
      "Epoch 1542/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8270 - f1_score: 0.6869\n",
      "Epoch 1542: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 1543/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8274 - f1_score: 0.6868\n",
      "Epoch 1543: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8274 - f1_score: 0.6868\n",
      "Epoch 1544/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8278 - f1_score: 0.6883\n",
      "Epoch 1544: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6882\n",
      "Epoch 1545/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8280 - f1_score: 0.6883\n",
      "Epoch 1545: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 1546/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 1546: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 1547/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8266 - f1_score: 0.6878\n",
      "Epoch 1547: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3874 - accuracy: 0.8265 - f1_score: 0.6878\n",
      "Epoch 1548/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1548: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1549/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8277 - f1_score: 0.6861\n",
      "Epoch 1549: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6861\n",
      "Epoch 1550/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6871\n",
      "Epoch 1550: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6872\n",
      "Epoch 1551/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 1551: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 1552/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6876\n",
      "Epoch 1552: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3829 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 1553/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8289 - f1_score: 0.6891\n",
      "Epoch 1553: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6892\n",
      "Epoch 1554/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 1554: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3830 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 1555/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 1555: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6890\n",
      "Epoch 1556/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8273 - f1_score: 0.6878\n",
      "Epoch 1556: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8273 - f1_score: 0.6878\n",
      "Epoch 1557/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6876\n",
      "Epoch 1557: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6876\n",
      "Epoch 1558/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 1558: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 1559/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8266 - f1_score: 0.6876\n",
      "Epoch 1559: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8266 - f1_score: 0.6876\n",
      "Epoch 1560/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 1560: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 1561/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8272 - f1_score: 0.6866\n",
      "Epoch 1561: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3876 - accuracy: 0.8272 - f1_score: 0.6866\n",
      "Epoch 1562/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6877\n",
      "Epoch 1562: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6877\n",
      "Epoch 1563/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 1563: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 1564/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 1564: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 1565/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 1565: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 1566/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 1566: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3832 - accuracy: 0.8293 - f1_score: 0.6878\n",
      "Epoch 1567/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 1567: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 1568/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8289 - f1_score: 0.6886\n",
      "Epoch 1568: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 1569/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8278 - f1_score: 0.6888\n",
      "Epoch 1569: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6889\n",
      "Epoch 1570/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 1570: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 1571/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8262 - f1_score: 0.6873\n",
      "Epoch 1571: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 1572/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8264 - f1_score: 0.6882\n",
      "Epoch 1572: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8263 - f1_score: 0.6880\n",
      "Epoch 1573/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6862\n",
      "Epoch 1573: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6862\n",
      "Epoch 1574/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 1574: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 1575/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 1575: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 1576/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 1576: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 1577/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 1577: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 1578/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1578: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3888 - accuracy: 0.8269 - f1_score: 0.6872\n",
      "Epoch 1579/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 1579: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 1580/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6881\n",
      "Epoch 1580: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6880\n",
      "Epoch 1581/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6888\n",
      "Epoch 1581: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6887\n",
      "Epoch 1582/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 1582: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 1583/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8277 - f1_score: 0.6882\n",
      "Epoch 1583: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 1584/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1584: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1585/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8271 - f1_score: 0.6867\n",
      "Epoch 1585: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8272 - f1_score: 0.6868\n",
      "Epoch 1586/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8265 - f1_score: 0.6877\n",
      "Epoch 1586: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8265 - f1_score: 0.6877\n",
      "Epoch 1587/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8261 - f1_score: 0.6873\n",
      "Epoch 1587: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8261 - f1_score: 0.6873\n",
      "Epoch 1588/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 1588: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 1589/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 1589: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6880\n",
      "Epoch 1590/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8279 - f1_score: 0.6885\n",
      "Epoch 1590: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8278 - f1_score: 0.6884\n",
      "Epoch 1591/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 1591: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 1592/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6882\n",
      "Epoch 1592: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8271 - f1_score: 0.6880\n",
      "Epoch 1593/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8272 - f1_score: 0.6863\n",
      "Epoch 1593: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3868 - accuracy: 0.8271 - f1_score: 0.6865\n",
      "Epoch 1594/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 1594: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 1595/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8272 - f1_score: 0.6870\n",
      "Epoch 1595: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8272 - f1_score: 0.6870\n",
      "Epoch 1596/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8258 - f1_score: 0.6876\n",
      "Epoch 1596: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3871 - accuracy: 0.8258 - f1_score: 0.6875\n",
      "Epoch 1597/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8266 - f1_score: 0.6873\n",
      "Epoch 1597: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3867 - accuracy: 0.8266 - f1_score: 0.6873\n",
      "Epoch 1598/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8266 - f1_score: 0.6882\n",
      "Epoch 1598: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8265 - f1_score: 0.6882\n",
      "Epoch 1599/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8259 - f1_score: 0.6870\n",
      "Epoch 1599: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3884 - accuracy: 0.8259 - f1_score: 0.6870\n",
      "Epoch 1600/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8260 - f1_score: 0.6875\n",
      "Epoch 1600: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3868 - accuracy: 0.8260 - f1_score: 0.6875\n",
      "Epoch 1601/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8278 - f1_score: 0.6868\n",
      "Epoch 1601: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3870 - accuracy: 0.8278 - f1_score: 0.6868\n",
      "Epoch 1602/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6872\n",
      "Epoch 1602: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6871\n",
      "Epoch 1603/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8269 - f1_score: 0.6872\n",
      "Epoch 1603: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3876 - accuracy: 0.8269 - f1_score: 0.6872\n",
      "Epoch 1604/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8258 - f1_score: 0.6867\n",
      "Epoch 1604: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3884 - accuracy: 0.8258 - f1_score: 0.6867\n",
      "Epoch 1605/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8264 - f1_score: 0.6863\n",
      "Epoch 1605: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3885 - accuracy: 0.8265 - f1_score: 0.6862\n",
      "Epoch 1606/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8243 - f1_score: 0.6864\n",
      "Epoch 1606: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3909 - accuracy: 0.8243 - f1_score: 0.6864\n",
      "Epoch 1607/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.8253 - f1_score: 0.6873\n",
      "Epoch 1607: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3881 - accuracy: 0.8254 - f1_score: 0.6875\n",
      "Epoch 1608/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 1608: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3864 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 1609/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8264 - f1_score: 0.6868\n",
      "Epoch 1609: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8265 - f1_score: 0.6869\n",
      "Epoch 1610/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1610: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1611/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8255 - f1_score: 0.6863\n",
      "Epoch 1611: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3906 - accuracy: 0.8255 - f1_score: 0.6863\n",
      "Epoch 1612/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8265 - f1_score: 0.6865\n",
      "Epoch 1612: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3873 - accuracy: 0.8266 - f1_score: 0.6866\n",
      "Epoch 1613/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 1613: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 1614/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 1614: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3865 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 1615/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 1615: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 1616/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 1616: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 1617/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8263 - f1_score: 0.6865\n",
      "Epoch 1617: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3880 - accuracy: 0.8263 - f1_score: 0.6866\n",
      "Epoch 1618/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8272 - f1_score: 0.6869\n",
      "Epoch 1618: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8272 - f1_score: 0.6869\n",
      "Epoch 1619/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8291 - f1_score: 0.6873\n",
      "Epoch 1619: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8290 - f1_score: 0.6871\n",
      "Epoch 1620/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 1620: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 1621/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1621: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1622/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1622: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 1623/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8289 - f1_score: 0.6866\n",
      "Epoch 1623: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8288 - f1_score: 0.6865\n",
      "Epoch 1624/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 1624: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3865 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 1625/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6868\n",
      "Epoch 1625: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6868\n",
      "Epoch 1626/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 1626: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6876\n",
      "Epoch 1627/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8287 - f1_score: 0.6873\n",
      "Epoch 1627: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8286 - f1_score: 0.6872\n",
      "Epoch 1628/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 1628: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 1629/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 1629: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 1630/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 1630: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 1631/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6882\n",
      "Epoch 1631: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6881\n",
      "Epoch 1632/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6876\n",
      "Epoch 1632: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3863 - accuracy: 0.8273 - f1_score: 0.6876\n",
      "Epoch 1633/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 1633: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 1634/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8269 - f1_score: 0.6867\n",
      "Epoch 1634: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3869 - accuracy: 0.8269 - f1_score: 0.6867\n",
      "Epoch 1635/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8287 - f1_score: 0.6871\n",
      "Epoch 1635: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8287 - f1_score: 0.6871\n",
      "Epoch 1636/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 1636: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6882\n",
      "Epoch 1637/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6887\n",
      "Epoch 1637: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 1638/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6892\n",
      "Epoch 1638: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6892\n",
      "Epoch 1639/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8269 - f1_score: 0.6886\n",
      "Epoch 1639: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8269 - f1_score: 0.6887\n",
      "Epoch 1640/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8283 - f1_score: 0.6887\n",
      "Epoch 1640: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3833 - accuracy: 0.8283 - f1_score: 0.6887\n",
      "Epoch 1641/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 1641: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 1642/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1642: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 1643/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 1643: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 1644/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8284 - f1_score: 0.6875\n",
      "Epoch 1644: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 1645/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 1645: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3864 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 1646/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 1646: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 1647/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 1647: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6875\n",
      "Epoch 1648/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 1648: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 1649/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 1649: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 1650/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8304 - f1_score: 0.6878\n",
      "Epoch 1650: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3821 - accuracy: 0.8303 - f1_score: 0.6878\n",
      "Epoch 1651/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6883\n",
      "Epoch 1651: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6883\n",
      "Epoch 1652/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8281 - f1_score: 0.6870\n",
      "Epoch 1652: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8280 - f1_score: 0.6867\n",
      "Epoch 1653/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 1653: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 1654/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 1654: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 1655/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6875\n",
      "Epoch 1655: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 1656/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8291 - f1_score: 0.6873\n",
      "Epoch 1656: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8293 - f1_score: 0.6874\n",
      "Epoch 1657/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8276 - f1_score: 0.6867\n",
      "Epoch 1657: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8276 - f1_score: 0.6867\n",
      "Epoch 1658/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1658: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3854 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1659/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 1659: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 1660/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8265 - f1_score: 0.6874\n",
      "Epoch 1660: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3876 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 1661/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8252 - f1_score: 0.6876\n",
      "Epoch 1661: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3876 - accuracy: 0.8251 - f1_score: 0.6876\n",
      "Epoch 1662/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8268 - f1_score: 0.6878\n",
      "Epoch 1662: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3860 - accuracy: 0.8268 - f1_score: 0.6879\n",
      "Epoch 1663/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 1663: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8282 - f1_score: 0.6883\n",
      "Epoch 1664/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 1664: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 1665/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 1665: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 1666/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8288 - f1_score: 0.6881\n",
      "Epoch 1666: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 1667/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 1667: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 1668/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1668: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1669/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.8252 - f1_score: 0.6859\n",
      "Epoch 1669: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3904 - accuracy: 0.8252 - f1_score: 0.6859\n",
      "Epoch 1670/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6872\n",
      "Epoch 1670: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6872\n",
      "Epoch 1671/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 1671: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 1672/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8287 - f1_score: 0.6870\n",
      "Epoch 1672: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8287 - f1_score: 0.6870\n",
      "Epoch 1673/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8285 - f1_score: 0.6873\n",
      "Epoch 1673: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 1674/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8285 - f1_score: 0.6886\n",
      "Epoch 1674: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 1675/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8294 - f1_score: 0.6881\n",
      "Epoch 1675: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3831 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 1676/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8298 - f1_score: 0.6878\n",
      "Epoch 1676: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 5s 10ms/step - loss: 0.3831 - accuracy: 0.8298 - f1_score: 0.6878\n",
      "Epoch 1677/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8261 - f1_score: 0.6879\n",
      "Epoch 1677: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8261 - f1_score: 0.6879\n",
      "Epoch 1678/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6883\n",
      "Epoch 1678: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 1679/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 1679: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 1680/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8261 - f1_score: 0.6855\n",
      "Epoch 1680: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3883 - accuracy: 0.8261 - f1_score: 0.6855\n",
      "Epoch 1681/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8256 - f1_score: 0.6866\n",
      "Epoch 1681: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3881 - accuracy: 0.8257 - f1_score: 0.6865\n",
      "Epoch 1682/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6863\n",
      "Epoch 1682: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3876 - accuracy: 0.8263 - f1_score: 0.6863\n",
      "Epoch 1683/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8273 - f1_score: 0.6869\n",
      "Epoch 1683: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8274 - f1_score: 0.6870\n",
      "Epoch 1684/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8297 - f1_score: 0.6879\n",
      "Epoch 1684: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8298 - f1_score: 0.6881\n",
      "Epoch 1685/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8297 - f1_score: 0.6878\n",
      "Epoch 1685: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8297 - f1_score: 0.6878\n",
      "Epoch 1686/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 1686: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 1687/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6879\n",
      "Epoch 1687: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6879\n",
      "Epoch 1688/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8269 - f1_score: 0.6882\n",
      "Epoch 1688: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6880\n",
      "Epoch 1689/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6881\n",
      "Epoch 1689: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6881\n",
      "Epoch 1690/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3877 - accuracy: 0.8260 - f1_score: 0.6878\n",
      "Epoch 1690: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8260 - f1_score: 0.6878\n",
      "Epoch 1691/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 1691: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3836 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 1692/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 1692: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6881\n",
      "Epoch 1693/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8266 - f1_score: 0.6867\n",
      "Epoch 1693: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3879 - accuracy: 0.8267 - f1_score: 0.6867\n",
      "Epoch 1694/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 1694: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 1695/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1695: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1696/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8268 - f1_score: 0.6872\n",
      "Epoch 1696: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8268 - f1_score: 0.6872\n",
      "Epoch 1697/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3926 - accuracy: 0.8226 - f1_score: 0.6855\n",
      "Epoch 1697: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3927 - accuracy: 0.8226 - f1_score: 0.6855\n",
      "Epoch 1698/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8267 - f1_score: 0.6875\n",
      "Epoch 1698: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8267 - f1_score: 0.6873\n",
      "Epoch 1699/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8264 - f1_score: 0.6867\n",
      "Epoch 1699: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8265 - f1_score: 0.6867\n",
      "Epoch 1700/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8259 - f1_score: 0.6862\n",
      "Epoch 1700: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3882 - accuracy: 0.8259 - f1_score: 0.6864\n",
      "Epoch 1701/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8295 - f1_score: 0.6874\n",
      "Epoch 1701: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8295 - f1_score: 0.6874\n",
      "Epoch 1702/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8294 - f1_score: 0.6869\n",
      "Epoch 1702: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8294 - f1_score: 0.6869\n",
      "Epoch 1703/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6870\n",
      "Epoch 1703: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6870\n",
      "Epoch 1704/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 1704: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8284 - f1_score: 0.6875\n",
      "Epoch 1705/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 1705: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 1706/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 1706: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 1707/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1707: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1708/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6866\n",
      "Epoch 1708: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6867\n",
      "Epoch 1709/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8274 - f1_score: 0.6874\n",
      "Epoch 1709: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 1710/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8273 - f1_score: 0.6866\n",
      "Epoch 1710: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8273 - f1_score: 0.6866\n",
      "Epoch 1711/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8257 - f1_score: 0.6866\n",
      "Epoch 1711: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3882 - accuracy: 0.8257 - f1_score: 0.6866\n",
      "Epoch 1712/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 1712: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 1713/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8289 - f1_score: 0.6871\n",
      "Epoch 1713: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8289 - f1_score: 0.6870\n",
      "Epoch 1714/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8264 - f1_score: 0.6869\n",
      "Epoch 1714: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3872 - accuracy: 0.8264 - f1_score: 0.6870\n",
      "Epoch 1715/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 1715: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 1716/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6882\n",
      "Epoch 1716: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6882\n",
      "Epoch 1717/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 1717: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3871 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 1718/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8279 - f1_score: 0.6880\n",
      "Epoch 1718: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8279 - f1_score: 0.6880\n",
      "Epoch 1719/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 1719: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 1720/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 1720: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 1721/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 1721: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 1722/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 1722: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6877\n",
      "Epoch 1723/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 1723: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 1724/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 1724: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 1725/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8286 - f1_score: 0.6869\n",
      "Epoch 1725: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8286 - f1_score: 0.6868\n",
      "Epoch 1726/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 1726: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 1727/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6876\n",
      "Epoch 1727: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6876\n",
      "Epoch 1728/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6880\n",
      "Epoch 1728: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 1729/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6888\n",
      "Epoch 1729: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6887\n",
      "Epoch 1730/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 1730: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 1731/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1731: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1732/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 1732: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3883 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 1733/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 1733: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 1734/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6868\n",
      "Epoch 1734: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6868\n",
      "Epoch 1735/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8258 - f1_score: 0.6862\n",
      "Epoch 1735: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3892 - accuracy: 0.8258 - f1_score: 0.6861\n",
      "Epoch 1736/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 1736: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 1737/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 1737: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 1738/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 1738: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8270 - f1_score: 0.6879\n",
      "Epoch 1739/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8271 - f1_score: 0.6889\n",
      "Epoch 1739: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3869 - accuracy: 0.8271 - f1_score: 0.6889\n",
      "Epoch 1740/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8270 - f1_score: 0.6886\n",
      "Epoch 1740: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8270 - f1_score: 0.6885\n",
      "Epoch 1741/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1741: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6873\n",
      "Epoch 1742/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 1742: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 1743/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 1743: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 1744/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 1744: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 1745/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8274 - f1_score: 0.6879\n",
      "Epoch 1745: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8274 - f1_score: 0.6879\n",
      "Epoch 1746/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 1746: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 1747/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 1747: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 1748/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 1748: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6889\n",
      "Epoch 1749/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8293 - f1_score: 0.6892\n",
      "Epoch 1749: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3824 - accuracy: 0.8293 - f1_score: 0.6891\n",
      "Epoch 1750/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 1750: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 1751/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 1751: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6883\n",
      "Epoch 1752/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8273 - f1_score: 0.6883\n",
      "Epoch 1752: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8274 - f1_score: 0.6883\n",
      "Epoch 1753/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 1753: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8282 - f1_score: 0.6887\n",
      "Epoch 1754/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6890\n",
      "Epoch 1754: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8269 - f1_score: 0.6890\n",
      "Epoch 1755/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8286 - f1_score: 0.6891\n",
      "Epoch 1755: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8286 - f1_score: 0.6890\n",
      "Epoch 1756/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 1756: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 1757/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 1757: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 1758/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8264 - f1_score: 0.6881\n",
      "Epoch 1758: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3864 - accuracy: 0.8265 - f1_score: 0.6882\n",
      "Epoch 1759/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 1759: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 1760/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6885\n",
      "Epoch 1760: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6885\n",
      "Epoch 1761/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8278 - f1_score: 0.6884\n",
      "Epoch 1761: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 1762/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 1762: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 1763/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 1763: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 1764/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8296 - f1_score: 0.6891\n",
      "Epoch 1764: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 1765/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 1765: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 1766/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8280 - f1_score: 0.6885\n",
      "Epoch 1766: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3835 - accuracy: 0.8280 - f1_score: 0.6885\n",
      "Epoch 1767/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 1767: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 1768/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 1768: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 1769/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8267 - f1_score: 0.6881\n",
      "Epoch 1769: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8267 - f1_score: 0.6881\n",
      "Epoch 1770/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6875\n",
      "Epoch 1770: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6875\n",
      "Epoch 1771/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8272 - f1_score: 0.6871\n",
      "Epoch 1771: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3867 - accuracy: 0.8272 - f1_score: 0.6870\n",
      "Epoch 1772/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8284 - f1_score: 0.6869\n",
      "Epoch 1772: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8284 - f1_score: 0.6869\n",
      "Epoch 1773/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 1773: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 1774/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6872\n",
      "Epoch 1774: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 1775/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8279 - f1_score: 0.6871\n",
      "Epoch 1775: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 1776/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8285 - f1_score: 0.6868\n",
      "Epoch 1776: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8285 - f1_score: 0.6868\n",
      "Epoch 1777/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8276 - f1_score: 0.6871\n",
      "Epoch 1777: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3871 - accuracy: 0.8277 - f1_score: 0.6871\n",
      "Epoch 1778/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8275 - f1_score: 0.6861\n",
      "Epoch 1778: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3869 - accuracy: 0.8275 - f1_score: 0.6861\n",
      "Epoch 1779/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 1779: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6877\n",
      "Epoch 1780/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 1780: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 1781/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1781: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1782/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 1782: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 1783/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 1783: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 1784/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8274 - f1_score: 0.6866\n",
      "Epoch 1784: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6866\n",
      "Epoch 1785/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1785: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1786/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6872\n",
      "Epoch 1786: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6872\n",
      "Epoch 1787/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8285 - f1_score: 0.6887\n",
      "Epoch 1787: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8286 - f1_score: 0.6887\n",
      "Epoch 1788/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1788: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3849 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1789/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6883\n",
      "Epoch 1789: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 1790/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 1790: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 1791/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8286 - f1_score: 0.6879\n",
      "Epoch 1791: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3827 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 1792/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 1792: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 1793/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 1793: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 1794/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8285 - f1_score: 0.6885\n",
      "Epoch 1794: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8285 - f1_score: 0.6885\n",
      "Epoch 1795/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 1795: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 1796/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 1796: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3810 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 1797/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 1797: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 1798/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 1798: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3860 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 1799/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6881\n",
      "Epoch 1799: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6882\n",
      "Epoch 1800/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 1800: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 1801/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 1801: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3826 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 1802/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1802: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 1803/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8277 - f1_score: 0.6875\n",
      "Epoch 1803: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3865 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 1804/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6873\n",
      "Epoch 1804: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8277 - f1_score: 0.6873\n",
      "Epoch 1805/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 1805: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 1806/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 1806: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 1807/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8271 - f1_score: 0.6870\n",
      "Epoch 1807: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3865 - accuracy: 0.8271 - f1_score: 0.6871\n",
      "Epoch 1808/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 1808: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 1809/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8263 - f1_score: 0.6865\n",
      "Epoch 1809: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3875 - accuracy: 0.8262 - f1_score: 0.6864\n",
      "Epoch 1810/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6865\n",
      "Epoch 1810: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8275 - f1_score: 0.6867\n",
      "Epoch 1811/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8272 - f1_score: 0.6860\n",
      "Epoch 1811: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8272 - f1_score: 0.6861\n",
      "Epoch 1812/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8280 - f1_score: 0.6862\n",
      "Epoch 1812: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8280 - f1_score: 0.6862\n",
      "Epoch 1813/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8288 - f1_score: 0.6864\n",
      "Epoch 1813: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8288 - f1_score: 0.6864\n",
      "Epoch 1814/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8290 - f1_score: 0.6872\n",
      "Epoch 1814: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8290 - f1_score: 0.6872\n",
      "Epoch 1815/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1815: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6872\n",
      "Epoch 1816/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 1816: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 1817/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 1817: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 1818/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8303 - f1_score: 0.6880\n",
      "Epoch 1818: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3820 - accuracy: 0.8303 - f1_score: 0.6880\n",
      "Epoch 1819/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 1819: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3816 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 1820/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6882\n",
      "Epoch 1820: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6882\n",
      "Epoch 1821/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 1821: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3848 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 1822/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8298 - f1_score: 0.6879\n",
      "Epoch 1822: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3835 - accuracy: 0.8298 - f1_score: 0.6879\n",
      "Epoch 1823/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 1823: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3823 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 1824/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6878\n",
      "Epoch 1824: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8271 - f1_score: 0.6878\n",
      "Epoch 1825/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8272 - f1_score: 0.6865\n",
      "Epoch 1825: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3870 - accuracy: 0.8271 - f1_score: 0.6866\n",
      "Epoch 1826/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6873\n",
      "Epoch 1826: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6874\n",
      "Epoch 1827/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 1827: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 1828/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 1828: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 1829/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8266 - f1_score: 0.6872\n",
      "Epoch 1829: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8265 - f1_score: 0.6872\n",
      "Epoch 1830/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 1830: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 1831/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8269 - f1_score: 0.6855\n",
      "Epoch 1831: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3878 - accuracy: 0.8269 - f1_score: 0.6855\n",
      "Epoch 1832/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6864\n",
      "Epoch 1832: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6865\n",
      "Epoch 1833/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8265 - f1_score: 0.6862\n",
      "Epoch 1833: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3862 - accuracy: 0.8265 - f1_score: 0.6862\n",
      "Epoch 1834/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8256 - f1_score: 0.6858\n",
      "Epoch 1834: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3889 - accuracy: 0.8256 - f1_score: 0.6858\n",
      "Epoch 1835/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8270 - f1_score: 0.6875\n",
      "Epoch 1835: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 1836/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 1836: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3829 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 1837/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 1837: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3835 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 1838/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 1838: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 1839/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 1839: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3831 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 1840/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 1840: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8275 - f1_score: 0.6882\n",
      "Epoch 1841/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.8234 - f1_score: 0.6865\n",
      "Epoch 1841: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3921 - accuracy: 0.8234 - f1_score: 0.6865\n",
      "Epoch 1842/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 1842: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3890 - accuracy: 0.8252 - f1_score: 0.6871\n",
      "Epoch 1843/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8272 - f1_score: 0.6880\n",
      "Epoch 1843: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8272 - f1_score: 0.6880\n",
      "Epoch 1844/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6885\n",
      "Epoch 1844: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6886\n",
      "Epoch 1845/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6869\n",
      "Epoch 1845: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6870\n",
      "Epoch 1846/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6872\n",
      "Epoch 1846: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6872\n",
      "Epoch 1847/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 1847: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 1848/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8279 - f1_score: 0.6876\n",
      "Epoch 1848: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 1849/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 1849: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3831 - accuracy: 0.8283 - f1_score: 0.6882\n",
      "Epoch 1850/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 1850: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 1851/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8292 - f1_score: 0.6872\n",
      "Epoch 1851: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8292 - f1_score: 0.6871\n",
      "Epoch 1852/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8270 - f1_score: 0.6878\n",
      "Epoch 1852: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8270 - f1_score: 0.6878\n",
      "Epoch 1853/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8286 - f1_score: 0.6877\n",
      "Epoch 1853: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3849 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 1854/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 1854: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 1855/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8262 - f1_score: 0.6866\n",
      "Epoch 1855: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3876 - accuracy: 0.8262 - f1_score: 0.6866\n",
      "Epoch 1856/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 1856: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3813 - accuracy: 0.8291 - f1_score: 0.6883\n",
      "Epoch 1857/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 1857: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3812 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 1858/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6877\n",
      "Epoch 1858: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3826 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 1859/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 1859: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8276 - f1_score: 0.6873\n",
      "Epoch 1860/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 1860: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3849 - accuracy: 0.8274 - f1_score: 0.6877\n",
      "Epoch 1861/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6889\n",
      "Epoch 1861: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6889\n",
      "Epoch 1862/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 1862: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 1863/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8287 - f1_score: 0.6871\n",
      "Epoch 1863: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6872\n",
      "Epoch 1864/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 1864: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 1865/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6881\n",
      "Epoch 1865: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 1866/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8273 - f1_score: 0.6883\n",
      "Epoch 1866: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8275 - f1_score: 0.6885\n",
      "Epoch 1867/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8270 - f1_score: 0.6883\n",
      "Epoch 1867: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8270 - f1_score: 0.6884\n",
      "Epoch 1868/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 1868: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 1869/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6890\n",
      "Epoch 1869: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6890\n",
      "Epoch 1870/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8272 - f1_score: 0.6882\n",
      "Epoch 1870: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8272 - f1_score: 0.6882\n",
      "Epoch 1871/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3881 - accuracy: 0.8264 - f1_score: 0.6873\n",
      "Epoch 1871: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3881 - accuracy: 0.8263 - f1_score: 0.6872\n",
      "Epoch 1872/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 1872: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 1873/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 1873: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 1874/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 1874: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 1875/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1875: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 1876/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8287 - f1_score: 0.6874\n",
      "Epoch 1876: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6874\n",
      "Epoch 1877/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8298 - f1_score: 0.6875\n",
      "Epoch 1877: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8298 - f1_score: 0.6875\n",
      "Epoch 1878/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8293 - f1_score: 0.6878\n",
      "Epoch 1878: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 1879/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8277 - f1_score: 0.6879\n",
      "Epoch 1879: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8277 - f1_score: 0.6879\n",
      "Epoch 1880/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 1880: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3831 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 1881/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 1881: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8275 - f1_score: 0.6869\n",
      "Epoch 1882/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8272 - f1_score: 0.6860\n",
      "Epoch 1882: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3870 - accuracy: 0.8272 - f1_score: 0.6860\n",
      "Epoch 1883/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6871\n",
      "Epoch 1883: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6871\n",
      "Epoch 1884/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 1884: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 1885/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6871\n",
      "Epoch 1885: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6872\n",
      "Epoch 1886/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 1886: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 1887/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8275 - f1_score: 0.6875\n",
      "Epoch 1887: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 1888/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8274 - f1_score: 0.6884\n",
      "Epoch 1888: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8274 - f1_score: 0.6883\n",
      "Epoch 1889/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 1889: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3826 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 1890/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 1890: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 1891/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6868\n",
      "Epoch 1891: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8276 - f1_score: 0.6868\n",
      "Epoch 1892/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3885 - accuracy: 0.8261 - f1_score: 0.6871\n",
      "Epoch 1892: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3886 - accuracy: 0.8260 - f1_score: 0.6871\n",
      "Epoch 1893/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 1893: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6872\n",
      "Epoch 1894/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 1894: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3841 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 1895/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8279 - f1_score: 0.6882\n",
      "Epoch 1895: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 1896/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 1896: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 1897/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 1897: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 1898/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 1898: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 1899/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8290 - f1_score: 0.6866\n",
      "Epoch 1899: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8290 - f1_score: 0.6866\n",
      "Epoch 1900/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8283 - f1_score: 0.6871\n",
      "Epoch 1900: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6872\n",
      "Epoch 1901/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8265 - f1_score: 0.6875\n",
      "Epoch 1901: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8266 - f1_score: 0.6875\n",
      "Epoch 1902/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8257 - f1_score: 0.6867\n",
      "Epoch 1902: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3871 - accuracy: 0.8257 - f1_score: 0.6867\n",
      "Epoch 1903/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6873\n",
      "Epoch 1903: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6874\n",
      "Epoch 1904/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8292 - f1_score: 0.6867\n",
      "Epoch 1904: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8291 - f1_score: 0.6868\n",
      "Epoch 1905/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 1905: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3867 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 1906/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6881\n",
      "Epoch 1906: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6881\n",
      "Epoch 1907/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8280 - f1_score: 0.6862\n",
      "Epoch 1907: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3856 - accuracy: 0.8280 - f1_score: 0.6862\n",
      "Epoch 1908/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8276 - f1_score: 0.6870\n",
      "Epoch 1908: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6870\n",
      "Epoch 1909/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 1909: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 1910/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8275 - f1_score: 0.6879\n",
      "Epoch 1910: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8275 - f1_score: 0.6879\n",
      "Epoch 1911/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8274 - f1_score: 0.6872\n",
      "Epoch 1911: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8274 - f1_score: 0.6871\n",
      "Epoch 1912/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1912: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 1913/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 1913: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 1914/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8270 - f1_score: 0.6878\n",
      "Epoch 1914: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8270 - f1_score: 0.6878\n",
      "Epoch 1915/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8267 - f1_score: 0.6866\n",
      "Epoch 1915: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3874 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 1916/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8273 - f1_score: 0.6858\n",
      "Epoch 1916: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8273 - f1_score: 0.6858\n",
      "Epoch 1917/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8285 - f1_score: 0.6874\n",
      "Epoch 1917: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8286 - f1_score: 0.6874\n",
      "Epoch 1918/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8288 - f1_score: 0.6880\n",
      "Epoch 1918: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3827 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 1919/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 1919: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 1920/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 1920: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 1921/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8268 - f1_score: 0.6883\n",
      "Epoch 1921: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8268 - f1_score: 0.6882\n",
      "Epoch 1922/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 1922: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8286 - f1_score: 0.6885\n",
      "Epoch 1923/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8278 - f1_score: 0.6888\n",
      "Epoch 1923: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8278 - f1_score: 0.6888\n",
      "Epoch 1924/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 1924: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 1925/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8279 - f1_score: 0.6886\n",
      "Epoch 1925: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8279 - f1_score: 0.6886\n",
      "Epoch 1926/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 1926: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 1927/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 1927: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 1928/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 1928: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 1929/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6867\n",
      "Epoch 1929: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6867\n",
      "Epoch 1930/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 1930: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 1931/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8289 - f1_score: 0.6878\n",
      "Epoch 1931: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3839 - accuracy: 0.8289 - f1_score: 0.6878\n",
      "Epoch 1932/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8260 - f1_score: 0.6867\n",
      "Epoch 1932: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3885 - accuracy: 0.8260 - f1_score: 0.6867\n",
      "Epoch 1933/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8256 - f1_score: 0.6865\n",
      "Epoch 1933: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3878 - accuracy: 0.8256 - f1_score: 0.6866\n",
      "Epoch 1934/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8265 - f1_score: 0.6870\n",
      "Epoch 1934: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3868 - accuracy: 0.8265 - f1_score: 0.6869\n",
      "Epoch 1935/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8267 - f1_score: 0.6867\n",
      "Epoch 1935: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3876 - accuracy: 0.8267 - f1_score: 0.6867\n",
      "Epoch 1936/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 1936: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8270 - f1_score: 0.6871\n",
      "Epoch 1937/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8270 - f1_score: 0.6867\n",
      "Epoch 1937: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3872 - accuracy: 0.8270 - f1_score: 0.6867\n",
      "Epoch 1938/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 1938: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 1939/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 1939: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 1940/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8286 - f1_score: 0.6883\n",
      "Epoch 1940: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 1941/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8273 - f1_score: 0.6878\n",
      "Epoch 1941: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8273 - f1_score: 0.6878\n",
      "Epoch 1942/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6885\n",
      "Epoch 1942: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6885\n",
      "Epoch 1943/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 1943: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 1944/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 1944: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3870 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 1945/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 1945: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6879\n",
      "Epoch 1946/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 1946: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 1947/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 1947: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3828 - accuracy: 0.8285 - f1_score: 0.6881\n",
      "Epoch 1948/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 1948: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3825 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 1949/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1949: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8276 - f1_score: 0.6885\n",
      "Epoch 1950/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6888\n",
      "Epoch 1950: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6888\n",
      "Epoch 1951/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 1951: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 1952/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 1952: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 1953/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 1953: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 1954/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 1954: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 1955/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 1955: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6878\n",
      "Epoch 1956/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8272 - f1_score: 0.6882\n",
      "Epoch 1956: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3856 - accuracy: 0.8273 - f1_score: 0.6881\n",
      "Epoch 1957/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8281 - f1_score: 0.6895\n",
      "Epoch 1957: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6895\n",
      "Epoch 1958/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 1958: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3861 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 1959/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8273 - f1_score: 0.6879\n",
      "Epoch 1959: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8273 - f1_score: 0.6879\n",
      "Epoch 1960/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1960: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 1961/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 1961: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 1962/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6882\n",
      "Epoch 1962: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6882\n",
      "Epoch 1963/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8278 - f1_score: 0.6883\n",
      "Epoch 1963: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8278 - f1_score: 0.6882\n",
      "Epoch 1964/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6887\n",
      "Epoch 1964: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6886\n",
      "Epoch 1965/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8265 - f1_score: 0.6877\n",
      "Epoch 1965: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8263 - f1_score: 0.6873\n",
      "Epoch 1966/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 1966: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 1967/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8280 - f1_score: 0.6883\n",
      "Epoch 1967: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8280 - f1_score: 0.6883\n",
      "Epoch 1968/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 1968: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 1969/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 1969: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3868 - accuracy: 0.8275 - f1_score: 0.6874\n",
      "Epoch 1970/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8279 - f1_score: 0.6865\n",
      "Epoch 1970: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8279 - f1_score: 0.6865\n",
      "Epoch 1971/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 1971: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6872\n",
      "Epoch 1972/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6883\n",
      "Epoch 1972: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6884\n",
      "Epoch 1973/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8271 - f1_score: 0.6881\n",
      "Epoch 1973: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6880\n",
      "Epoch 1974/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 1974: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 1975/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 1975: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 1976/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6875\n",
      "Epoch 1976: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6876\n",
      "Epoch 1977/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 1977: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8271 - f1_score: 0.6869\n",
      "Epoch 1978/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8280 - f1_score: 0.6868\n",
      "Epoch 1978: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8280 - f1_score: 0.6868\n",
      "Epoch 1979/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8259 - f1_score: 0.6858\n",
      "Epoch 1979: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3871 - accuracy: 0.8260 - f1_score: 0.6859\n",
      "Epoch 1980/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 1980: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 1981/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6877\n",
      "Epoch 1981: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3869 - accuracy: 0.8264 - f1_score: 0.6876\n",
      "Epoch 1982/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 1982: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3867 - accuracy: 0.8268 - f1_score: 0.6876\n",
      "Epoch 1983/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 1983: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 1984/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8277 - f1_score: 0.6882\n",
      "Epoch 1984: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8277 - f1_score: 0.6881\n",
      "Epoch 1985/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6890\n",
      "Epoch 1985: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6892\n",
      "Epoch 1986/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 1986: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3821 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 1987/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8280 - f1_score: 0.6888\n",
      "Epoch 1987: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8280 - f1_score: 0.6887\n",
      "Epoch 1988/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8273 - f1_score: 0.6880\n",
      "Epoch 1988: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8273 - f1_score: 0.6880\n",
      "Epoch 1989/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 1989: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3825 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 1990/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8289 - f1_score: 0.6891\n",
      "Epoch 1990: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3819 - accuracy: 0.8289 - f1_score: 0.6890\n",
      "Epoch 1991/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8273 - f1_score: 0.6883\n",
      "Epoch 1991: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8273 - f1_score: 0.6883\n",
      "Epoch 1992/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8290 - f1_score: 0.6899\n",
      "Epoch 1992: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3823 - accuracy: 0.8290 - f1_score: 0.6899\n",
      "Epoch 1993/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6900\n",
      "Epoch 1993: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3815 - accuracy: 0.8297 - f1_score: 0.6900\n",
      "Epoch 1994/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 1994: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 1995/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 1995: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8284 - f1_score: 0.6885\n",
      "Epoch 1996/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6871\n",
      "Epoch 1996: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6872\n",
      "Epoch 1997/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6877\n",
      "Epoch 1997: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3859 - accuracy: 0.8270 - f1_score: 0.6877\n",
      "Epoch 1998/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8274 - f1_score: 0.6883\n",
      "Epoch 1998: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8274 - f1_score: 0.6883\n",
      "Epoch 1999/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6879\n",
      "Epoch 1999: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 2000/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6891\n",
      "Epoch 2000: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6891\n",
      "Epoch 2001/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 2001: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 2002/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2002: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2003/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 2003: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 2004/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8277 - f1_score: 0.6868\n",
      "Epoch 2004: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8277 - f1_score: 0.6868\n",
      "Epoch 2005/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 2005: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 2006/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 2006: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 2007/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 2007: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 2008/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6875\n",
      "Epoch 2008: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 2009/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 2009: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 2010/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8292 - f1_score: 0.6871\n",
      "Epoch 2010: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3858 - accuracy: 0.8292 - f1_score: 0.6871\n",
      "Epoch 2011/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 2011: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 2012/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2012: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 2013/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8269 - f1_score: 0.6875\n",
      "Epoch 2013: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8269 - f1_score: 0.6874\n",
      "Epoch 2014/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 2014: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 2015/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8286 - f1_score: 0.6868\n",
      "Epoch 2015: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8286 - f1_score: 0.6868\n",
      "Epoch 2016/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8282 - f1_score: 0.6870\n",
      "Epoch 2016: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3855 - accuracy: 0.8281 - f1_score: 0.6869\n",
      "Epoch 2017/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8284 - f1_score: 0.6864\n",
      "Epoch 2017: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8285 - f1_score: 0.6865\n",
      "Epoch 2018/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 2018: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 2019/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8261 - f1_score: 0.6864\n",
      "Epoch 2019: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3881 - accuracy: 0.8262 - f1_score: 0.6864\n",
      "Epoch 2020/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 2020: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 2021/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 2021: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 2022/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 2022: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 2023/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 2023: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2024/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8267 - f1_score: 0.6873\n",
      "Epoch 2024: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3879 - accuracy: 0.8267 - f1_score: 0.6873\n",
      "Epoch 2025/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 2025: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3847 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 2026/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8288 - f1_score: 0.6882\n",
      "Epoch 2026: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6882\n",
      "Epoch 2027/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 2027: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 2028/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8291 - f1_score: 0.6866\n",
      "Epoch 2028: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8291 - f1_score: 0.6865\n",
      "Epoch 2029/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6873\n",
      "Epoch 2029: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8295 - f1_score: 0.6874\n",
      "Epoch 2030/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 2030: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6879\n",
      "Epoch 2031/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 2031: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6873\n",
      "Epoch 2032/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 2032: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6880\n",
      "Epoch 2033/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8267 - f1_score: 0.6879\n",
      "Epoch 2033: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3862 - accuracy: 0.8267 - f1_score: 0.6879\n",
      "Epoch 2034/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8278 - f1_score: 0.6881\n",
      "Epoch 2034: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8278 - f1_score: 0.6882\n",
      "Epoch 2035/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 2035: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3860 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 2036/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 2036: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3849 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 2037/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8265 - f1_score: 0.6873\n",
      "Epoch 2037: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3858 - accuracy: 0.8265 - f1_score: 0.6873\n",
      "Epoch 2038/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2038: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3822 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2039/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8258 - f1_score: 0.6877\n",
      "Epoch 2039: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3878 - accuracy: 0.8258 - f1_score: 0.6877\n",
      "Epoch 2040/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8276 - f1_score: 0.6870\n",
      "Epoch 2040: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3864 - accuracy: 0.8276 - f1_score: 0.6869\n",
      "Epoch 2041/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8292 - f1_score: 0.6870\n",
      "Epoch 2041: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8291 - f1_score: 0.6870\n",
      "Epoch 2042/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6880\n",
      "Epoch 2042: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 2043/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6870\n",
      "Epoch 2043: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6871\n",
      "Epoch 2044/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 2044: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 2045/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 2045: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3826 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 2046/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6882\n",
      "Epoch 2046: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 2047/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 2047: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 2048/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 2048: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 2049/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 2049: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 2050/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2050: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 2051/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8274 - f1_score: 0.6870\n",
      "Epoch 2051: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3866 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 2052/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8285 - f1_score: 0.6874\n",
      "Epoch 2052: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 2053/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8287 - f1_score: 0.6872\n",
      "Epoch 2053: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3839 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 2054/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 2054: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3849 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 2055/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 2055: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 10ms/step - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 2056/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 2056: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 2057/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 2057: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3807 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 2058/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 2058: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 2059/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2059: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 2060/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2060: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2061/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 2061: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 2062/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6887\n",
      "Epoch 2062: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3838 - accuracy: 0.8283 - f1_score: 0.6887\n",
      "Epoch 2063/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 2063: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 2064/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 2064: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 2065/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 2065: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3834 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 2066/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8288 - f1_score: 0.6881\n",
      "Epoch 2066: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3828 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 2067/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 2067: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3831 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 2068/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 2068: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3817 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 2069/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8285 - f1_score: 0.6886\n",
      "Epoch 2069: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3827 - accuracy: 0.8285 - f1_score: 0.6886\n",
      "Epoch 2070/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8285 - f1_score: 0.6897\n",
      "Epoch 2070: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3822 - accuracy: 0.8285 - f1_score: 0.6897\n",
      "Epoch 2071/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 2071: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 2072/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 2072: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3836 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 2073/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8280 - f1_score: 0.6888\n",
      "Epoch 2073: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3835 - accuracy: 0.8280 - f1_score: 0.6888\n",
      "Epoch 2074/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8287 - f1_score: 0.6889\n",
      "Epoch 2074: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8287 - f1_score: 0.6890\n",
      "Epoch 2075/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8265 - f1_score: 0.6886\n",
      "Epoch 2075: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3868 - accuracy: 0.8265 - f1_score: 0.6885\n",
      "Epoch 2076/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8280 - f1_score: 0.6890\n",
      "Epoch 2076: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6890\n",
      "Epoch 2077/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 2077: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 2078/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 2078: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3844 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 2079/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 2079: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 2080/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 2080: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3869 - accuracy: 0.8272 - f1_score: 0.6871\n",
      "Epoch 2081/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6886\n",
      "Epoch 2081: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6885\n",
      "Epoch 2082/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 2082: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3817 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 2083/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8293 - f1_score: 0.6893\n",
      "Epoch 2083: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3818 - accuracy: 0.8293 - f1_score: 0.6892\n",
      "Epoch 2084/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8286 - f1_score: 0.6889\n",
      "Epoch 2084: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3829 - accuracy: 0.8286 - f1_score: 0.6889\n",
      "Epoch 2085/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8297 - f1_score: 0.6895\n",
      "Epoch 2085: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3812 - accuracy: 0.8296 - f1_score: 0.6894\n",
      "Epoch 2086/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 2086: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 2087/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8260 - f1_score: 0.6879\n",
      "Epoch 2087: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3877 - accuracy: 0.8260 - f1_score: 0.6878\n",
      "Epoch 2088/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8274 - f1_score: 0.6883\n",
      "Epoch 2088: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 2089/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 2089: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3842 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 2090/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8292 - f1_score: 0.6873\n",
      "Epoch 2090: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3844 - accuracy: 0.8291 - f1_score: 0.6872\n",
      "Epoch 2091/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 2091: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 2092/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 2092: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3872 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 2093/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6890\n",
      "Epoch 2093: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6890\n",
      "Epoch 2094/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 2094: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3845 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 2095/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 2095: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 2096/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6870\n",
      "Epoch 2096: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6869\n",
      "Epoch 2097/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8284 - f1_score: 0.6872\n",
      "Epoch 2097: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3854 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 2098/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 2098: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3849 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 2099/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8263 - f1_score: 0.6877\n",
      "Epoch 2099: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3877 - accuracy: 0.8263 - f1_score: 0.6877\n",
      "Epoch 2100/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 2100: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3846 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 2101/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6869\n",
      "Epoch 2101: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3854 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 2102/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 2102: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3821 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 2103/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8260 - f1_score: 0.6872\n",
      "Epoch 2103: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3879 - accuracy: 0.8258 - f1_score: 0.6872\n",
      "Epoch 2104/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8268 - f1_score: 0.6884\n",
      "Epoch 2104: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 9ms/step - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6883\n",
      "Epoch 2105/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6884\n",
      "Epoch 2105: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6883\n",
      "Epoch 2106/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8264 - f1_score: 0.6872\n",
      "Epoch 2106: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3869 - accuracy: 0.8264 - f1_score: 0.6872\n",
      "Epoch 2107/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8256 - f1_score: 0.6881\n",
      "Epoch 2107: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3876 - accuracy: 0.8255 - f1_score: 0.6881\n",
      "Epoch 2108/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8275 - f1_score: 0.6884\n",
      "Epoch 2108: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8275 - f1_score: 0.6884\n",
      "Epoch 2109/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8270 - f1_score: 0.6879\n",
      "Epoch 2109: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8270 - f1_score: 0.6879\n",
      "Epoch 2110/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6887\n",
      "Epoch 2110: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6887\n",
      "Epoch 2111/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 2111: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 2112/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2112: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 2113/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 2113: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 2114/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8269 - f1_score: 0.6883\n",
      "Epoch 2114: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8269 - f1_score: 0.6883\n",
      "Epoch 2115/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 2115: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 2116/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 2116: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 2117/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 2117: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 2118/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8291 - f1_score: 0.6874\n",
      "Epoch 2118: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8290 - f1_score: 0.6875\n",
      "Epoch 2119/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 2119: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 2120/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 2120: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3875 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 2121/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6875\n",
      "Epoch 2121: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 2122/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8269 - f1_score: 0.6877\n",
      "Epoch 2122: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3859 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 2123/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8266 - f1_score: 0.6878\n",
      "Epoch 2123: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3872 - accuracy: 0.8266 - f1_score: 0.6879\n",
      "Epoch 2124/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8270 - f1_score: 0.6882\n",
      "Epoch 2124: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8269 - f1_score: 0.6882\n",
      "Epoch 2125/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6886\n",
      "Epoch 2125: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6885\n",
      "Epoch 2126/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 2126: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3851 - accuracy: 0.8271 - f1_score: 0.6877\n",
      "Epoch 2127/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8287 - f1_score: 0.6873\n",
      "Epoch 2127: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8287 - f1_score: 0.6873\n",
      "Epoch 2128/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6880\n",
      "Epoch 2128: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2129/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8274 - f1_score: 0.6873\n",
      "Epoch 2129: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3869 - accuracy: 0.8274 - f1_score: 0.6872\n",
      "Epoch 2130/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8262 - f1_score: 0.6867\n",
      "Epoch 2130: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3880 - accuracy: 0.8261 - f1_score: 0.6867\n",
      "Epoch 2131/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6876\n",
      "Epoch 2131: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 2132/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 2132: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6874\n",
      "Epoch 2133/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8270 - f1_score: 0.6879\n",
      "Epoch 2133: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3854 - accuracy: 0.8270 - f1_score: 0.6879\n",
      "Epoch 2134/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 2134: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6886\n",
      "Epoch 2135/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8297 - f1_score: 0.6893\n",
      "Epoch 2135: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8297 - f1_score: 0.6893\n",
      "Epoch 2136/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 2136: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 2137/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 2137: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 2138/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6883\n",
      "Epoch 2138: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6883\n",
      "Epoch 2139/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6891\n",
      "Epoch 2139: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6890\n",
      "Epoch 2140/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6889\n",
      "Epoch 2140: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6887\n",
      "Epoch 2141/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8274 - f1_score: 0.6881\n",
      "Epoch 2141: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8275 - f1_score: 0.6882\n",
      "Epoch 2142/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8265 - f1_score: 0.6880\n",
      "Epoch 2142: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8263 - f1_score: 0.6880\n",
      "Epoch 2143/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8267 - f1_score: 0.6878\n",
      "Epoch 2143: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6879\n",
      "Epoch 2144/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8300 - f1_score: 0.6892\n",
      "Epoch 2144: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6894\n",
      "Epoch 2145/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8284 - f1_score: 0.6894\n",
      "Epoch 2145: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3835 - accuracy: 0.8283 - f1_score: 0.6896\n",
      "Epoch 2146/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 2146: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 2147/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8258 - f1_score: 0.6878\n",
      "Epoch 2147: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3880 - accuracy: 0.8258 - f1_score: 0.6878\n",
      "Epoch 2148/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 2148: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2149/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 2149: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6877\n",
      "Epoch 2150/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8280 - f1_score: 0.6887\n",
      "Epoch 2150: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6887\n",
      "Epoch 2151/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8278 - f1_score: 0.6886\n",
      "Epoch 2151: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8279 - f1_score: 0.6886\n",
      "Epoch 2152/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8278 - f1_score: 0.6886\n",
      "Epoch 2152: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8279 - f1_score: 0.6887\n",
      "Epoch 2153/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 2153: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 2154/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 2154: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 2155/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8299 - f1_score: 0.6878\n",
      "Epoch 2155: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8299 - f1_score: 0.6877\n",
      "Epoch 2156/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 2156: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 2157/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 2157: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 2158/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 2158: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2159/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 2159: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 2160/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6886\n",
      "Epoch 2160: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 2161/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2161: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 2162/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 2162: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 2163/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 2163: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 2164/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 2164: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2165/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 2165: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8301 - f1_score: 0.6879\n",
      "Epoch 2166/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 2166: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 2167/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8277 - f1_score: 0.6873\n",
      "Epoch 2167: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 2168/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8274 - f1_score: 0.6885\n",
      "Epoch 2168: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8274 - f1_score: 0.6885\n",
      "Epoch 2169/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2169: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 2170/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8273 - f1_score: 0.6880\n",
      "Epoch 2170: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 2171/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2171: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 2172/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6862\n",
      "Epoch 2172: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8269 - f1_score: 0.6861\n",
      "Epoch 2173/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 2173: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 2174/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 2174: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 2175/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6870\n",
      "Epoch 2175: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 2176/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6879\n",
      "Epoch 2176: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6878\n",
      "Epoch 2177/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 2177: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6876\n",
      "Epoch 2178/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 2178: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 2179/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6870\n",
      "Epoch 2179: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6870\n",
      "Epoch 2180/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 2180: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 2181/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 2181: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 2182/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2182: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2183/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8287 - f1_score: 0.6867\n",
      "Epoch 2183: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8286 - f1_score: 0.6867\n",
      "Epoch 2184/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8283 - f1_score: 0.6865\n",
      "Epoch 2184: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3851 - accuracy: 0.8284 - f1_score: 0.6867\n",
      "Epoch 2185/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 2185: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6871\n",
      "Epoch 2186/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 2186: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 2187/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6887\n",
      "Epoch 2187: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 2188/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8282 - f1_score: 0.6882\n",
      "Epoch 2188: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8282 - f1_score: 0.6883\n",
      "Epoch 2189/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 2189: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 2190/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8293 - f1_score: 0.6874\n",
      "Epoch 2190: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8293 - f1_score: 0.6873\n",
      "Epoch 2191/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8305 - f1_score: 0.6875\n",
      "Epoch 2191: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8304 - f1_score: 0.6874\n",
      "Epoch 2192/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8279 - f1_score: 0.6869\n",
      "Epoch 2192: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8279 - f1_score: 0.6869\n",
      "Epoch 2193/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 2193: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 2194/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 2194: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 2195/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8288 - f1_score: 0.6868\n",
      "Epoch 2195: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8288 - f1_score: 0.6868\n",
      "Epoch 2196/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6881\n",
      "Epoch 2196: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 2197/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2197: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2198/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2198: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2199/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8278 - f1_score: 0.6882\n",
      "Epoch 2199: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8278 - f1_score: 0.6882\n",
      "Epoch 2200/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 2200: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6882\n",
      "Epoch 2201/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6876\n",
      "Epoch 2201: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6876\n",
      "Epoch 2202/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 2202: accuracy did not improve from 0.83064\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 2203/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 2203: accuracy improved from 0.83064 to 0.83067, saving model to ./625-batch_size625\\weight-improvement2-2203-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 2204/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 2204: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 2205/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 2205: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 2206/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 2206: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 2207/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 2207: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 2208/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6886\n",
      "Epoch 2208: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 2209/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 2209: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 2210/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 2210: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3823 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 2211/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 2211: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6874\n",
      "Epoch 2212/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8289 - f1_score: 0.6891\n",
      "Epoch 2212: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8290 - f1_score: 0.6892\n",
      "Epoch 2213/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2213: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 2214/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8285 - f1_score: 0.6866\n",
      "Epoch 2214: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8285 - f1_score: 0.6866\n",
      "Epoch 2215/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8292 - f1_score: 0.6867\n",
      "Epoch 2215: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8292 - f1_score: 0.6867\n",
      "Epoch 2216/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 2216: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 2217/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6889\n",
      "Epoch 2217: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6890\n",
      "Epoch 2218/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8278 - f1_score: 0.6885\n",
      "Epoch 2218: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8277 - f1_score: 0.6886\n",
      "Epoch 2219/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 2219: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 2220/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 2220: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3821 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 2221/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6888\n",
      "Epoch 2221: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6889\n",
      "Epoch 2222/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6892\n",
      "Epoch 2222: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6892\n",
      "Epoch 2223/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6898\n",
      "Epoch 2223: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6898\n",
      "Epoch 2224/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8295 - f1_score: 0.6895\n",
      "Epoch 2224: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6896\n",
      "Epoch 2225/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 2225: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6887\n",
      "Epoch 2226/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8270 - f1_score: 0.6882\n",
      "Epoch 2226: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8270 - f1_score: 0.6882\n",
      "Epoch 2227/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 2227: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 2228/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8292 - f1_score: 0.6874\n",
      "Epoch 2228: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8292 - f1_score: 0.6874\n",
      "Epoch 2229/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 2229: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8270 - f1_score: 0.6868\n",
      "Epoch 2230/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8282 - f1_score: 0.6871\n",
      "Epoch 2230: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 2231/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6878\n",
      "Epoch 2231: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6877\n",
      "Epoch 2232/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 2232: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6876\n",
      "Epoch 2233/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8297 - f1_score: 0.6866\n",
      "Epoch 2233: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3843 - accuracy: 0.8297 - f1_score: 0.6865\n",
      "Epoch 2234/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 2234: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8299 - f1_score: 0.6890\n",
      "Epoch 2235/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8300 - f1_score: 0.6879\n",
      "Epoch 2235: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8299 - f1_score: 0.6879\n",
      "Epoch 2236/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8273 - f1_score: 0.6888\n",
      "Epoch 2236: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8272 - f1_score: 0.6888\n",
      "Epoch 2237/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8285 - f1_score: 0.6889\n",
      "Epoch 2237: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8284 - f1_score: 0.6889\n",
      "Epoch 2238/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 2238: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 2239/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 2239: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 2240/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 2240: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 2241/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8272 - f1_score: 0.6886\n",
      "Epoch 2241: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8270 - f1_score: 0.6885\n",
      "Epoch 2242/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6891\n",
      "Epoch 2242: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6889\n",
      "Epoch 2243/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 2243: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 2244/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8285 - f1_score: 0.6892\n",
      "Epoch 2244: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8285 - f1_score: 0.6893\n",
      "Epoch 2245/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6884\n",
      "Epoch 2245: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6885\n",
      "Epoch 2246/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8279 - f1_score: 0.6882\n",
      "Epoch 2246: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6883\n",
      "Epoch 2247/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 2247: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8280 - f1_score: 0.6880\n",
      "Epoch 2248/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 2248: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 2249/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8280 - f1_score: 0.6866\n",
      "Epoch 2249: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8281 - f1_score: 0.6866\n",
      "Epoch 2250/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 2250: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 2251/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 2251: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 2252/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 2252: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 2253/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 2253: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6885\n",
      "Epoch 2254/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8280 - f1_score: 0.6885\n",
      "Epoch 2254: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 2255/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8290 - f1_score: 0.6875\n",
      "Epoch 2255: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3844 - accuracy: 0.8290 - f1_score: 0.6874\n",
      "Epoch 2256/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8267 - f1_score: 0.6877\n",
      "Epoch 2256: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3864 - accuracy: 0.8267 - f1_score: 0.6876\n",
      "Epoch 2257/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 2257: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 2258/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6889\n",
      "Epoch 2258: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8289 - f1_score: 0.6889\n",
      "Epoch 2259/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6892\n",
      "Epoch 2259: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6892\n",
      "Epoch 2260/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 2260: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2261/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 2261: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 2262/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6886\n",
      "Epoch 2262: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6885\n",
      "Epoch 2263/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 2263: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 2264/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 2264: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 2265/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 2265: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3870 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 2266/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8269 - f1_score: 0.6876\n",
      "Epoch 2266: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3857 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 2267/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 2267: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 2268/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2268: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2269/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8276 - f1_score: 0.6868\n",
      "Epoch 2269: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8276 - f1_score: 0.6867\n",
      "Epoch 2270/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 2270: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2271/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 2271: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6878\n",
      "Epoch 2272/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 2272: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3856 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 2273/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 2273: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 2274/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2274: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2275/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8251 - f1_score: 0.6864\n",
      "Epoch 2275: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3887 - accuracy: 0.8253 - f1_score: 0.6865\n",
      "Epoch 2276/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8265 - f1_score: 0.6876\n",
      "Epoch 2276: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3863 - accuracy: 0.8266 - f1_score: 0.6877\n",
      "Epoch 2277/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 2277: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3855 - accuracy: 0.8274 - f1_score: 0.6881\n",
      "Epoch 2278/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6884\n",
      "Epoch 2278: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6884\n",
      "Epoch 2279/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 2279: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 2280/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 2280: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 2281/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 2281: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6885\n",
      "Epoch 2282/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8265 - f1_score: 0.6854\n",
      "Epoch 2282: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3879 - accuracy: 0.8265 - f1_score: 0.6854\n",
      "Epoch 2283/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8290 - f1_score: 0.6870\n",
      "Epoch 2283: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8290 - f1_score: 0.6871\n",
      "Epoch 2284/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 2284: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3842 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 2285/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8266 - f1_score: 0.6877\n",
      "Epoch 2285: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8265 - f1_score: 0.6877\n",
      "Epoch 2286/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 2286: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 2287/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 2287: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2288/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6870\n",
      "Epoch 2288: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 2289/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8293 - f1_score: 0.6875\n",
      "Epoch 2289: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3836 - accuracy: 0.8293 - f1_score: 0.6874\n",
      "Epoch 2290/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6878\n",
      "Epoch 2290: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6878\n",
      "Epoch 2291/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8299 - f1_score: 0.6874\n",
      "Epoch 2291: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8299 - f1_score: 0.6874\n",
      "Epoch 2292/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6877\n",
      "Epoch 2292: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6880\n",
      "Epoch 2293/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8304 - f1_score: 0.6878\n",
      "Epoch 2293: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6878\n",
      "Epoch 2294/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8293 - f1_score: 0.6873\n",
      "Epoch 2294: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8292 - f1_score: 0.6873\n",
      "Epoch 2295/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8276 - f1_score: 0.6874\n",
      "Epoch 2295: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 2296/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 2296: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 2297/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8264 - f1_score: 0.6864\n",
      "Epoch 2297: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3883 - accuracy: 0.8265 - f1_score: 0.6866\n",
      "Epoch 2298/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 2298: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 2299/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6880\n",
      "Epoch 2299: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6880\n",
      "Epoch 2300/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2300: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 2301/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8256 - f1_score: 0.6868\n",
      "Epoch 2301: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3875 - accuracy: 0.8256 - f1_score: 0.6869\n",
      "Epoch 2302/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3872 - accuracy: 0.8265 - f1_score: 0.6870\n",
      "Epoch 2302: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3871 - accuracy: 0.8266 - f1_score: 0.6871\n",
      "Epoch 2303/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8290 - f1_score: 0.6876\n",
      "Epoch 2303: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3844 - accuracy: 0.8290 - f1_score: 0.6876\n",
      "Epoch 2304/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2304: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2305/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2305: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 2306/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8298 - f1_score: 0.6876\n",
      "Epoch 2306: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 2307/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 2307: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8285 - f1_score: 0.6887\n",
      "Epoch 2308/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2308: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2309/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6873\n",
      "Epoch 2309: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6873\n",
      "Epoch 2310/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8289 - f1_score: 0.6872\n",
      "Epoch 2310: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8289 - f1_score: 0.6872\n",
      "Epoch 2311/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 2311: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8285 - f1_score: 0.6873\n",
      "Epoch 2312/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3894 - accuracy: 0.8258 - f1_score: 0.6859\n",
      "Epoch 2312: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3894 - accuracy: 0.8259 - f1_score: 0.6859\n",
      "Epoch 2313/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6857\n",
      "Epoch 2313: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6856\n",
      "Epoch 2314/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 2314: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 2315/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 2315: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 2316/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6860\n",
      "Epoch 2316: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6862\n",
      "Epoch 2317/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8266 - f1_score: 0.6871\n",
      "Epoch 2317: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8265 - f1_score: 0.6871\n",
      "Epoch 2318/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6872\n",
      "Epoch 2318: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3892 - accuracy: 0.8255 - f1_score: 0.6873\n",
      "Epoch 2319/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8269 - f1_score: 0.6866\n",
      "Epoch 2319: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3873 - accuracy: 0.8269 - f1_score: 0.6865\n",
      "Epoch 2320/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8257 - f1_score: 0.6860\n",
      "Epoch 2320: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3879 - accuracy: 0.8258 - f1_score: 0.6860\n",
      "Epoch 2321/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6864\n",
      "Epoch 2321: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3868 - accuracy: 0.8272 - f1_score: 0.6863\n",
      "Epoch 2322/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8267 - f1_score: 0.6877\n",
      "Epoch 2322: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8266 - f1_score: 0.6877\n",
      "Epoch 2323/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 2323: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 2324/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2324: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3836 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2325/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 2325: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 2326/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 2326: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8292 - f1_score: 0.6876\n",
      "Epoch 2327/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6880\n",
      "Epoch 2327: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6880\n",
      "Epoch 2328/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8266 - f1_score: 0.6882\n",
      "Epoch 2328: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8265 - f1_score: 0.6881\n",
      "Epoch 2329/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8254 - f1_score: 0.6870\n",
      "Epoch 2329: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3884 - accuracy: 0.8254 - f1_score: 0.6871\n",
      "Epoch 2330/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8266 - f1_score: 0.6871\n",
      "Epoch 2330: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6871\n",
      "Epoch 2331/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8286 - f1_score: 0.6870\n",
      "Epoch 2331: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8286 - f1_score: 0.6869\n",
      "Epoch 2332/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 2332: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8277 - f1_score: 0.6871\n",
      "Epoch 2333/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 2333: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 2334/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 2334: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 2335/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8298 - f1_score: 0.6873\n",
      "Epoch 2335: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8298 - f1_score: 0.6873\n",
      "Epoch 2336/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8294 - f1_score: 0.6867\n",
      "Epoch 2336: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8293 - f1_score: 0.6867\n",
      "Epoch 2337/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6865\n",
      "Epoch 2337: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6865\n",
      "Epoch 2338/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6873\n",
      "Epoch 2338: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6873\n",
      "Epoch 2339/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8281 - f1_score: 0.6869\n",
      "Epoch 2339: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3864 - accuracy: 0.8281 - f1_score: 0.6869\n",
      "Epoch 2340/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8281 - f1_score: 0.6869\n",
      "Epoch 2340: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8281 - f1_score: 0.6869\n",
      "Epoch 2341/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 2341: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 2342/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6887\n",
      "Epoch 2342: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6887\n",
      "Epoch 2343/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 2343: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 2344/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2344: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2345/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6879\n",
      "Epoch 2345: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6879\n",
      "Epoch 2346/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 2346: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2347/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8265 - f1_score: 0.6872\n",
      "Epoch 2347: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3873 - accuracy: 0.8265 - f1_score: 0.6873\n",
      "Epoch 2348/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8279 - f1_score: 0.6889\n",
      "Epoch 2348: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8279 - f1_score: 0.6888\n",
      "Epoch 2349/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 2349: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6879\n",
      "Epoch 2350/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3884 - accuracy: 0.8256 - f1_score: 0.6878\n",
      "Epoch 2350: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3884 - accuracy: 0.8256 - f1_score: 0.6880\n",
      "Epoch 2351/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8272 - f1_score: 0.6870\n",
      "Epoch 2351: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3876 - accuracy: 0.8272 - f1_score: 0.6869\n",
      "Epoch 2352/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8280 - f1_score: 0.6882\n",
      "Epoch 2352: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 2353/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8268 - f1_score: 0.6875\n",
      "Epoch 2353: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3871 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 2354/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8282 - f1_score: 0.6885\n",
      "Epoch 2354: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8282 - f1_score: 0.6886\n",
      "Epoch 2355/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6886\n",
      "Epoch 2355: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6886\n",
      "Epoch 2356/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8274 - f1_score: 0.6878\n",
      "Epoch 2356: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8274 - f1_score: 0.6878\n",
      "Epoch 2357/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 2357: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 2358/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 2358: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8268 - f1_score: 0.6873\n",
      "Epoch 2359/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 2359: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 2360/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 2360: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8281 - f1_score: 0.6881\n",
      "Epoch 2361/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6876\n",
      "Epoch 2361: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6876\n",
      "Epoch 2362/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 2362: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 2363/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8277 - f1_score: 0.6878\n",
      "Epoch 2363: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8278 - f1_score: 0.6879\n",
      "Epoch 2364/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 2364: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 2365/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 2365: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 2366/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8274 - f1_score: 0.6878\n",
      "Epoch 2366: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 2367/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8268 - f1_score: 0.6888\n",
      "Epoch 2367: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8268 - f1_score: 0.6888\n",
      "Epoch 2368/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8296 - f1_score: 0.6891\n",
      "Epoch 2368: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 2369/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 2369: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 2370/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8269 - f1_score: 0.6876\n",
      "Epoch 2370: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3872 - accuracy: 0.8269 - f1_score: 0.6876\n",
      "Epoch 2371/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8267 - f1_score: 0.6872\n",
      "Epoch 2371: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6871\n",
      "Epoch 2372/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6873\n",
      "Epoch 2372: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6871\n",
      "Epoch 2373/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6872\n",
      "Epoch 2373: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6873\n",
      "Epoch 2374/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 2374: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2375/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6887\n",
      "Epoch 2375: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 2376/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 2376: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 2377/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8273 - f1_score: 0.6882\n",
      "Epoch 2377: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8273 - f1_score: 0.6882\n",
      "Epoch 2378/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8286 - f1_score: 0.6890\n",
      "Epoch 2378: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8286 - f1_score: 0.6891\n",
      "Epoch 2379/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 2379: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2380/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6868\n",
      "Epoch 2380: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6868\n",
      "Epoch 2381/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 2381: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 2382/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8272 - f1_score: 0.6860\n",
      "Epoch 2382: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8273 - f1_score: 0.6861\n",
      "Epoch 2383/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8268 - f1_score: 0.6865\n",
      "Epoch 2383: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3878 - accuracy: 0.8268 - f1_score: 0.6866\n",
      "Epoch 2384/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8262 - f1_score: 0.6868\n",
      "Epoch 2384: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3875 - accuracy: 0.8262 - f1_score: 0.6868\n",
      "Epoch 2385/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8278 - f1_score: 0.6866\n",
      "Epoch 2385: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3861 - accuracy: 0.8279 - f1_score: 0.6867\n",
      "Epoch 2386/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.8258 - f1_score: 0.6865\n",
      "Epoch 2386: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3881 - accuracy: 0.8258 - f1_score: 0.6865\n",
      "Epoch 2387/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 2387: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 2388/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6875\n",
      "Epoch 2388: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 2389/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 2389: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 2390/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 2390: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6873\n",
      "Epoch 2391/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 2391: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3857 - accuracy: 0.8271 - f1_score: 0.6868\n",
      "Epoch 2392/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8273 - f1_score: 0.6874\n",
      "Epoch 2392: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8273 - f1_score: 0.6874\n",
      "Epoch 2393/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6876\n",
      "Epoch 2393: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6876\n",
      "Epoch 2394/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 2394: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 2395/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 2395: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8281 - f1_score: 0.6867\n",
      "Epoch 2396/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 2396: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 2397/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8278 - f1_score: 0.6879\n",
      "Epoch 2397: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 2398/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 2398: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 2399/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6883\n",
      "Epoch 2399: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8271 - f1_score: 0.6883\n",
      "Epoch 2400/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8289 - f1_score: 0.6875\n",
      "Epoch 2400: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 2401/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 2401: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 2402/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8282 - f1_score: 0.6890\n",
      "Epoch 2402: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8281 - f1_score: 0.6888\n",
      "Epoch 2403/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 2403: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 2404/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8279 - f1_score: 0.6871\n",
      "Epoch 2404: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8279 - f1_score: 0.6871\n",
      "Epoch 2405/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8268 - f1_score: 0.6868\n",
      "Epoch 2405: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3871 - accuracy: 0.8268 - f1_score: 0.6867\n",
      "Epoch 2406/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8265 - f1_score: 0.6875\n",
      "Epoch 2406: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8265 - f1_score: 0.6875\n",
      "Epoch 2407/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8273 - f1_score: 0.6863\n",
      "Epoch 2407: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8274 - f1_score: 0.6865\n",
      "Epoch 2408/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 2408: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6875\n",
      "Epoch 2409/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 2409: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 2410/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6885\n",
      "Epoch 2410: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6885\n",
      "Epoch 2411/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2411: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2412/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 2412: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 2413/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 2413: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2414/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2414: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2415/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6873\n",
      "Epoch 2415: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6873\n",
      "Epoch 2416/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8273 - f1_score: 0.6877\n",
      "Epoch 2416: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8271 - f1_score: 0.6879\n",
      "Epoch 2417/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 2417: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 2418/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8274 - f1_score: 0.6872\n",
      "Epoch 2418: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 2419/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 2419: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 2420/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8299 - f1_score: 0.6876\n",
      "Epoch 2420: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8298 - f1_score: 0.6877\n",
      "Epoch 2421/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8270 - f1_score: 0.6877\n",
      "Epoch 2421: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6878\n",
      "Epoch 2422/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 2422: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6872\n",
      "Epoch 2423/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 2423: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 2424/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6871\n",
      "Epoch 2424: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8282 - f1_score: 0.6871\n",
      "Epoch 2425/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8275 - f1_score: 0.6865\n",
      "Epoch 2425: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8275 - f1_score: 0.6865\n",
      "Epoch 2426/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8275 - f1_score: 0.6865\n",
      "Epoch 2426: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8276 - f1_score: 0.6865\n",
      "Epoch 2427/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 2427: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2428/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 2428: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8274 - f1_score: 0.6881\n",
      "Epoch 2429/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 2429: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 2430/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6879\n",
      "Epoch 2430: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6879\n",
      "Epoch 2431/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2431: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 2432/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8271 - f1_score: 0.6872\n",
      "Epoch 2432: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8272 - f1_score: 0.6873\n",
      "Epoch 2433/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8274 - f1_score: 0.6870\n",
      "Epoch 2433: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8274 - f1_score: 0.6870\n",
      "Epoch 2434/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6872\n",
      "Epoch 2434: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 2435/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8269 - f1_score: 0.6880\n",
      "Epoch 2435: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3861 - accuracy: 0.8269 - f1_score: 0.6880\n",
      "Epoch 2436/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6880\n",
      "Epoch 2436: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6881\n",
      "Epoch 2437/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 2437: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 2438/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8298 - f1_score: 0.6877\n",
      "Epoch 2438: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8299 - f1_score: 0.6876\n",
      "Epoch 2439/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8276 - f1_score: 0.6889\n",
      "Epoch 2439: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8277 - f1_score: 0.6888\n",
      "Epoch 2440/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6884\n",
      "Epoch 2440: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6885\n",
      "Epoch 2441/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8276 - f1_score: 0.6872\n",
      "Epoch 2441: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8276 - f1_score: 0.6873\n",
      "Epoch 2442/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 2442: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 2443/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 2443: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 2444/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 2444: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 2445/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6867\n",
      "Epoch 2445: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6867\n",
      "Epoch 2446/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 2446: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8275 - f1_score: 0.6877\n",
      "Epoch 2447/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 2447: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 2448/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8270 - f1_score: 0.6865\n",
      "Epoch 2448: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3870 - accuracy: 0.8270 - f1_score: 0.6865\n",
      "Epoch 2449/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6872\n",
      "Epoch 2449: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6873\n",
      "Epoch 2450/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2450: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8288 - f1_score: 0.6882\n",
      "Epoch 2451/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8266 - f1_score: 0.6873\n",
      "Epoch 2451: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8266 - f1_score: 0.6873\n",
      "Epoch 2452/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8292 - f1_score: 0.6891\n",
      "Epoch 2452: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6890\n",
      "Epoch 2453/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6885\n",
      "Epoch 2453: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 2454/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 2454: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 2455/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 2455: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 2456/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 2456: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 2457/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 2457: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 2458/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6873\n",
      "Epoch 2458: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6874\n",
      "Epoch 2459/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 2459: accuracy did not improve from 0.83067\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 2460/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8309 - f1_score: 0.6879\n",
      "Epoch 2460: accuracy improved from 0.83067 to 0.83109, saving model to ./625-batch_size625\\weight-improvement2-2460-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8311 - f1_score: 0.6878\n",
      "Epoch 2461/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8298 - f1_score: 0.6878\n",
      "Epoch 2461: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 2462/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 2462: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 2463/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 2463: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 2464/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 2464: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 2465/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 2465: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 2466/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 2466: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8272 - f1_score: 0.6878\n",
      "Epoch 2467/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 2467: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6869\n",
      "Epoch 2468/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8280 - f1_score: 0.6883\n",
      "Epoch 2468: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8280 - f1_score: 0.6884\n",
      "Epoch 2469/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 2469: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 2470/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8278 - f1_score: 0.6883\n",
      "Epoch 2470: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8276 - f1_score: 0.6882\n",
      "Epoch 2471/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8267 - f1_score: 0.6865\n",
      "Epoch 2471: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3867 - accuracy: 0.8267 - f1_score: 0.6865\n",
      "Epoch 2472/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 2472: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 2473/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8290 - f1_score: 0.6876\n",
      "Epoch 2473: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 2474/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8262 - f1_score: 0.6875\n",
      "Epoch 2474: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3873 - accuracy: 0.8263 - f1_score: 0.6875\n",
      "Epoch 2475/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8249 - f1_score: 0.6869\n",
      "Epoch 2475: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3900 - accuracy: 0.8248 - f1_score: 0.6870\n",
      "Epoch 2476/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.8247 - f1_score: 0.6859\n",
      "Epoch 2476: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3909 - accuracy: 0.8247 - f1_score: 0.6859\n",
      "Epoch 2477/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 2477: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 2478/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8283 - f1_score: 0.6882\n",
      "Epoch 2478: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 2479/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8297 - f1_score: 0.6876\n",
      "Epoch 2479: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 2480/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 2480: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 2481/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8251 - f1_score: 0.6871\n",
      "Epoch 2481: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3881 - accuracy: 0.8251 - f1_score: 0.6872\n",
      "Epoch 2482/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8274 - f1_score: 0.6887\n",
      "Epoch 2482: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8274 - f1_score: 0.6886\n",
      "Epoch 2483/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8269 - f1_score: 0.6881\n",
      "Epoch 2483: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8269 - f1_score: 0.6881\n",
      "Epoch 2484/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 2484: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3843 - accuracy: 0.8278 - f1_score: 0.6879\n",
      "Epoch 2485/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8294 - f1_score: 0.6872\n",
      "Epoch 2485: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3838 - accuracy: 0.8294 - f1_score: 0.6872\n",
      "Epoch 2486/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8297 - f1_score: 0.6881\n",
      "Epoch 2486: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 2487/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 2487: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8282 - f1_score: 0.6884\n",
      "Epoch 2488/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 2488: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 2489/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 2489: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8277 - f1_score: 0.6869\n",
      "Epoch 2490/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8274 - f1_score: 0.6855\n",
      "Epoch 2490: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8274 - f1_score: 0.6854\n",
      "Epoch 2491/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 2491: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8287 - f1_score: 0.6878\n",
      "Epoch 2492/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 2492: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8270 - f1_score: 0.6878\n",
      "Epoch 2493/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 2493: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6880\n",
      "Epoch 2494/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6891\n",
      "Epoch 2494: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 2495/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8289 - f1_score: 0.6892\n",
      "Epoch 2495: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8289 - f1_score: 0.6892\n",
      "Epoch 2496/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6895\n",
      "Epoch 2496: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8292 - f1_score: 0.6895\n",
      "Epoch 2497/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8273 - f1_score: 0.6883\n",
      "Epoch 2497: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6884\n",
      "Epoch 2498/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 2498: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 2499/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 2499: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8274 - f1_score: 0.6881\n",
      "Epoch 2500/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8273 - f1_score: 0.6885\n",
      "Epoch 2500: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8272 - f1_score: 0.6887\n",
      "Epoch 2501/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 2501: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 2502/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 2502: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 2503/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2503: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 2504/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6890\n",
      "Epoch 2504: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6890\n",
      "Epoch 2505/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8301 - f1_score: 0.6892\n",
      "Epoch 2505: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 2506/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 2506: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 2507/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6890\n",
      "Epoch 2507: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8284 - f1_score: 0.6888\n",
      "Epoch 2508/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6888\n",
      "Epoch 2508: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6889\n",
      "Epoch 2509/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6883\n",
      "Epoch 2509: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6882\n",
      "Epoch 2510/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 2510: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 2511/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6891\n",
      "Epoch 2511: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 2512/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8277 - f1_score: 0.6884\n",
      "Epoch 2512: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8278 - f1_score: 0.6882\n",
      "Epoch 2513/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3879 - accuracy: 0.8262 - f1_score: 0.6877\n",
      "Epoch 2513: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3879 - accuracy: 0.8261 - f1_score: 0.6877\n",
      "Epoch 2514/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8281 - f1_score: 0.6890\n",
      "Epoch 2514: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8280 - f1_score: 0.6888\n",
      "Epoch 2515/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 2515: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 2516/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8264 - f1_score: 0.6876\n",
      "Epoch 2516: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 2517/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8288 - f1_score: 0.6868\n",
      "Epoch 2517: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8288 - f1_score: 0.6868\n",
      "Epoch 2518/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8271 - f1_score: 0.6874\n",
      "Epoch 2518: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3862 - accuracy: 0.8271 - f1_score: 0.6874\n",
      "Epoch 2519/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.8243 - f1_score: 0.6863\n",
      "Epoch 2519: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3902 - accuracy: 0.8243 - f1_score: 0.6863\n",
      "Epoch 2520/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8287 - f1_score: 0.6873\n",
      "Epoch 2520: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 2521/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 2521: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6877\n",
      "Epoch 2522/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 2522: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 2523/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8278 - f1_score: 0.6877\n",
      "Epoch 2523: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 2524/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6880\n",
      "Epoch 2524: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2525/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8272 - f1_score: 0.6878\n",
      "Epoch 2525: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8273 - f1_score: 0.6877\n",
      "Epoch 2526/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 2526: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6873\n",
      "Epoch 2527/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 2527: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 2528/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6866\n",
      "Epoch 2528: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6867\n",
      "Epoch 2529/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8289 - f1_score: 0.6870\n",
      "Epoch 2529: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3848 - accuracy: 0.8289 - f1_score: 0.6869\n",
      "Epoch 2530/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8289 - f1_score: 0.6871\n",
      "Epoch 2530: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3842 - accuracy: 0.8289 - f1_score: 0.6871\n",
      "Epoch 2531/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8263 - f1_score: 0.6874\n",
      "Epoch 2531: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3853 - accuracy: 0.8263 - f1_score: 0.6874\n",
      "Epoch 2532/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 2532: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8284 - f1_score: 0.6885\n",
      "Epoch 2533/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8277 - f1_score: 0.6883\n",
      "Epoch 2533: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 2534/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8300 - f1_score: 0.6877\n",
      "Epoch 2534: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8301 - f1_score: 0.6877\n",
      "Epoch 2535/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 2535: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 2536/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8265 - f1_score: 0.6875\n",
      "Epoch 2536: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3873 - accuracy: 0.8265 - f1_score: 0.6875\n",
      "Epoch 2537/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8276 - f1_score: 0.6863\n",
      "Epoch 2537: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3861 - accuracy: 0.8275 - f1_score: 0.6862\n",
      "Epoch 2538/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 2538: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 2539/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 2539: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8268 - f1_score: 0.6869\n",
      "Epoch 2540/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8264 - f1_score: 0.6865\n",
      "Epoch 2540: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8264 - f1_score: 0.6865\n",
      "Epoch 2541/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8273 - f1_score: 0.6869\n",
      "Epoch 2541: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8273 - f1_score: 0.6868\n",
      "Epoch 2542/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 2542: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 2543/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8274 - f1_score: 0.6884\n",
      "Epoch 2543: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8275 - f1_score: 0.6884\n",
      "Epoch 2544/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8273 - f1_score: 0.6881\n",
      "Epoch 2544: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3854 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 2545/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 2545: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 2546/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8290 - f1_score: 0.6871\n",
      "Epoch 2546: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3845 - accuracy: 0.8290 - f1_score: 0.6871\n",
      "Epoch 2547/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8272 - f1_score: 0.6877\n",
      "Epoch 2547: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3848 - accuracy: 0.8272 - f1_score: 0.6875\n",
      "Epoch 2548/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8279 - f1_score: 0.6865\n",
      "Epoch 2548: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3861 - accuracy: 0.8280 - f1_score: 0.6865\n",
      "Epoch 2549/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 2549: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 2550/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 2550: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 2551/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 2551: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3813 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 2552/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8287 - f1_score: 0.6896\n",
      "Epoch 2552: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8287 - f1_score: 0.6896\n",
      "Epoch 2553/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 2553: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 2554/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6865\n",
      "Epoch 2554: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6866\n",
      "Epoch 2555/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3884 - accuracy: 0.8258 - f1_score: 0.6862\n",
      "Epoch 2555: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3884 - accuracy: 0.8258 - f1_score: 0.6862\n",
      "Epoch 2556/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 2556: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 2557/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6882\n",
      "Epoch 2557: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6881\n",
      "Epoch 2558/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 2558: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 2559/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 2559: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 2560/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8296 - f1_score: 0.6892\n",
      "Epoch 2560: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3823 - accuracy: 0.8296 - f1_score: 0.6892\n",
      "Epoch 2561/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 2561: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 2562/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 2562: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2563/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8290 - f1_score: 0.6876\n",
      "Epoch 2563: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6876\n",
      "Epoch 2564/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6878\n",
      "Epoch 2564: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 2565/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8308 - f1_score: 0.6875\n",
      "Epoch 2565: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8307 - f1_score: 0.6876\n",
      "Epoch 2566/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 2566: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 2567/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8290 - f1_score: 0.6874\n",
      "Epoch 2567: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3843 - accuracy: 0.8292 - f1_score: 0.6875\n",
      "Epoch 2568/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 2568: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 2569/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 2569: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 2570/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6882\n",
      "Epoch 2570: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2571/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8285 - f1_score: 0.6869\n",
      "Epoch 2571: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6869\n",
      "Epoch 2572/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8272 - f1_score: 0.6872\n",
      "Epoch 2572: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3851 - accuracy: 0.8273 - f1_score: 0.6874\n",
      "Epoch 2573/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 2573: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 2574/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 2574: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 2575/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6890\n",
      "Epoch 2575: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 2576/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8300 - f1_score: 0.6894\n",
      "Epoch 2576: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3807 - accuracy: 0.8299 - f1_score: 0.6893\n",
      "Epoch 2577/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2577: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3845 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 2578/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8283 - f1_score: 0.6887\n",
      "Epoch 2578: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3835 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 2579/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 2579: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 2580/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 2580: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 2581/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6892\n",
      "Epoch 2581: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8293 - f1_score: 0.6892\n",
      "Epoch 2582/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2582: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2583/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2583: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3835 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2584/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8280 - f1_score: 0.6904\n",
      "Epoch 2584: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3836 - accuracy: 0.8279 - f1_score: 0.6904\n",
      "Epoch 2585/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6879\n",
      "Epoch 2585: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3849 - accuracy: 0.8277 - f1_score: 0.6879\n",
      "Epoch 2586/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8277 - f1_score: 0.6887\n",
      "Epoch 2586: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3838 - accuracy: 0.8278 - f1_score: 0.6888\n",
      "Epoch 2587/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 2587: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 2588/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2588: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2589/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6883\n",
      "Epoch 2589: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2590/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 2590: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 2591/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 2591: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 2592/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 2592: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 2593/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3877 - accuracy: 0.8257 - f1_score: 0.6874\n",
      "Epoch 2593: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3877 - accuracy: 0.8257 - f1_score: 0.6873\n",
      "Epoch 2594/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3874 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 2594: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3873 - accuracy: 0.8261 - f1_score: 0.6866\n",
      "Epoch 2595/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 2595: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 2596/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6879\n",
      "Epoch 2596: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 2597/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 2597: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 2598/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 2598: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 2599/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 2599: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 2600/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 2600: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 2601/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8283 - f1_score: 0.6888\n",
      "Epoch 2601: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8283 - f1_score: 0.6887\n",
      "Epoch 2602/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 2602: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 2603/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8292 - f1_score: 0.6894\n",
      "Epoch 2603: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8293 - f1_score: 0.6894\n",
      "Epoch 2604/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8298 - f1_score: 0.6895\n",
      "Epoch 2604: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3813 - accuracy: 0.8298 - f1_score: 0.6894\n",
      "Epoch 2605/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2605: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2606/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 2606: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8297 - f1_score: 0.6888\n",
      "Epoch 2607/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 2607: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6885\n",
      "Epoch 2608/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8282 - f1_score: 0.6892\n",
      "Epoch 2608: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3838 - accuracy: 0.8282 - f1_score: 0.6893\n",
      "Epoch 2609/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 2609: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 2610/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 2610: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2611/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 2611: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 2612/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 2612: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 2613/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 2613: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2614/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8294 - f1_score: 0.6874\n",
      "Epoch 2614: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8294 - f1_score: 0.6873\n",
      "Epoch 2615/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 2615: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 2616/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 2616: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 2617/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6871\n",
      "Epoch 2617: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6871\n",
      "Epoch 2618/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6873\n",
      "Epoch 2618: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8302 - f1_score: 0.6873\n",
      "Epoch 2619/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 2619: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 2620/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 2620: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8280 - f1_score: 0.6884\n",
      "Epoch 2621/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8286 - f1_score: 0.6890\n",
      "Epoch 2621: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8286 - f1_score: 0.6889\n",
      "Epoch 2622/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8292 - f1_score: 0.6886\n",
      "Epoch 2622: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3821 - accuracy: 0.8292 - f1_score: 0.6886\n",
      "Epoch 2623/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 2623: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6889\n",
      "Epoch 2624/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 2624: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 2625/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8301 - f1_score: 0.6878\n",
      "Epoch 2625: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6879\n",
      "Epoch 2626/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 2626: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3820 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 2627/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 2627: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 2628/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 2628: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 2629/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8286 - f1_score: 0.6870\n",
      "Epoch 2629: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8286 - f1_score: 0.6870\n",
      "Epoch 2630/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 2630: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8292 - f1_score: 0.6875\n",
      "Epoch 2631/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 2631: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 2632/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6872\n",
      "Epoch 2632: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6872\n",
      "Epoch 2633/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 2633: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 2634/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 2634: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3811 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 2635/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6872\n",
      "Epoch 2635: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8287 - f1_score: 0.6873\n",
      "Epoch 2636/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6871\n",
      "Epoch 2636: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8293 - f1_score: 0.6872\n",
      "Epoch 2637/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6881\n",
      "Epoch 2637: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 2638/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 2638: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 2639/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 2639: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 2640/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6868\n",
      "Epoch 2640: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6867\n",
      "Epoch 2641/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 2641: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8290 - f1_score: 0.6875\n",
      "Epoch 2642/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 2642: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2643/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6880\n",
      "Epoch 2643: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6880\n",
      "Epoch 2644/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8294 - f1_score: 0.6876\n",
      "Epoch 2644: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8293 - f1_score: 0.6875\n",
      "Epoch 2645/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8268 - f1_score: 0.6878\n",
      "Epoch 2645: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8268 - f1_score: 0.6879\n",
      "Epoch 2646/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 2646: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 2647/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8284 - f1_score: 0.6872\n",
      "Epoch 2647: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8284 - f1_score: 0.6872\n",
      "Epoch 2648/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8291 - f1_score: 0.6870\n",
      "Epoch 2648: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8291 - f1_score: 0.6871\n",
      "Epoch 2649/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 2649: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 2650/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 2650: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 2651/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6890\n",
      "Epoch 2651: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8292 - f1_score: 0.6891\n",
      "Epoch 2652/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 2652: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 2653/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6886\n",
      "Epoch 2653: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 2654/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 2654: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 2655/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6873\n",
      "Epoch 2655: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 2656/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8275 - f1_score: 0.6878\n",
      "Epoch 2656: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6877\n",
      "Epoch 2657/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8272 - f1_score: 0.6880\n",
      "Epoch 2657: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8274 - f1_score: 0.6879\n",
      "Epoch 2658/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 2658: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 2659/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 2659: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 2660/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8280 - f1_score: 0.6887\n",
      "Epoch 2660: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6886\n",
      "Epoch 2661/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8288 - f1_score: 0.6894\n",
      "Epoch 2661: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6895\n",
      "Epoch 2662/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 2662: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 2663/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 2663: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6888\n",
      "Epoch 2664/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 2664: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 2665/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 2665: accuracy did not improve from 0.83109\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 2666/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8316 - f1_score: 0.6889\n",
      "Epoch 2666: accuracy improved from 0.83109 to 0.83164, saving model to ./625-batch_size625\\weight-improvement2-2666-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3796 - accuracy: 0.8316 - f1_score: 0.6890\n",
      "Epoch 2667/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8309 - f1_score: 0.6885\n",
      "Epoch 2667: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 2668/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 2668: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 2669/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6887\n",
      "Epoch 2669: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 2670/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8285 - f1_score: 0.6889\n",
      "Epoch 2670: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3823 - accuracy: 0.8285 - f1_score: 0.6889\n",
      "Epoch 2671/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 2671: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3804 - accuracy: 0.8303 - f1_score: 0.6889\n",
      "Epoch 2672/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 2672: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6889\n",
      "Epoch 2673/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 2673: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 2674/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2674: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6877\n",
      "Epoch 2675/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 2675: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 2676/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8300 - f1_score: 0.6883\n",
      "Epoch 2676: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 2677/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 2677: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3806 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 2678/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 2678: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 2679/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6868\n",
      "Epoch 2679: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6868\n",
      "Epoch 2680/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8278 - f1_score: 0.6868\n",
      "Epoch 2680: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6870\n",
      "Epoch 2681/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6872\n",
      "Epoch 2681: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 2682/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8295 - f1_score: 0.6887\n",
      "Epoch 2682: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3815 - accuracy: 0.8295 - f1_score: 0.6887\n",
      "Epoch 2683/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8292 - f1_score: 0.6889\n",
      "Epoch 2683: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8292 - f1_score: 0.6889\n",
      "Epoch 2684/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 2684: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3812 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 2685/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 2685: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 2686/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 2686: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 2687/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 2687: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 2688/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 2688: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 2689/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6886\n",
      "Epoch 2689: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8289 - f1_score: 0.6885\n",
      "Epoch 2690/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8286 - f1_score: 0.6887\n",
      "Epoch 2690: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8286 - f1_score: 0.6887\n",
      "Epoch 2691/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 2691: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 2692/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 2692: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 2693/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8307 - f1_score: 0.6899\n",
      "Epoch 2693: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6899\n",
      "Epoch 2694/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 2694: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.8308 - f1_score: 0.6883\n",
      "Epoch 2695/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8307 - f1_score: 0.6892\n",
      "Epoch 2695: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3796 - accuracy: 0.8307 - f1_score: 0.6891\n",
      "Epoch 2696/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8308 - f1_score: 0.6894\n",
      "Epoch 2696: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3802 - accuracy: 0.8308 - f1_score: 0.6893\n",
      "Epoch 2697/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8299 - f1_score: 0.6883\n",
      "Epoch 2697: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8299 - f1_score: 0.6883\n",
      "Epoch 2698/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8301 - f1_score: 0.6896\n",
      "Epoch 2698: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6897\n",
      "Epoch 2699/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 2699: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8302 - f1_score: 0.6888\n",
      "Epoch 2700/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8274 - f1_score: 0.6890\n",
      "Epoch 2700: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8276 - f1_score: 0.6890\n",
      "Epoch 2701/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 2701: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 2702/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8280 - f1_score: 0.6869\n",
      "Epoch 2702: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8279 - f1_score: 0.6868\n",
      "Epoch 2703/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6880\n",
      "Epoch 2703: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 2704/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3888 - accuracy: 0.8261 - f1_score: 0.6880\n",
      "Epoch 2704: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3888 - accuracy: 0.8261 - f1_score: 0.6880\n",
      "Epoch 2705/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2705: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6880\n",
      "Epoch 2706/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6884\n",
      "Epoch 2706: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 2707/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6875\n",
      "Epoch 2707: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 2708/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6893\n",
      "Epoch 2708: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6894\n",
      "Epoch 2709/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 2709: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 2710/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 2710: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 2711/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6872\n",
      "Epoch 2711: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6871\n",
      "Epoch 2712/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 2712: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 2713/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8297 - f1_score: 0.6894\n",
      "Epoch 2713: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8298 - f1_score: 0.6893\n",
      "Epoch 2714/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8312 - f1_score: 0.6882\n",
      "Epoch 2714: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8312 - f1_score: 0.6883\n",
      "Epoch 2715/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 2715: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 2716/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 2716: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3812 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 2717/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 2717: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3806 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 2718/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 2718: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3813 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 2719/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 2719: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 2720/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 2720: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6888\n",
      "Epoch 2721/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6893\n",
      "Epoch 2721: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6892\n",
      "Epoch 2722/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6878\n",
      "Epoch 2722: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6879\n",
      "Epoch 2723/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 2723: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 2724/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 2724: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 2725/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6871\n",
      "Epoch 2725: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6874\n",
      "Epoch 2726/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 2726: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 2727/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8285 - f1_score: 0.6891\n",
      "Epoch 2727: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6891\n",
      "Epoch 2728/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 2728: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 2729/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 2729: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 2730/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 2730: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 2731/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 2731: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8293 - f1_score: 0.6885\n",
      "Epoch 2732/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 2732: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 2733/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 2733: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 2734/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 2734: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8298 - f1_score: 0.6886\n",
      "Epoch 2735/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6882\n",
      "Epoch 2735: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6882\n",
      "Epoch 2736/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 2736: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 2737/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8278 - f1_score: 0.6891\n",
      "Epoch 2737: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8276 - f1_score: 0.6891\n",
      "Epoch 2738/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6892\n",
      "Epoch 2738: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3817 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 2739/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6897\n",
      "Epoch 2739: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6897\n",
      "Epoch 2740/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 2740: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 2741/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 2741: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 2742/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6887\n",
      "Epoch 2742: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6887\n",
      "Epoch 2743/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 2743: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 2744/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8300 - f1_score: 0.6895\n",
      "Epoch 2744: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8300 - f1_score: 0.6895\n",
      "Epoch 2745/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6895\n",
      "Epoch 2745: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3808 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 2746/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8293 - f1_score: 0.6886\n",
      "Epoch 2746: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 2747/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 2747: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3838 - accuracy: 0.8284 - f1_score: 0.6874\n",
      "Epoch 2748/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8284 - f1_score: 0.6885\n",
      "Epoch 2748: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3847 - accuracy: 0.8283 - f1_score: 0.6886\n",
      "Epoch 2749/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 2749: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 2750/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8298 - f1_score: 0.6878\n",
      "Epoch 2750: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8299 - f1_score: 0.6877\n",
      "Epoch 2751/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 2751: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 2752/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 2752: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 2753/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 2753: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 2754/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 2754: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 2755/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8286 - f1_score: 0.6883\n",
      "Epoch 2755: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2756/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6892\n",
      "Epoch 2756: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 2757/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 2757: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 2758/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8311 - f1_score: 0.6884\n",
      "Epoch 2758: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3811 - accuracy: 0.8311 - f1_score: 0.6884\n",
      "Epoch 2759/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 2759: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 2760/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 2760: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 2761/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8299 - f1_score: 0.6894\n",
      "Epoch 2761: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6895\n",
      "Epoch 2762/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6894\n",
      "Epoch 2762: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6894\n",
      "Epoch 2763/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8297 - f1_score: 0.6893\n",
      "Epoch 2763: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3823 - accuracy: 0.8297 - f1_score: 0.6893\n",
      "Epoch 2764/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 2764: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 2765/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 2765: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 2766/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 2766: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 2767/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 2767: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8304 - f1_score: 0.6885\n",
      "Epoch 2768/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 2768: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8286 - f1_score: 0.6884\n",
      "Epoch 2769/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6890\n",
      "Epoch 2769: accuracy did not improve from 0.83164\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 2770/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8316 - f1_score: 0.6897\n",
      "Epoch 2770: accuracy improved from 0.83164 to 0.83170, saving model to ./625-batch_size625\\weight-improvement2-2770-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3792 - accuracy: 0.8317 - f1_score: 0.6898\n",
      "Epoch 2771/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 2771: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 2772/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8294 - f1_score: 0.6897\n",
      "Epoch 2772: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3813 - accuracy: 0.8295 - f1_score: 0.6897\n",
      "Epoch 2773/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8303 - f1_score: 0.6893\n",
      "Epoch 2773: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3820 - accuracy: 0.8301 - f1_score: 0.6892\n",
      "Epoch 2774/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8291 - f1_score: 0.6888\n",
      "Epoch 2774: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8291 - f1_score: 0.6888\n",
      "Epoch 2775/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8306 - f1_score: 0.6894\n",
      "Epoch 2775: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6894\n",
      "Epoch 2776/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 2776: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8302 - f1_score: 0.6890\n",
      "Epoch 2777/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 2777: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3820 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 2778/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8308 - f1_score: 0.6897\n",
      "Epoch 2778: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3801 - accuracy: 0.8308 - f1_score: 0.6896\n",
      "Epoch 2779/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 2779: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 2780/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6878\n",
      "Epoch 2780: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6878\n",
      "Epoch 2781/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8303 - f1_score: 0.6875\n",
      "Epoch 2781: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3820 - accuracy: 0.8303 - f1_score: 0.6875\n",
      "Epoch 2782/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 2782: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 2783/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2783: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2784/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 2784: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 2785/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 2785: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 2786/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 2786: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3793 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 2787/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6881\n",
      "Epoch 2787: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 2788/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 2788: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3854 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 2789/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8290 - f1_score: 0.6876\n",
      "Epoch 2789: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8290 - f1_score: 0.6875\n",
      "Epoch 2790/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 2790: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 2791/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8283 - f1_score: 0.6879\n",
      "Epoch 2791: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 2792/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6873\n",
      "Epoch 2792: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8294 - f1_score: 0.6872\n",
      "Epoch 2793/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3847 - accuracy: 0.8288 - f1_score: 0.6864\n",
      "Epoch 2793: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3847 - accuracy: 0.8288 - f1_score: 0.6864\n",
      "Epoch 2794/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3865 - accuracy: 0.8273 - f1_score: 0.6876\n",
      "Epoch 2794: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 2795/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8272 - f1_score: 0.6879\n",
      "Epoch 2795: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3864 - accuracy: 0.8271 - f1_score: 0.6878\n",
      "Epoch 2796/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2796: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3847 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 2797/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8308 - f1_score: 0.6879\n",
      "Epoch 2797: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3815 - accuracy: 0.8308 - f1_score: 0.6879\n",
      "Epoch 2798/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 2798: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 2799/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 2799: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 2800/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8293 - f1_score: 0.6888\n",
      "Epoch 2800: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 2801/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 2801: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 2802/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8273 - f1_score: 0.6872\n",
      "Epoch 2802: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3865 - accuracy: 0.8273 - f1_score: 0.6873\n",
      "Epoch 2803/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6874\n",
      "Epoch 2803: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6874\n",
      "Epoch 2804/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 2804: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 2805/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 2805: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 2806/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8269 - f1_score: 0.6896\n",
      "Epoch 2806: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8269 - f1_score: 0.6896\n",
      "Epoch 2807/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8286 - f1_score: 0.6901\n",
      "Epoch 2807: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8285 - f1_score: 0.6901\n",
      "Epoch 2808/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 2808: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6892\n",
      "Epoch 2809/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6891\n",
      "Epoch 2809: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8287 - f1_score: 0.6890\n",
      "Epoch 2810/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 2810: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 2811/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8282 - f1_score: 0.6887\n",
      "Epoch 2811: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3851 - accuracy: 0.8282 - f1_score: 0.6887\n",
      "Epoch 2812/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 2812: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3856 - accuracy: 0.8278 - f1_score: 0.6881\n",
      "Epoch 2813/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8292 - f1_score: 0.6885\n",
      "Epoch 2813: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8292 - f1_score: 0.6885\n",
      "Epoch 2814/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 2814: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 2815/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 2815: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 2816/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6892\n",
      "Epoch 2816: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8296 - f1_score: 0.6890\n",
      "Epoch 2817/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 2817: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 2818/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8307 - f1_score: 0.6893\n",
      "Epoch 2818: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8308 - f1_score: 0.6893\n",
      "Epoch 2819/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 2819: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8305 - f1_score: 0.6890\n",
      "Epoch 2820/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8315 - f1_score: 0.6895\n",
      "Epoch 2820: accuracy did not improve from 0.83170\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8315 - f1_score: 0.6894\n",
      "Epoch 2821/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8320 - f1_score: 0.6897\n",
      "Epoch 2821: accuracy improved from 0.83170 to 0.83189, saving model to ./625-batch_size625\\weight-improvement2-2821-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3793 - accuracy: 0.8319 - f1_score: 0.6895\n",
      "Epoch 2822/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 2822: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 2823/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6879\n",
      "Epoch 2823: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 2824/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8283 - f1_score: 0.6891\n",
      "Epoch 2824: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8283 - f1_score: 0.6891\n",
      "Epoch 2825/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8288 - f1_score: 0.6893\n",
      "Epoch 2825: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8288 - f1_score: 0.6894\n",
      "Epoch 2826/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 2826: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 2827/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8291 - f1_score: 0.6889\n",
      "Epoch 2827: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6889\n",
      "Epoch 2828/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8294 - f1_score: 0.6891\n",
      "Epoch 2828: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 2829/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8300 - f1_score: 0.6897\n",
      "Epoch 2829: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3812 - accuracy: 0.8301 - f1_score: 0.6898\n",
      "Epoch 2830/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 2830: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3814 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 2831/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 2831: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6890\n",
      "Epoch 2832/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 2832: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 2833/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8293 - f1_score: 0.6888\n",
      "Epoch 2833: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6888\n",
      "Epoch 2834/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2834: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 2835/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6890\n",
      "Epoch 2835: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6890\n",
      "Epoch 2836/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 2836: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8282 - f1_score: 0.6882\n",
      "Epoch 2837/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8280 - f1_score: 0.6896\n",
      "Epoch 2837: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8281 - f1_score: 0.6895\n",
      "Epoch 2838/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6871\n",
      "Epoch 2838: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8296 - f1_score: 0.6873\n",
      "Epoch 2839/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 2839: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 2840/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 2840: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 2841/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 2841: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 2842/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 2842: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 2843/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 2843: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 2844/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6899\n",
      "Epoch 2844: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8309 - f1_score: 0.6899\n",
      "Epoch 2845/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8288 - f1_score: 0.6891\n",
      "Epoch 2845: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3836 - accuracy: 0.8288 - f1_score: 0.6892\n",
      "Epoch 2846/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 2846: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 2847/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8289 - f1_score: 0.6890\n",
      "Epoch 2847: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8289 - f1_score: 0.6890\n",
      "Epoch 2848/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 2848: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6881\n",
      "Epoch 2849/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2849: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 2850/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 2850: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 2851/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8286 - f1_score: 0.6886\n",
      "Epoch 2851: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8287 - f1_score: 0.6887\n",
      "Epoch 2852/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 2852: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 2853/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 2853: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 2854/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 2854: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6885\n",
      "Epoch 2855/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8305 - f1_score: 0.6879\n",
      "Epoch 2855: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8303 - f1_score: 0.6878\n",
      "Epoch 2856/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8299 - f1_score: 0.6870\n",
      "Epoch 2856: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8298 - f1_score: 0.6870\n",
      "Epoch 2857/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8277 - f1_score: 0.6864\n",
      "Epoch 2857: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3866 - accuracy: 0.8278 - f1_score: 0.6865\n",
      "Epoch 2858/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 2858: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8286 - f1_score: 0.6873\n",
      "Epoch 2859/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 2859: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8302 - f1_score: 0.6881\n",
      "Epoch 2860/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8300 - f1_score: 0.6883\n",
      "Epoch 2860: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8299 - f1_score: 0.6883\n",
      "Epoch 2861/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6886\n",
      "Epoch 2861: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 2862/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 2862: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 2863/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6875\n",
      "Epoch 2863: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6875\n",
      "Epoch 2864/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8301 - f1_score: 0.6874\n",
      "Epoch 2864: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3812 - accuracy: 0.8300 - f1_score: 0.6874\n",
      "Epoch 2865/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8296 - f1_score: 0.6872\n",
      "Epoch 2865: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6872\n",
      "Epoch 2866/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6875\n",
      "Epoch 2866: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6875\n",
      "Epoch 2867/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 2867: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6872\n",
      "Epoch 2868/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6879\n",
      "Epoch 2868: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6880\n",
      "Epoch 2869/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6871\n",
      "Epoch 2869: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3870 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 2870/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 2870: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 2871/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8293 - f1_score: 0.6892\n",
      "Epoch 2871: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8293 - f1_score: 0.6894\n",
      "Epoch 2872/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 2872: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 2873/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 2873: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 2874/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2874: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2875/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 2875: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 2876/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6881\n",
      "Epoch 2876: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6882\n",
      "Epoch 2877/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 2877: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8281 - f1_score: 0.6888\n",
      "Epoch 2878/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 2878: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8293 - f1_score: 0.6885\n",
      "Epoch 2879/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 2879: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 2880/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8287 - f1_score: 0.6875\n",
      "Epoch 2880: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 2881/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 2881: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 2882/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 2882: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 2883/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6875\n",
      "Epoch 2883: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8302 - f1_score: 0.6876\n",
      "Epoch 2884/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 2884: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3807 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 2885/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8289 - f1_score: 0.6888\n",
      "Epoch 2885: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6888\n",
      "Epoch 2886/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 2886: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 2887/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 2887: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 2888/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 2888: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6880\n",
      "Epoch 2889/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 2889: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 2890/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 2890: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 2891/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 2891: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 2892/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 2892: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 2893/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8278 - f1_score: 0.6882\n",
      "Epoch 2893: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8277 - f1_score: 0.6883\n",
      "Epoch 2894/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6883\n",
      "Epoch 2894: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3859 - accuracy: 0.8272 - f1_score: 0.6883\n",
      "Epoch 2895/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 2895: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3861 - accuracy: 0.8271 - f1_score: 0.6873\n",
      "Epoch 2896/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 2896: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3813 - accuracy: 0.8303 - f1_score: 0.6881\n",
      "Epoch 2897/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 2897: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 2898/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8305 - f1_score: 0.6898\n",
      "Epoch 2898: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3806 - accuracy: 0.8305 - f1_score: 0.6899\n",
      "Epoch 2899/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 2899: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2900/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8278 - f1_score: 0.6871\n",
      "Epoch 2900: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3852 - accuracy: 0.8277 - f1_score: 0.6871\n",
      "Epoch 2901/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 2901: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 2902/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8272 - f1_score: 0.6874\n",
      "Epoch 2902: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3859 - accuracy: 0.8271 - f1_score: 0.6874\n",
      "Epoch 2903/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8299 - f1_score: 0.6879\n",
      "Epoch 2903: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8299 - f1_score: 0.6879\n",
      "Epoch 2904/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 2904: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 2905/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 2905: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 2906/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 2906: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 2907/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2907: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2908/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 2908: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6882\n",
      "Epoch 2909/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6882\n",
      "Epoch 2909: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 2910/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 2910: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8303 - f1_score: 0.6885\n",
      "Epoch 2911/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8311 - f1_score: 0.6898\n",
      "Epoch 2911: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3795 - accuracy: 0.8311 - f1_score: 0.6898\n",
      "Epoch 2912/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8312 - f1_score: 0.6889\n",
      "Epoch 2912: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8312 - f1_score: 0.6887\n",
      "Epoch 2913/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 2913: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 2914/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 2914: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 2915/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 2915: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 2916/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 2916: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3879 - accuracy: 0.8260 - f1_score: 0.6866\n",
      "Epoch 2917/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8264 - f1_score: 0.6877\n",
      "Epoch 2917: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8264 - f1_score: 0.6877\n",
      "Epoch 2918/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 2918: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 2919/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 2919: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 2920/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8293 - f1_score: 0.6876\n",
      "Epoch 2920: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8293 - f1_score: 0.6876\n",
      "Epoch 2921/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6867\n",
      "Epoch 2921: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6867\n",
      "Epoch 2922/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 2922: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 2923/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 2923: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 2924/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 2924: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 2925/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 2925: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 2926/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6898\n",
      "Epoch 2926: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6898\n",
      "Epoch 2927/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6889\n",
      "Epoch 2927: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6888\n",
      "Epoch 2928/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 2928: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 2929/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 2929: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 2930/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 2930: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 2931/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8301 - f1_score: 0.6881\n",
      "Epoch 2931: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6881\n",
      "Epoch 2932/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 2932: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 2933/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 2933: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 2934/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8312 - f1_score: 0.6888\n",
      "Epoch 2934: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 2935/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 2935: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8303 - f1_score: 0.6889\n",
      "Epoch 2936/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 2936: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 2937/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 2937: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8299 - f1_score: 0.6884\n",
      "Epoch 2938/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8284 - f1_score: 0.6873\n",
      "Epoch 2938: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 2939/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8296 - f1_score: 0.6874\n",
      "Epoch 2939: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6874\n",
      "Epoch 2940/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6896\n",
      "Epoch 2940: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6896\n",
      "Epoch 2941/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 2941: accuracy did not improve from 0.83189\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 2942/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8323 - f1_score: 0.6890\n",
      "Epoch 2942: accuracy improved from 0.83189 to 0.83224, saving model to ./625-batch_size625\\weight-improvement2-2942-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8322 - f1_score: 0.6891\n",
      "Epoch 2943/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 2943: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 2944/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8297 - f1_score: 0.6894\n",
      "Epoch 2944: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8296 - f1_score: 0.6892\n",
      "Epoch 2945/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 2945: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 2946/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 2946: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3832 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 2947/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 2947: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6883\n",
      "Epoch 2948/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 2948: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 2949/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 2949: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 2950/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8289 - f1_score: 0.6882\n",
      "Epoch 2950: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8289 - f1_score: 0.6882\n",
      "Epoch 2951/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6885\n",
      "Epoch 2951: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3852 - accuracy: 0.8277 - f1_score: 0.6884\n",
      "Epoch 2952/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6885\n",
      "Epoch 2952: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 2953/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 2953: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 2954/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6889\n",
      "Epoch 2954: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8293 - f1_score: 0.6888\n",
      "Epoch 2955/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 2955: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 2956/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6892\n",
      "Epoch 2956: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6893\n",
      "Epoch 2957/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 2957: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 2958/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 2958: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6887\n",
      "Epoch 2959/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8285 - f1_score: 0.6893\n",
      "Epoch 2959: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8284 - f1_score: 0.6892\n",
      "Epoch 2960/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6893\n",
      "Epoch 2960: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8289 - f1_score: 0.6891\n",
      "Epoch 2961/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2961: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 2962/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 2962: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 2963/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 2963: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 2964/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 2964: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8286 - f1_score: 0.6885\n",
      "Epoch 2965/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8275 - f1_score: 0.6884\n",
      "Epoch 2965: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8276 - f1_score: 0.6885\n",
      "Epoch 2966/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 2966: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8293 - f1_score: 0.6886\n",
      "Epoch 2967/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 2967: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 2968/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 2968: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 2969/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6867\n",
      "Epoch 2969: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6867\n",
      "Epoch 2970/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 2970: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 2971/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 2971: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 2972/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 2972: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3805 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 2973/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 2973: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6888\n",
      "Epoch 2974/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 2974: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3829 - accuracy: 0.8282 - f1_score: 0.6884\n",
      "Epoch 2975/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 2975: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 2976/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 2976: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 2977/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 2977: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 2978/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 2978: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 2979/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 2979: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 2980/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 2980: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 2981/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 2981: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 2982/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 2982: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 2983/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8303 - f1_score: 0.6879\n",
      "Epoch 2983: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6879\n",
      "Epoch 2984/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 2984: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6877\n",
      "Epoch 2985/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8312 - f1_score: 0.6879\n",
      "Epoch 2985: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8313 - f1_score: 0.6879\n",
      "Epoch 2986/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 2986: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 2987/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 2987: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 2988/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6882\n",
      "Epoch 2988: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6884\n",
      "Epoch 2989/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 2989: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 2990/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8297 - f1_score: 0.6879\n",
      "Epoch 2990: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8297 - f1_score: 0.6879\n",
      "Epoch 2991/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 2991: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 2992/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 2992: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6876\n",
      "Epoch 2993/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 2993: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8275 - f1_score: 0.6872\n",
      "Epoch 2994/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 2994: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 2995/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8303 - f1_score: 0.6873\n",
      "Epoch 2995: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8304 - f1_score: 0.6873\n",
      "Epoch 2996/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 2996: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3820 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 2997/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8289 - f1_score: 0.6872\n",
      "Epoch 2997: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8289 - f1_score: 0.6873\n",
      "Epoch 2998/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 2998: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 2999/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8311 - f1_score: 0.6881\n",
      "Epoch 2999: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8312 - f1_score: 0.6882\n",
      "Epoch 3000/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8301 - f1_score: 0.6875\n",
      "Epoch 3000: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8301 - f1_score: 0.6875\n",
      "Epoch 3001/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8317 - f1_score: 0.6884\n",
      "Epoch 3001: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8318 - f1_score: 0.6884\n",
      "Epoch 3002/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8303 - f1_score: 0.6876\n",
      "Epoch 3002: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3823 - accuracy: 0.8305 - f1_score: 0.6875\n",
      "Epoch 3003/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 3003: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6879\n",
      "Epoch 3004/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8307 - f1_score: 0.6882\n",
      "Epoch 3004: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3821 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 3005/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 3005: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 3006/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8282 - f1_score: 0.6869\n",
      "Epoch 3006: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6871\n",
      "Epoch 3007/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8274 - f1_score: 0.6876\n",
      "Epoch 3007: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3863 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 3008/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 3008: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 3009/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 3009: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3010/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 3010: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 3011/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6894\n",
      "Epoch 3011: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6894\n",
      "Epoch 3012/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 3012: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 3013/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 3013: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 3014/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6876\n",
      "Epoch 3014: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6877\n",
      "Epoch 3015/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8308 - f1_score: 0.6883\n",
      "Epoch 3015: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.8308 - f1_score: 0.6882\n",
      "Epoch 3016/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 3016: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 3017/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8297 - f1_score: 0.6892\n",
      "Epoch 3017: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8298 - f1_score: 0.6892\n",
      "Epoch 3018/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8283 - f1_score: 0.6871\n",
      "Epoch 3018: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 3019/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6885\n",
      "Epoch 3019: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6885\n",
      "Epoch 3020/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6887\n",
      "Epoch 3020: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8285 - f1_score: 0.6887\n",
      "Epoch 3021/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8306 - f1_score: 0.6878\n",
      "Epoch 3021: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8306 - f1_score: 0.6878\n",
      "Epoch 3022/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6900\n",
      "Epoch 3022: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6899\n",
      "Epoch 3023/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6889\n",
      "Epoch 3023: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6889\n",
      "Epoch 3024/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 3024: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 3025/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 3025: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 3026/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 3026: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 3027/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8293 - f1_score: 0.6886\n",
      "Epoch 3027: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8293 - f1_score: 0.6885\n",
      "Epoch 3028/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 3028: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8286 - f1_score: 0.6885\n",
      "Epoch 3029/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6894\n",
      "Epoch 3029: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8306 - f1_score: 0.6894\n",
      "Epoch 3030/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 3030: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 3031/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 3031: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 3032/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8304 - f1_score: 0.6878\n",
      "Epoch 3032: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8305 - f1_score: 0.6879\n",
      "Epoch 3033/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 3033: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 3034/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3825 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 3034: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 3035/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8292 - f1_score: 0.6873\n",
      "Epoch 3035: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6874\n",
      "Epoch 3036/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 3036: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 3037/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8277 - f1_score: 0.6875\n",
      "Epoch 3037: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3864 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 3038/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6866\n",
      "Epoch 3038: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6866\n",
      "Epoch 3039/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 3039: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 3040/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 3040: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3820 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 3041/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8293 - f1_score: 0.6886\n",
      "Epoch 3041: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 3042/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 3042: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 3043/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 3043: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 3044/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 3044: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 3045/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 3045: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 3046/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 3046: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 3047/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8297 - f1_score: 0.6883\n",
      "Epoch 3047: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 3048/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8305 - f1_score: 0.6895\n",
      "Epoch 3048: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8305 - f1_score: 0.6895\n",
      "Epoch 3049/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 3049: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 3050/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8306 - f1_score: 0.6887\n",
      "Epoch 3050: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 3051/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8302 - f1_score: 0.6877\n",
      "Epoch 3051: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6877\n",
      "Epoch 3052/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8293 - f1_score: 0.6885\n",
      "Epoch 3052: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8292 - f1_score: 0.6885\n",
      "Epoch 3053/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6890\n",
      "Epoch 3053: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6890\n",
      "Epoch 3054/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 3054: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 3055/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8300 - f1_score: 0.6878\n",
      "Epoch 3055: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8300 - f1_score: 0.6880\n",
      "Epoch 3056/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8300 - f1_score: 0.6878\n",
      "Epoch 3056: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3823 - accuracy: 0.8300 - f1_score: 0.6878\n",
      "Epoch 3057/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 3057: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 3058/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8283 - f1_score: 0.6889\n",
      "Epoch 3058: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8283 - f1_score: 0.6889\n",
      "Epoch 3059/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 3059: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 3060/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8297 - f1_score: 0.6888\n",
      "Epoch 3060: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8297 - f1_score: 0.6888\n",
      "Epoch 3061/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6880\n",
      "Epoch 3061: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 3062/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 3062: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6890\n",
      "Epoch 3063/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8290 - f1_score: 0.6889\n",
      "Epoch 3063: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8289 - f1_score: 0.6890\n",
      "Epoch 3064/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 3064: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6876\n",
      "Epoch 3065/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 3065: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3066/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 3066: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6888\n",
      "Epoch 3067/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8313 - f1_score: 0.6898\n",
      "Epoch 3067: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3793 - accuracy: 0.8312 - f1_score: 0.6899\n",
      "Epoch 3068/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8317 - f1_score: 0.6892\n",
      "Epoch 3068: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3812 - accuracy: 0.8316 - f1_score: 0.6892\n",
      "Epoch 3069/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6878\n",
      "Epoch 3069: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 3070/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 3070: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6888\n",
      "Epoch 3071/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8290 - f1_score: 0.6888\n",
      "Epoch 3071: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8289 - f1_score: 0.6888\n",
      "Epoch 3072/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 3072: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 3073/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 3073: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3850 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 3074/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 3074: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 3075/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 3075: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 3076/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 3076: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 3077/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8272 - f1_score: 0.6878\n",
      "Epoch 3077: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3860 - accuracy: 0.8271 - f1_score: 0.6879\n",
      "Epoch 3078/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 3078: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 3079/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 3079: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 3080/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 3080: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 3081/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 3081: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6883\n",
      "Epoch 3082/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6887\n",
      "Epoch 3082: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 3083/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8306 - f1_score: 0.6898\n",
      "Epoch 3083: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8306 - f1_score: 0.6898\n",
      "Epoch 3084/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8311 - f1_score: 0.6883\n",
      "Epoch 3084: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3804 - accuracy: 0.8311 - f1_score: 0.6883\n",
      "Epoch 3085/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 3085: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 3086/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8293 - f1_score: 0.6889\n",
      "Epoch 3086: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 3087/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8303 - f1_score: 0.6874\n",
      "Epoch 3087: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8304 - f1_score: 0.6874\n",
      "Epoch 3088/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 3088: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 3089/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 3089: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 3090/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 3090: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 3091/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 3091: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 3092/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8297 - f1_score: 0.6892\n",
      "Epoch 3092: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8297 - f1_score: 0.6893\n",
      "Epoch 3093/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 3093: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 3094/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6873\n",
      "Epoch 3094: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6875\n",
      "Epoch 3095/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 3095: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6888\n",
      "Epoch 3096/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6893\n",
      "Epoch 3096: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6892\n",
      "Epoch 3097/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6883\n",
      "Epoch 3097: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6883\n",
      "Epoch 3098/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 3098: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3842 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 3099/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8293 - f1_score: 0.6876\n",
      "Epoch 3099: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 3100/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 3100: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 3101/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8293 - f1_score: 0.6872\n",
      "Epoch 3101: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8296 - f1_score: 0.6874\n",
      "Epoch 3102/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6872\n",
      "Epoch 3102: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6871\n",
      "Epoch 3103/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8296 - f1_score: 0.6873\n",
      "Epoch 3103: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6873\n",
      "Epoch 3104/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 3104: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 3105/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 3105: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 3106/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 3106: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 3107/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8305 - f1_score: 0.6872\n",
      "Epoch 3107: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8305 - f1_score: 0.6870\n",
      "Epoch 3108/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8316 - f1_score: 0.6888\n",
      "Epoch 3108: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8316 - f1_score: 0.6888\n",
      "Epoch 3109/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8302 - f1_score: 0.6870\n",
      "Epoch 3109: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8302 - f1_score: 0.6871\n",
      "Epoch 3110/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8277 - f1_score: 0.6872\n",
      "Epoch 3110: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8278 - f1_score: 0.6872\n",
      "Epoch 3111/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 3111: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 3112/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6879\n",
      "Epoch 3112: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6879\n",
      "Epoch 3113/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 3113: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6887\n",
      "Epoch 3114/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 3114: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 3115/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 3115: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 3116/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8295 - f1_score: 0.6865\n",
      "Epoch 3116: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8294 - f1_score: 0.6864\n",
      "Epoch 3117/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8311 - f1_score: 0.6880\n",
      "Epoch 3117: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8311 - f1_score: 0.6880\n",
      "Epoch 3118/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8312 - f1_score: 0.6886\n",
      "Epoch 3118: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8312 - f1_score: 0.6886\n",
      "Epoch 3119/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6879\n",
      "Epoch 3119: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8310 - f1_score: 0.6879\n",
      "Epoch 3120/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3120: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3121/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8296 - f1_score: 0.6882\n",
      "Epoch 3121: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 3122/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8299 - f1_score: 0.6895\n",
      "Epoch 3122: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8299 - f1_score: 0.6894\n",
      "Epoch 3123/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 3123: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3124/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 3124: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 3125/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 3125: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8305 - f1_score: 0.6886\n",
      "Epoch 3126/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8275 - f1_score: 0.6880\n",
      "Epoch 3126: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8275 - f1_score: 0.6880\n",
      "Epoch 3127/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 3127: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 3128/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.8247 - f1_score: 0.6864\n",
      "Epoch 3128: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3908 - accuracy: 0.8247 - f1_score: 0.6864\n",
      "Epoch 3129/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 3129: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 3130/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 3130: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 3131/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6868\n",
      "Epoch 3131: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8290 - f1_score: 0.6868\n",
      "Epoch 3132/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 3132: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 3133/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 3133: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 3134/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 3134: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 3135/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 3135: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 3136/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 3136: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 3137/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8308 - f1_score: 0.6889\n",
      "Epoch 3137: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8308 - f1_score: 0.6889\n",
      "Epoch 3138/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8292 - f1_score: 0.6876\n",
      "Epoch 3138: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6877\n",
      "Epoch 3139/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8311 - f1_score: 0.6892\n",
      "Epoch 3139: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8310 - f1_score: 0.6890\n",
      "Epoch 3140/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8302 - f1_score: 0.6888\n",
      "Epoch 3140: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 3141/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6891\n",
      "Epoch 3141: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6891\n",
      "Epoch 3142/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3142: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 3143/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 3143: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 3144/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 3144: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 3145/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8295 - f1_score: 0.6885\n",
      "Epoch 3145: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 3146/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 3146: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 3147/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 3147: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 3148/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 3148: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6881\n",
      "Epoch 3149/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 3149: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3150/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.8311 - f1_score: 0.6888\n",
      "Epoch 3150: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8311 - f1_score: 0.6888\n",
      "Epoch 3151/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8306 - f1_score: 0.6891\n",
      "Epoch 3151: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3802 - accuracy: 0.8305 - f1_score: 0.6890\n",
      "Epoch 3152/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3152: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 3153/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3153: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 3154/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8308 - f1_score: 0.6900\n",
      "Epoch 3154: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8307 - f1_score: 0.6898\n",
      "Epoch 3155/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3155: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 3156/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8322 - f1_score: 0.6876\n",
      "Epoch 3156: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8320 - f1_score: 0.6875\n",
      "Epoch 3157/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 3157: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6885\n",
      "Epoch 3158/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 3158: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 3159/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 3159: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 3160/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8301 - f1_score: 0.6889\n",
      "Epoch 3160: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3807 - accuracy: 0.8300 - f1_score: 0.6889\n",
      "Epoch 3161/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 3161: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 3162/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8293 - f1_score: 0.6878\n",
      "Epoch 3162: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8293 - f1_score: 0.6878\n",
      "Epoch 3163/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 3163: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3164/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8295 - f1_score: 0.6884\n",
      "Epoch 3164: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 3165/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8312 - f1_score: 0.6886\n",
      "Epoch 3165: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8310 - f1_score: 0.6885\n",
      "Epoch 3166/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8286 - f1_score: 0.6887\n",
      "Epoch 3166: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8286 - f1_score: 0.6886\n",
      "Epoch 3167/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8294 - f1_score: 0.6892\n",
      "Epoch 3167: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8294 - f1_score: 0.6892\n",
      "Epoch 3168/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8297 - f1_score: 0.6889\n",
      "Epoch 3168: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8298 - f1_score: 0.6890\n",
      "Epoch 3169/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 3169: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 3170/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 3170: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 3171/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 3171: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 3172/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 3172: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3821 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 3173/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 3173: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 3174/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 3174: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 3175/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 3175: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8276 - f1_score: 0.6869\n",
      "Epoch 3176/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8267 - f1_score: 0.6879\n",
      "Epoch 3176: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8266 - f1_score: 0.6880\n",
      "Epoch 3177/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6889\n",
      "Epoch 3177: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6889\n",
      "Epoch 3178/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8299 - f1_score: 0.6901\n",
      "Epoch 3178: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8298 - f1_score: 0.6901\n",
      "Epoch 3179/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8296 - f1_score: 0.6890\n",
      "Epoch 3179: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6891\n",
      "Epoch 3180/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6890\n",
      "Epoch 3180: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6890\n",
      "Epoch 3181/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 3181: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 3182/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8301 - f1_score: 0.6893\n",
      "Epoch 3182: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8301 - f1_score: 0.6893\n",
      "Epoch 3183/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8300 - f1_score: 0.6902\n",
      "Epoch 3183: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3794 - accuracy: 0.8300 - f1_score: 0.6902\n",
      "Epoch 3184/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 3184: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 3185/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 3185: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 3186/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 3186: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 3187/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8311 - f1_score: 0.6878\n",
      "Epoch 3187: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8311 - f1_score: 0.6878\n",
      "Epoch 3188/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8289 - f1_score: 0.6891\n",
      "Epoch 3188: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8289 - f1_score: 0.6892\n",
      "Epoch 3189/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8284 - f1_score: 0.6888\n",
      "Epoch 3189: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8285 - f1_score: 0.6889\n",
      "Epoch 3190/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8299 - f1_score: 0.6897\n",
      "Epoch 3190: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8298 - f1_score: 0.6896\n",
      "Epoch 3191/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 3191: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8276 - f1_score: 0.6878\n",
      "Epoch 3192/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 3192: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 3193/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 3193: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6890\n",
      "Epoch 3194/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8316 - f1_score: 0.6886\n",
      "Epoch 3194: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8318 - f1_score: 0.6888\n",
      "Epoch 3195/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8303 - f1_score: 0.6881\n",
      "Epoch 3195: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8302 - f1_score: 0.6882\n",
      "Epoch 3196/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8305 - f1_score: 0.6891\n",
      "Epoch 3196: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8305 - f1_score: 0.6890\n",
      "Epoch 3197/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8309 - f1_score: 0.6897\n",
      "Epoch 3197: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6898\n",
      "Epoch 3198/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8318 - f1_score: 0.6882\n",
      "Epoch 3198: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8317 - f1_score: 0.6882\n",
      "Epoch 3199/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 3199: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8289 - f1_score: 0.6875\n",
      "Epoch 3200/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 3200: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 3201/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 3201: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 3202/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8304 - f1_score: 0.6895\n",
      "Epoch 3202: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8304 - f1_score: 0.6895\n",
      "Epoch 3203/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6898\n",
      "Epoch 3203: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8292 - f1_score: 0.6897\n",
      "Epoch 3204/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 3204: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 3205/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8310 - f1_score: 0.6886\n",
      "Epoch 3205: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8310 - f1_score: 0.6886\n",
      "Epoch 3206/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 3206: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 3207/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8299 - f1_score: 0.6874\n",
      "Epoch 3207: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6874\n",
      "Epoch 3208/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 3208: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 3209/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8311 - f1_score: 0.6881\n",
      "Epoch 3209: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8310 - f1_score: 0.6881\n",
      "Epoch 3210/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8312 - f1_score: 0.6885\n",
      "Epoch 3210: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8311 - f1_score: 0.6885\n",
      "Epoch 3211/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 3211: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 3212/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6886\n",
      "Epoch 3212: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 3213/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8308 - f1_score: 0.6888\n",
      "Epoch 3213: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 3214/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8317 - f1_score: 0.6890\n",
      "Epoch 3214: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3795 - accuracy: 0.8317 - f1_score: 0.6893\n",
      "Epoch 3215/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6882\n",
      "Epoch 3215: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3804 - accuracy: 0.8308 - f1_score: 0.6882\n",
      "Epoch 3216/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8317 - f1_score: 0.6887\n",
      "Epoch 3216: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3794 - accuracy: 0.8317 - f1_score: 0.6888\n",
      "Epoch 3217/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8307 - f1_score: 0.6894\n",
      "Epoch 3217: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8308 - f1_score: 0.6893\n",
      "Epoch 3218/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 3218: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6887\n",
      "Epoch 3219/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 3219: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 3220/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 3220: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6892\n",
      "Epoch 3221/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8318 - f1_score: 0.6899\n",
      "Epoch 3221: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8319 - f1_score: 0.6899\n",
      "Epoch 3222/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8306 - f1_score: 0.6897\n",
      "Epoch 3222: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8306 - f1_score: 0.6897\n",
      "Epoch 3223/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 3223: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 3224/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8265 - f1_score: 0.6874\n",
      "Epoch 3224: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3877 - accuracy: 0.8264 - f1_score: 0.6875\n",
      "Epoch 3225/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 3225: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 3226/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8301 - f1_score: 0.6881\n",
      "Epoch 3226: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 3227/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 3227: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 3228/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 3228: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8287 - f1_score: 0.6879\n",
      "Epoch 3229/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6876\n",
      "Epoch 3229: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8302 - f1_score: 0.6878\n",
      "Epoch 3230/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8302 - f1_score: 0.6881\n",
      "Epoch 3230: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 3231/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8289 - f1_score: 0.6867\n",
      "Epoch 3231: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8291 - f1_score: 0.6866\n",
      "Epoch 3232/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8310 - f1_score: 0.6876\n",
      "Epoch 3232: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8310 - f1_score: 0.6876\n",
      "Epoch 3233/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8274 - f1_score: 0.6866\n",
      "Epoch 3233: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6867\n",
      "Epoch 3234/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8319 - f1_score: 0.6885\n",
      "Epoch 3234: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8318 - f1_score: 0.6883\n",
      "Epoch 3235/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 3235: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 3236/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 3236: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8276 - f1_score: 0.6880\n",
      "Epoch 3237/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8299 - f1_score: 0.6884\n",
      "Epoch 3237: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8299 - f1_score: 0.6884\n",
      "Epoch 3238/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 3238: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 3239/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6896\n",
      "Epoch 3239: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6895\n",
      "Epoch 3240/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3240: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 3241/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 3241: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8296 - f1_score: 0.6887\n",
      "Epoch 3242/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6875\n",
      "Epoch 3242: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6875\n",
      "Epoch 3243/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 3243: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8284 - f1_score: 0.6881\n",
      "Epoch 3244/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6876\n",
      "Epoch 3244: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8304 - f1_score: 0.6877\n",
      "Epoch 3245/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 3245: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 3246/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8282 - f1_score: 0.6878\n",
      "Epoch 3246: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8282 - f1_score: 0.6880\n",
      "Epoch 3247/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6885\n",
      "Epoch 3247: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8284 - f1_score: 0.6885\n",
      "Epoch 3248/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 3248: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6880\n",
      "Epoch 3249/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8280 - f1_score: 0.6872\n",
      "Epoch 3249: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 3250/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8310 - f1_score: 0.6885\n",
      "Epoch 3250: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6885\n",
      "Epoch 3251/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8316 - f1_score: 0.6895\n",
      "Epoch 3251: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8315 - f1_score: 0.6892\n",
      "Epoch 3252/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 3252: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 3253/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 3253: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8313 - f1_score: 0.6888\n",
      "Epoch 3254/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 3254: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 3255/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 3255: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 3256/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8313 - f1_score: 0.6896\n",
      "Epoch 3256: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3802 - accuracy: 0.8312 - f1_score: 0.6896\n",
      "Epoch 3257/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 3257: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 3258/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 3258: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 3259/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8279 - f1_score: 0.6877\n",
      "Epoch 3259: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3862 - accuracy: 0.8278 - f1_score: 0.6878\n",
      "Epoch 3260/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8270 - f1_score: 0.6892\n",
      "Epoch 3260: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8270 - f1_score: 0.6892\n",
      "Epoch 3261/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 3261: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8271 - f1_score: 0.6875\n",
      "Epoch 3262/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 3262: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 3263/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8306 - f1_score: 0.6895\n",
      "Epoch 3263: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8306 - f1_score: 0.6895\n",
      "Epoch 3264/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 3264: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6880\n",
      "Epoch 3265/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 3265: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 3266/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8314 - f1_score: 0.6883\n",
      "Epoch 3266: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8315 - f1_score: 0.6882\n",
      "Epoch 3267/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6881\n",
      "Epoch 3267: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8301 - f1_score: 0.6881\n",
      "Epoch 3268/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 3268: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 3269/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8314 - f1_score: 0.6885\n",
      "Epoch 3269: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8314 - f1_score: 0.6885\n",
      "Epoch 3270/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 3270: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 3271/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 3271: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 3272/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 3272: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 3273/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 3273: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 3274/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 3274: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 3275/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6885\n",
      "Epoch 3275: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6885\n",
      "Epoch 3276/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8296 - f1_score: 0.6890\n",
      "Epoch 3276: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8296 - f1_score: 0.6890\n",
      "Epoch 3277/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8282 - f1_score: 0.6883\n",
      "Epoch 3277: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8281 - f1_score: 0.6884\n",
      "Epoch 3278/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3278: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3279/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 3279: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 3280/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 3280: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 3281/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 3281: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8303 - f1_score: 0.6889\n",
      "Epoch 3282/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8304 - f1_score: 0.6901\n",
      "Epoch 3282: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8304 - f1_score: 0.6901\n",
      "Epoch 3283/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 3283: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 3284/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 3284: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6888\n",
      "Epoch 3285/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 3285: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 3286/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8287 - f1_score: 0.6890\n",
      "Epoch 3286: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8287 - f1_score: 0.6891\n",
      "Epoch 3287/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6887\n",
      "Epoch 3287: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6887\n",
      "Epoch 3288/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8281 - f1_score: 0.6885\n",
      "Epoch 3288: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8281 - f1_score: 0.6886\n",
      "Epoch 3289/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 3289: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 3290/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 3290: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 3291/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 3291: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 3292/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8274 - f1_score: 0.6883\n",
      "Epoch 3292: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8273 - f1_score: 0.6884\n",
      "Epoch 3293/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8283 - f1_score: 0.6883\n",
      "Epoch 3293: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 3294/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 3294: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8283 - f1_score: 0.6872\n",
      "Epoch 3295/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 3295: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6877\n",
      "Epoch 3296/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8275 - f1_score: 0.6867\n",
      "Epoch 3296: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8276 - f1_score: 0.6866\n",
      "Epoch 3297/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8277 - f1_score: 0.6882\n",
      "Epoch 3297: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8277 - f1_score: 0.6881\n",
      "Epoch 3298/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8295 - f1_score: 0.6877\n",
      "Epoch 3298: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 3299/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6878\n",
      "Epoch 3299: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6878\n",
      "Epoch 3300/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8296 - f1_score: 0.6875\n",
      "Epoch 3300: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6874\n",
      "Epoch 3301/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8305 - f1_score: 0.6896\n",
      "Epoch 3301: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8304 - f1_score: 0.6896\n",
      "Epoch 3302/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8304 - f1_score: 0.6881\n",
      "Epoch 3302: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8304 - f1_score: 0.6881\n",
      "Epoch 3303/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8314 - f1_score: 0.6882\n",
      "Epoch 3303: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8314 - f1_score: 0.6882\n",
      "Epoch 3304/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 3304: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 3305/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8293 - f1_score: 0.6871\n",
      "Epoch 3305: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8293 - f1_score: 0.6870\n",
      "Epoch 3306/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8307 - f1_score: 0.6876\n",
      "Epoch 3306: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8307 - f1_score: 0.6877\n",
      "Epoch 3307/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6876\n",
      "Epoch 3307: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6877\n",
      "Epoch 3308/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6874\n",
      "Epoch 3308: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8279 - f1_score: 0.6875\n",
      "Epoch 3309/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 3309: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 3310/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6878\n",
      "Epoch 3310: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6879\n",
      "Epoch 3311/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 3311: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 3312/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 3312: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 3313/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8281 - f1_score: 0.6876\n",
      "Epoch 3313: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8281 - f1_score: 0.6877\n",
      "Epoch 3314/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6881\n",
      "Epoch 3314: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6878\n",
      "Epoch 3315/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 3315: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 3316/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8284 - f1_score: 0.6880\n",
      "Epoch 3316: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8284 - f1_score: 0.6880\n",
      "Epoch 3317/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 3317: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 3318/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 3318: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 3319/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 3319: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 3320/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8293 - f1_score: 0.6874\n",
      "Epoch 3320: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6874\n",
      "Epoch 3321/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 3321: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 3322/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 3322: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 3323/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 3323: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 3324/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 3324: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8292 - f1_score: 0.6881\n",
      "Epoch 3325/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6877\n",
      "Epoch 3325: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8303 - f1_score: 0.6876\n",
      "Epoch 3326/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 3326: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 3327/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 3327: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 3328/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 3328: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 3329/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8283 - f1_score: 0.6871\n",
      "Epoch 3329: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8283 - f1_score: 0.6870\n",
      "Epoch 3330/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 3330: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 3331/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6886\n",
      "Epoch 3331: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 3332/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6878\n",
      "Epoch 3332: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6877\n",
      "Epoch 3333/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3333: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 3334/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 3334: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 3335/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8297 - f1_score: 0.6889\n",
      "Epoch 3335: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 3336/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 3336: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 3337/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8321 - f1_score: 0.6892\n",
      "Epoch 3337: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8322 - f1_score: 0.6892\n",
      "Epoch 3338/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6885\n",
      "Epoch 3338: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 3339/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 3339: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 3340/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6882\n",
      "Epoch 3340: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8302 - f1_score: 0.6882\n",
      "Epoch 3341/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6874\n",
      "Epoch 3341: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8295 - f1_score: 0.6874\n",
      "Epoch 3342/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 3342: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6873\n",
      "Epoch 3343/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 3343: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 3344/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 3344: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 3345/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8307 - f1_score: 0.6882\n",
      "Epoch 3345: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8306 - f1_score: 0.6883\n",
      "Epoch 3346/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3346: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8304 - f1_score: 0.6883\n",
      "Epoch 3347/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 3347: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 3348/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 3348: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 3349/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8288 - f1_score: 0.6869\n",
      "Epoch 3349: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3860 - accuracy: 0.8288 - f1_score: 0.6868\n",
      "Epoch 3350/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8292 - f1_score: 0.6866\n",
      "Epoch 3350: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3839 - accuracy: 0.8292 - f1_score: 0.6866\n",
      "Epoch 3351/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6868\n",
      "Epoch 3351: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6868\n",
      "Epoch 3352/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8306 - f1_score: 0.6887\n",
      "Epoch 3352: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8306 - f1_score: 0.6886\n",
      "Epoch 3353/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3353: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3354/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6874\n",
      "Epoch 3354: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 3355/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 3355: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 3356/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6862\n",
      "Epoch 3356: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8268 - f1_score: 0.6862\n",
      "Epoch 3357/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 3357: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6877\n",
      "Epoch 3358/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8278 - f1_score: 0.6863\n",
      "Epoch 3358: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8280 - f1_score: 0.6864\n",
      "Epoch 3359/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8296 - f1_score: 0.6878\n",
      "Epoch 3359: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 3360/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6871\n",
      "Epoch 3360: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8273 - f1_score: 0.6870\n",
      "Epoch 3361/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6878\n",
      "Epoch 3361: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6877\n",
      "Epoch 3362/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8276 - f1_score: 0.6871\n",
      "Epoch 3362: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3868 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 3363/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8272 - f1_score: 0.6885\n",
      "Epoch 3363: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8272 - f1_score: 0.6885\n",
      "Epoch 3364/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 3364: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 3365/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 3365: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 3366/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 3366: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 3367/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8305 - f1_score: 0.6877\n",
      "Epoch 3367: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8305 - f1_score: 0.6877\n",
      "Epoch 3368/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 3368: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 3369/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6880\n",
      "Epoch 3369: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6879\n",
      "Epoch 3370/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8298 - f1_score: 0.6879\n",
      "Epoch 3370: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3815 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 3371/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6876\n",
      "Epoch 3371: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6877\n",
      "Epoch 3372/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8309 - f1_score: 0.6873\n",
      "Epoch 3372: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8308 - f1_score: 0.6873\n",
      "Epoch 3373/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6869\n",
      "Epoch 3373: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6869\n",
      "Epoch 3374/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 3374: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8280 - f1_score: 0.6875\n",
      "Epoch 3375/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6875\n",
      "Epoch 3375: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6875\n",
      "Epoch 3376/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8275 - f1_score: 0.6855\n",
      "Epoch 3376: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6856\n",
      "Epoch 3377/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 3377: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 3378/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 3378: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 3379/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 3379: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 3380/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 3380: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 3381/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8302 - f1_score: 0.6890\n",
      "Epoch 3381: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6889\n",
      "Epoch 3382/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 3382: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3383/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6881\n",
      "Epoch 3383: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 3384/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 3384: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 3385/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 3385: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 3386/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 3386: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 3387/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.8312 - f1_score: 0.6876\n",
      "Epoch 3387: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3807 - accuracy: 0.8312 - f1_score: 0.6876\n",
      "Epoch 3388/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8303 - f1_score: 0.6867\n",
      "Epoch 3388: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8303 - f1_score: 0.6869\n",
      "Epoch 3389/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8308 - f1_score: 0.6886\n",
      "Epoch 3389: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 3390/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8297 - f1_score: 0.6876\n",
      "Epoch 3390: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8297 - f1_score: 0.6876\n",
      "Epoch 3391/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 3391: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8285 - f1_score: 0.6876\n",
      "Epoch 3392/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8290 - f1_score: 0.6873\n",
      "Epoch 3392: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8290 - f1_score: 0.6873\n",
      "Epoch 3393/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8289 - f1_score: 0.6869\n",
      "Epoch 3393: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8290 - f1_score: 0.6869\n",
      "Epoch 3394/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3871 - accuracy: 0.8272 - f1_score: 0.6858\n",
      "Epoch 3394: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3872 - accuracy: 0.8271 - f1_score: 0.6858\n",
      "Epoch 3395/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8290 - f1_score: 0.6883\n",
      "Epoch 3395: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 3396/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 3396: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 3397/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8301 - f1_score: 0.6877\n",
      "Epoch 3397: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8300 - f1_score: 0.6876\n",
      "Epoch 3398/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3398: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 3399/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6875\n",
      "Epoch 3399: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6876\n",
      "Epoch 3400/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 3400: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3867 - accuracy: 0.8278 - f1_score: 0.6875\n",
      "Epoch 3401/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8311 - f1_score: 0.6882\n",
      "Epoch 3401: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8311 - f1_score: 0.6883\n",
      "Epoch 3402/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 3402: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 3403/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8309 - f1_score: 0.6886\n",
      "Epoch 3403: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6885\n",
      "Epoch 3404/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 3404: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 3405/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6885\n",
      "Epoch 3405: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 3406/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 3406: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 3407/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 3407: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8299 - f1_score: 0.6884\n",
      "Epoch 3408/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8276 - f1_score: 0.6883\n",
      "Epoch 3408: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8276 - f1_score: 0.6882\n",
      "Epoch 3409/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 3409: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 3410/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3410: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 3411/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6888\n",
      "Epoch 3411: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 3412/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8305 - f1_score: 0.6879\n",
      "Epoch 3412: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8304 - f1_score: 0.6878\n",
      "Epoch 3413/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6876\n",
      "Epoch 3413: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6876\n",
      "Epoch 3414/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8311 - f1_score: 0.6893\n",
      "Epoch 3414: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8310 - f1_score: 0.6892\n",
      "Epoch 3415/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8308 - f1_score: 0.6892\n",
      "Epoch 3415: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8308 - f1_score: 0.6892\n",
      "Epoch 3416/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6881\n",
      "Epoch 3416: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3839 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 3417/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6884\n",
      "Epoch 3417: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 3418/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 3418: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 3419/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6877\n",
      "Epoch 3419: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 3420/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8304 - f1_score: 0.6880\n",
      "Epoch 3420: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3799 - accuracy: 0.8304 - f1_score: 0.6880\n",
      "Epoch 3421/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6878\n",
      "Epoch 3421: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3823 - accuracy: 0.8303 - f1_score: 0.6880\n",
      "Epoch 3422/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8302 - f1_score: 0.6889\n",
      "Epoch 3422: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3805 - accuracy: 0.8302 - f1_score: 0.6889\n",
      "Epoch 3423/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 3423: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 3424/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6875\n",
      "Epoch 3424: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6875\n",
      "Epoch 3425/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6866\n",
      "Epoch 3425: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6866\n",
      "Epoch 3426/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 3426: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6881\n",
      "Epoch 3427/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8315 - f1_score: 0.6876\n",
      "Epoch 3427: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8315 - f1_score: 0.6876\n",
      "Epoch 3428/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 3428: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 3429/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 3429: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8290 - f1_score: 0.6883\n",
      "Epoch 3430/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 3430: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 3431/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 3431: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 3432/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 3432: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3855 - accuracy: 0.8277 - f1_score: 0.6874\n",
      "Epoch 3433/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 3433: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 3434/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6872\n",
      "Epoch 3434: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6872\n",
      "Epoch 3435/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8307 - f1_score: 0.6879\n",
      "Epoch 3435: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8307 - f1_score: 0.6879\n",
      "Epoch 3436/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8291 - f1_score: 0.6872\n",
      "Epoch 3436: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8291 - f1_score: 0.6871\n",
      "Epoch 3437/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 3437: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 3438/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8310 - f1_score: 0.6889\n",
      "Epoch 3438: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6891\n",
      "Epoch 3439/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 3439: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 3440/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8285 - f1_score: 0.6885\n",
      "Epoch 3440: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8286 - f1_score: 0.6885\n",
      "Epoch 3441/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3825 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 3441: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 3442/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 3442: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 3443/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8281 - f1_score: 0.6874\n",
      "Epoch 3443: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8281 - f1_score: 0.6875\n",
      "Epoch 3444/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8275 - f1_score: 0.6873\n",
      "Epoch 3444: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8276 - f1_score: 0.6873\n",
      "Epoch 3445/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8288 - f1_score: 0.6864\n",
      "Epoch 3445: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6865\n",
      "Epoch 3446/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 3446: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 3447/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 3447: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6881\n",
      "Epoch 3448/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8310 - f1_score: 0.6879\n",
      "Epoch 3448: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6879\n",
      "Epoch 3449/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 3449: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 3450/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8319 - f1_score: 0.6888\n",
      "Epoch 3450: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8319 - f1_score: 0.6888\n",
      "Epoch 3451/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8311 - f1_score: 0.6884\n",
      "Epoch 3451: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8311 - f1_score: 0.6884\n",
      "Epoch 3452/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8296 - f1_score: 0.6875\n",
      "Epoch 3452: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8296 - f1_score: 0.6875\n",
      "Epoch 3453/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3453: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3454/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 3454: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 3455/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6872\n",
      "Epoch 3455: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6873\n",
      "Epoch 3456/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8283 - f1_score: 0.6879\n",
      "Epoch 3456: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8283 - f1_score: 0.6880\n",
      "Epoch 3457/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8310 - f1_score: 0.6881\n",
      "Epoch 3457: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8310 - f1_score: 0.6880\n",
      "Epoch 3458/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8286 - f1_score: 0.6864\n",
      "Epoch 3458: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8286 - f1_score: 0.6865\n",
      "Epoch 3459/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8293 - f1_score: 0.6872\n",
      "Epoch 3459: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8293 - f1_score: 0.6871\n",
      "Epoch 3460/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 3460: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6882\n",
      "Epoch 3461/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8315 - f1_score: 0.6887\n",
      "Epoch 3461: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8315 - f1_score: 0.6887\n",
      "Epoch 3462/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 3462: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 3463/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 3463: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 3464/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6874\n",
      "Epoch 3464: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6874\n",
      "Epoch 3465/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 3465: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 3466/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6872\n",
      "Epoch 3466: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6872\n",
      "Epoch 3467/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8298 - f1_score: 0.6874\n",
      "Epoch 3467: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8299 - f1_score: 0.6874\n",
      "Epoch 3468/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8291 - f1_score: 0.6868\n",
      "Epoch 3468: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8290 - f1_score: 0.6867\n",
      "Epoch 3469/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8298 - f1_score: 0.6874\n",
      "Epoch 3469: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8298 - f1_score: 0.6874\n",
      "Epoch 3470/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 3470: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 3471/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8302 - f1_score: 0.6885\n",
      "Epoch 3471: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 3472/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 3472: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6882\n",
      "Epoch 3473/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 3473: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8302 - f1_score: 0.6882\n",
      "Epoch 3474/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6899\n",
      "Epoch 3474: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6898\n",
      "Epoch 3475/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8299 - f1_score: 0.6884\n",
      "Epoch 3475: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8299 - f1_score: 0.6883\n",
      "Epoch 3476/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 3476: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3817 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 3477/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8311 - f1_score: 0.6888\n",
      "Epoch 3477: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3807 - accuracy: 0.8312 - f1_score: 0.6888\n",
      "Epoch 3478/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 3478: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 3479/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6890\n",
      "Epoch 3479: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6888\n",
      "Epoch 3480/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 3480: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6886\n",
      "Epoch 3481/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 3481: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6877\n",
      "Epoch 3482/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8304 - f1_score: 0.6876\n",
      "Epoch 3482: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8304 - f1_score: 0.6876\n",
      "Epoch 3483/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 3483: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 3484/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8309 - f1_score: 0.6885\n",
      "Epoch 3484: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8309 - f1_score: 0.6885\n",
      "Epoch 3485/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6881\n",
      "Epoch 3485: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6883\n",
      "Epoch 3486/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3486: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 3487/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8315 - f1_score: 0.6887\n",
      "Epoch 3487: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8315 - f1_score: 0.6887\n",
      "Epoch 3488/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8313 - f1_score: 0.6885\n",
      "Epoch 3488: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8313 - f1_score: 0.6885\n",
      "Epoch 3489/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6878\n",
      "Epoch 3489: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6880\n",
      "Epoch 3490/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 3490: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 3491/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 3491: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 3492/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8305 - f1_score: 0.6881\n",
      "Epoch 3492: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8304 - f1_score: 0.6881\n",
      "Epoch 3493/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8280 - f1_score: 0.6876\n",
      "Epoch 3493: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6874\n",
      "Epoch 3494/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6879\n",
      "Epoch 3494: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6878\n",
      "Epoch 3495/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8293 - f1_score: 0.6875\n",
      "Epoch 3495: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8294 - f1_score: 0.6874\n",
      "Epoch 3496/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6882\n",
      "Epoch 3496: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 3497/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 3497: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3805 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 3498/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8279 - f1_score: 0.6888\n",
      "Epoch 3498: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8279 - f1_score: 0.6885\n",
      "Epoch 3499/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 3499: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 3500/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 3500: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 3501/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 3501: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3841 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 3502/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 3502: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 3503/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6864\n",
      "Epoch 3503: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8293 - f1_score: 0.6865\n",
      "Epoch 3504/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8301 - f1_score: 0.6872\n",
      "Epoch 3504: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6873\n",
      "Epoch 3505/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 3505: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8297 - f1_score: 0.6883\n",
      "Epoch 3506/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8293 - f1_score: 0.6878\n",
      "Epoch 3506: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 3507/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8302 - f1_score: 0.6889\n",
      "Epoch 3507: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3805 - accuracy: 0.8301 - f1_score: 0.6889\n",
      "Epoch 3508/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 3508: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 3509/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8312 - f1_score: 0.6883\n",
      "Epoch 3509: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8312 - f1_score: 0.6884\n",
      "Epoch 3510/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8293 - f1_score: 0.6885\n",
      "Epoch 3510: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 3511/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 3511: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 3512/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 3512: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8295 - f1_score: 0.6889\n",
      "Epoch 3513/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 3513: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6880\n",
      "Epoch 3514/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8302 - f1_score: 0.6897\n",
      "Epoch 3514: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6896\n",
      "Epoch 3515/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6896\n",
      "Epoch 3515: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8294 - f1_score: 0.6895\n",
      "Epoch 3516/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8312 - f1_score: 0.6892\n",
      "Epoch 3516: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8310 - f1_score: 0.6891\n",
      "Epoch 3517/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 3517: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6889\n",
      "Epoch 3518/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6893\n",
      "Epoch 3518: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6893\n",
      "Epoch 3519/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8303 - f1_score: 0.6893\n",
      "Epoch 3519: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6893\n",
      "Epoch 3520/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6889\n",
      "Epoch 3520: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8296 - f1_score: 0.6890\n",
      "Epoch 3521/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8297 - f1_score: 0.6879\n",
      "Epoch 3521: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 3522/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6892\n",
      "Epoch 3522: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 3523/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 3523: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 3524/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 3524: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 3525/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8294 - f1_score: 0.6870\n",
      "Epoch 3525: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8295 - f1_score: 0.6871\n",
      "Epoch 3526/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 3526: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 3527/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8287 - f1_score: 0.6872\n",
      "Epoch 3527: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8287 - f1_score: 0.6872\n",
      "Epoch 3528/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 3528: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 3529/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6887\n",
      "Epoch 3529: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6886\n",
      "Epoch 3530/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 3530: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 3531/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8298 - f1_score: 0.6895\n",
      "Epoch 3531: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8299 - f1_score: 0.6893\n",
      "Epoch 3532/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 3532: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 3533/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 3533: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 3534/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8277 - f1_score: 0.6885\n",
      "Epoch 3534: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8277 - f1_score: 0.6885\n",
      "Epoch 3535/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 3535: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 3536/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8273 - f1_score: 0.6875\n",
      "Epoch 3536: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 3537/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8293 - f1_score: 0.6891\n",
      "Epoch 3537: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8293 - f1_score: 0.6888\n",
      "Epoch 3538/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8302 - f1_score: 0.6885\n",
      "Epoch 3538: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8302 - f1_score: 0.6884\n",
      "Epoch 3539/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 3539: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8289 - f1_score: 0.6884\n",
      "Epoch 3540/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6885\n",
      "Epoch 3540: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8308 - f1_score: 0.6885\n",
      "Epoch 3541/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 3541: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 3542/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 3542: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6892\n",
      "Epoch 3543/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 3543: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3843 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 3544/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 3544: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 3545/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8311 - f1_score: 0.6878\n",
      "Epoch 3545: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8309 - f1_score: 0.6878\n",
      "Epoch 3546/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 3546: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 3547/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8293 - f1_score: 0.6890\n",
      "Epoch 3547: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 3548/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 3548: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 3549/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6881\n",
      "Epoch 3549: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6881\n",
      "Epoch 3550/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 3550: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 3551/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 3551: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 3552/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 3552: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6884\n",
      "Epoch 3553/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 3553: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 3554/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6891\n",
      "Epoch 3554: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 3555/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8297 - f1_score: 0.6876\n",
      "Epoch 3555: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6877\n",
      "Epoch 3556/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 3556: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 3557/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8310 - f1_score: 0.6885\n",
      "Epoch 3557: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 3558/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6878\n",
      "Epoch 3558: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6879\n",
      "Epoch 3559/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8307 - f1_score: 0.6876\n",
      "Epoch 3559: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8307 - f1_score: 0.6876\n",
      "Epoch 3560/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6877\n",
      "Epoch 3560: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6876\n",
      "Epoch 3561/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8285 - f1_score: 0.6873\n",
      "Epoch 3561: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6871\n",
      "Epoch 3562/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6879\n",
      "Epoch 3562: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6879\n",
      "Epoch 3563/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8298 - f1_score: 0.6889\n",
      "Epoch 3563: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 3564/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 3564: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6885\n",
      "Epoch 3565/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8289 - f1_score: 0.6882\n",
      "Epoch 3565: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3823 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 3566/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 3566: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 3567/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 3567: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 3568/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6885\n",
      "Epoch 3568: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6885\n",
      "Epoch 3569/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6878\n",
      "Epoch 3569: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8279 - f1_score: 0.6876\n",
      "Epoch 3570/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 3570: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3844 - accuracy: 0.8274 - f1_score: 0.6882\n",
      "Epoch 3571/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6882\n",
      "Epoch 3571: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 3572/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 3572: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3801 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 3573/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 3573: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 3574/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6879\n",
      "Epoch 3574: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6879\n",
      "Epoch 3575/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8308 - f1_score: 0.6883\n",
      "Epoch 3575: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 3576/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8310 - f1_score: 0.6889\n",
      "Epoch 3576: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8309 - f1_score: 0.6888\n",
      "Epoch 3577/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6883\n",
      "Epoch 3577: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6883\n",
      "Epoch 3578/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 3578: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 3579/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8322 - f1_score: 0.6888\n",
      "Epoch 3579: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8321 - f1_score: 0.6888\n",
      "Epoch 3580/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6868\n",
      "Epoch 3580: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6869\n",
      "Epoch 3581/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6876\n",
      "Epoch 3581: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8302 - f1_score: 0.6878\n",
      "Epoch 3582/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 3582: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8286 - f1_score: 0.6882\n",
      "Epoch 3583/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 3583: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 3584/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 3584: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 3585/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6879\n",
      "Epoch 3585: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6880\n",
      "Epoch 3586/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 3586: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 3587/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 3587: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 3588/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8306 - f1_score: 0.6879\n",
      "Epoch 3588: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8306 - f1_score: 0.6879\n",
      "Epoch 3589/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6889\n",
      "Epoch 3589: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6889\n",
      "Epoch 3590/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6897\n",
      "Epoch 3590: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6895\n",
      "Epoch 3591/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 3591: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3794 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 3592/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8317 - f1_score: 0.6887\n",
      "Epoch 3592: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3799 - accuracy: 0.8317 - f1_score: 0.6887\n",
      "Epoch 3593/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8297 - f1_score: 0.6883\n",
      "Epoch 3593: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 3594/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8296 - f1_score: 0.6897\n",
      "Epoch 3594: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8296 - f1_score: 0.6898\n",
      "Epoch 3595/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 3595: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 3596/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8278 - f1_score: 0.6885\n",
      "Epoch 3596: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8278 - f1_score: 0.6885\n",
      "Epoch 3597/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8277 - f1_score: 0.6878\n",
      "Epoch 3597: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8277 - f1_score: 0.6877\n",
      "Epoch 3598/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 3598: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 3599/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8306 - f1_score: 0.6880\n",
      "Epoch 3599: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8305 - f1_score: 0.6880\n",
      "Epoch 3600/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8285 - f1_score: 0.6890\n",
      "Epoch 3600: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8287 - f1_score: 0.6889\n",
      "Epoch 3601/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8303 - f1_score: 0.6885\n",
      "Epoch 3601: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 3602/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8304 - f1_score: 0.6878\n",
      "Epoch 3602: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8305 - f1_score: 0.6877\n",
      "Epoch 3603/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6889\n",
      "Epoch 3603: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8295 - f1_score: 0.6889\n",
      "Epoch 3604/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 3604: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 3605/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8297 - f1_score: 0.6888\n",
      "Epoch 3605: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8297 - f1_score: 0.6889\n",
      "Epoch 3606/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 3606: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 3607/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 3607: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 3608/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 3608: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 3609/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 3609: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 3610/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6892\n",
      "Epoch 3610: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 3611/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 3611: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 3612/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 3612: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 3613/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 3613: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 3614/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8284 - f1_score: 0.6866\n",
      "Epoch 3614: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6866\n",
      "Epoch 3615/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8304 - f1_score: 0.6881\n",
      "Epoch 3615: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8303 - f1_score: 0.6881\n",
      "Epoch 3616/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8286 - f1_score: 0.6883\n",
      "Epoch 3616: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8286 - f1_score: 0.6883\n",
      "Epoch 3617/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 3617: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 3618/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8313 - f1_score: 0.6891\n",
      "Epoch 3618: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3796 - accuracy: 0.8313 - f1_score: 0.6891\n",
      "Epoch 3619/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 3619: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 3620/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6899\n",
      "Epoch 3620: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8312 - f1_score: 0.6897\n",
      "Epoch 3621/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6895\n",
      "Epoch 3621: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8295 - f1_score: 0.6894\n",
      "Epoch 3622/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 3622: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 3623/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8309 - f1_score: 0.6886\n",
      "Epoch 3623: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6886\n",
      "Epoch 3624/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8312 - f1_score: 0.6889\n",
      "Epoch 3624: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8312 - f1_score: 0.6891\n",
      "Epoch 3625/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8313 - f1_score: 0.6888\n",
      "Epoch 3625: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8313 - f1_score: 0.6888\n",
      "Epoch 3626/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8299 - f1_score: 0.6878\n",
      "Epoch 3626: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8299 - f1_score: 0.6879\n",
      "Epoch 3627/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6880\n",
      "Epoch 3627: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6880\n",
      "Epoch 3628/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 3628: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 3629/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 3629: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8312 - f1_score: 0.6886\n",
      "Epoch 3630/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 3630: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 3631/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 3631: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 3632/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8297 - f1_score: 0.6892\n",
      "Epoch 3632: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6892\n",
      "Epoch 3633/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6871\n",
      "Epoch 3633: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6871\n",
      "Epoch 3634/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8310 - f1_score: 0.6881\n",
      "Epoch 3634: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8311 - f1_score: 0.6881\n",
      "Epoch 3635/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6879\n",
      "Epoch 3635: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8301 - f1_score: 0.6878\n",
      "Epoch 3636/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 3636: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 3637/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6874\n",
      "Epoch 3637: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6874\n",
      "Epoch 3638/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8311 - f1_score: 0.6876\n",
      "Epoch 3638: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8310 - f1_score: 0.6874\n",
      "Epoch 3639/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8301 - f1_score: 0.6871\n",
      "Epoch 3639: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8301 - f1_score: 0.6870\n",
      "Epoch 3640/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6866\n",
      "Epoch 3640: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6866\n",
      "Epoch 3641/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 3641: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8295 - f1_score: 0.6881\n",
      "Epoch 3642/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 3642: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6881\n",
      "Epoch 3643/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 3643: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 3644/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8308 - f1_score: 0.6889\n",
      "Epoch 3644: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8308 - f1_score: 0.6888\n",
      "Epoch 3645/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 3645: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3808 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 3646/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8309 - f1_score: 0.6894\n",
      "Epoch 3646: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3792 - accuracy: 0.8309 - f1_score: 0.6894\n",
      "Epoch 3647/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 3647: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8295 - f1_score: 0.6885\n",
      "Epoch 3648/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6871\n",
      "Epoch 3648: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6872\n",
      "Epoch 3649/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 3649: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 3650/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8300 - f1_score: 0.6883\n",
      "Epoch 3650: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 3651/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8302 - f1_score: 0.6878\n",
      "Epoch 3651: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3811 - accuracy: 0.8303 - f1_score: 0.6878\n",
      "Epoch 3652/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8307 - f1_score: 0.6872\n",
      "Epoch 3652: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3816 - accuracy: 0.8308 - f1_score: 0.6872\n",
      "Epoch 3653/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8317 - f1_score: 0.6885\n",
      "Epoch 3653: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8317 - f1_score: 0.6885\n",
      "Epoch 3654/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8307 - f1_score: 0.6887\n",
      "Epoch 3654: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 3655/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8319 - f1_score: 0.6883\n",
      "Epoch 3655: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8319 - f1_score: 0.6883\n",
      "Epoch 3656/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8306 - f1_score: 0.6890\n",
      "Epoch 3656: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 3657/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8318 - f1_score: 0.6887\n",
      "Epoch 3657: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8318 - f1_score: 0.6887\n",
      "Epoch 3658/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8307 - f1_score: 0.6880\n",
      "Epoch 3658: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8306 - f1_score: 0.6879\n",
      "Epoch 3659/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8295 - f1_score: 0.6872\n",
      "Epoch 3659: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3838 - accuracy: 0.8295 - f1_score: 0.6872\n",
      "Epoch 3660/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8279 - f1_score: 0.6876\n",
      "Epoch 3660: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8279 - f1_score: 0.6876\n",
      "Epoch 3661/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3661: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3662/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 3662: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 3663/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 3663: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 3664/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 3664: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 3665/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 3665: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 3666/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8290 - f1_score: 0.6892\n",
      "Epoch 3666: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8290 - f1_score: 0.6890\n",
      "Epoch 3667/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6892\n",
      "Epoch 3667: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6890\n",
      "Epoch 3668/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8291 - f1_score: 0.6889\n",
      "Epoch 3668: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 3669/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 3669: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3798 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 3670/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 3670: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6886\n",
      "Epoch 3671/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.8311 - f1_score: 0.6894\n",
      "Epoch 3671: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8310 - f1_score: 0.6894\n",
      "Epoch 3672/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8283 - f1_score: 0.6888\n",
      "Epoch 3672: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8283 - f1_score: 0.6887\n",
      "Epoch 3673/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8310 - f1_score: 0.6891\n",
      "Epoch 3673: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8310 - f1_score: 0.6891\n",
      "Epoch 3674/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8286 - f1_score: 0.6893\n",
      "Epoch 3674: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8286 - f1_score: 0.6893\n",
      "Epoch 3675/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 3675: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 3676/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 3676: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6888\n",
      "Epoch 3677/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6880\n",
      "Epoch 3677: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8302 - f1_score: 0.6878\n",
      "Epoch 3678/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8285 - f1_score: 0.6881\n",
      "Epoch 3678: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6881\n",
      "Epoch 3679/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 3679: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3680/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6873\n",
      "Epoch 3680: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6873\n",
      "Epoch 3681/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6870\n",
      "Epoch 3681: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6870\n",
      "Epoch 3682/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8279 - f1_score: 0.6870\n",
      "Epoch 3682: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8280 - f1_score: 0.6871\n",
      "Epoch 3683/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 3683: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 3684/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8296 - f1_score: 0.6888\n",
      "Epoch 3684: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6888\n",
      "Epoch 3685/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8303 - f1_score: 0.6892\n",
      "Epoch 3685: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 3686/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 3686: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 3687/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3687: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3688/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 3688: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6877\n",
      "Epoch 3689/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 3689: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8303 - f1_score: 0.6891\n",
      "Epoch 3690/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8308 - f1_score: 0.6882\n",
      "Epoch 3690: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6885\n",
      "Epoch 3691/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6894\n",
      "Epoch 3691: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8312 - f1_score: 0.6894\n",
      "Epoch 3692/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8323 - f1_score: 0.6886\n",
      "Epoch 3692: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8322 - f1_score: 0.6888\n",
      "Epoch 3693/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8314 - f1_score: 0.6895\n",
      "Epoch 3693: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3782 - accuracy: 0.8314 - f1_score: 0.6897\n",
      "Epoch 3694/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8296 - f1_score: 0.6891\n",
      "Epoch 3694: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8296 - f1_score: 0.6891\n",
      "Epoch 3695/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6898\n",
      "Epoch 3695: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8302 - f1_score: 0.6899\n",
      "Epoch 3696/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6888\n",
      "Epoch 3696: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6888\n",
      "Epoch 3697/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 3697: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 3698/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8315 - f1_score: 0.6880\n",
      "Epoch 3698: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8315 - f1_score: 0.6880\n",
      "Epoch 3699/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 3699: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8303 - f1_score: 0.6885\n",
      "Epoch 3700/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8306 - f1_score: 0.6883\n",
      "Epoch 3700: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8306 - f1_score: 0.6883\n",
      "Epoch 3701/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 3701: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 3702/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 3702: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3812 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 3703/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8287 - f1_score: 0.6876\n",
      "Epoch 3703: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8288 - f1_score: 0.6876\n",
      "Epoch 3704/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 3704: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6880\n",
      "Epoch 3705/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8301 - f1_score: 0.6889\n",
      "Epoch 3705: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 3706/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 3706: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 3707/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8306 - f1_score: 0.6898\n",
      "Epoch 3707: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8306 - f1_score: 0.6897\n",
      "Epoch 3708/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 3708: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 3709/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6893\n",
      "Epoch 3709: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6895\n",
      "Epoch 3710/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 3710: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 3711/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8287 - f1_score: 0.6887\n",
      "Epoch 3711: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 3712/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8319 - f1_score: 0.6897\n",
      "Epoch 3712: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8321 - f1_score: 0.6897\n",
      "Epoch 3713/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8308 - f1_score: 0.6889\n",
      "Epoch 3713: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 3714/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6878\n",
      "Epoch 3714: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8312 - f1_score: 0.6878\n",
      "Epoch 3715/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6879\n",
      "Epoch 3715: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 3716/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 3716: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 3717/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 3717: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8298 - f1_score: 0.6890\n",
      "Epoch 3718/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8303 - f1_score: 0.6894\n",
      "Epoch 3718: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8304 - f1_score: 0.6894\n",
      "Epoch 3719/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 3719: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 3720/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6877\n",
      "Epoch 3720: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6877\n",
      "Epoch 3721/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 3721: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8293 - f1_score: 0.6890\n",
      "Epoch 3722/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8269 - f1_score: 0.6871\n",
      "Epoch 3722: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3862 - accuracy: 0.8270 - f1_score: 0.6872\n",
      "Epoch 3723/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8299 - f1_score: 0.6890\n",
      "Epoch 3723: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8298 - f1_score: 0.6890\n",
      "Epoch 3724/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8316 - f1_score: 0.6881\n",
      "Epoch 3724: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8315 - f1_score: 0.6881\n",
      "Epoch 3725/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8312 - f1_score: 0.6891\n",
      "Epoch 3725: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6890\n",
      "Epoch 3726/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8311 - f1_score: 0.6881\n",
      "Epoch 3726: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8311 - f1_score: 0.6881\n",
      "Epoch 3727/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6886\n",
      "Epoch 3727: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8302 - f1_score: 0.6885\n",
      "Epoch 3728/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 3728: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 3729/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8309 - f1_score: 0.6893\n",
      "Epoch 3729: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8310 - f1_score: 0.6894\n",
      "Epoch 3730/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8303 - f1_score: 0.6891\n",
      "Epoch 3730: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 3731/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 3731: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6872\n",
      "Epoch 3732/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3732: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3733/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 3733: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 3734/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8285 - f1_score: 0.6884\n",
      "Epoch 3734: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8285 - f1_score: 0.6886\n",
      "Epoch 3735/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 3735: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6883\n",
      "Epoch 3736/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8312 - f1_score: 0.6887\n",
      "Epoch 3736: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8312 - f1_score: 0.6887\n",
      "Epoch 3737/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6873\n",
      "Epoch 3737: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6873\n",
      "Epoch 3738/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8304 - f1_score: 0.6895\n",
      "Epoch 3738: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8303 - f1_score: 0.6894\n",
      "Epoch 3739/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8290 - f1_score: 0.6883\n",
      "Epoch 3739: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 3740/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8295 - f1_score: 0.6875\n",
      "Epoch 3740: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 3741/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6881\n",
      "Epoch 3741: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8315 - f1_score: 0.6881\n",
      "Epoch 3742/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6894\n",
      "Epoch 3742: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6894\n",
      "Epoch 3743/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 3743: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 3744/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8309 - f1_score: 0.6893\n",
      "Epoch 3744: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8310 - f1_score: 0.6893\n",
      "Epoch 3745/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8315 - f1_score: 0.6888\n",
      "Epoch 3745: accuracy did not improve from 0.83224\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3791 - accuracy: 0.8315 - f1_score: 0.6888\n",
      "Epoch 3746/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.8328 - f1_score: 0.6892\n",
      "Epoch 3746: accuracy improved from 0.83224 to 0.83287, saving model to ./625-batch_size625\\weight-improvement2-3746-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3769 - accuracy: 0.8329 - f1_score: 0.6891\n",
      "Epoch 3747/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8325 - f1_score: 0.6886\n",
      "Epoch 3747: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3791 - accuracy: 0.8326 - f1_score: 0.6887\n",
      "Epoch 3748/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8297 - f1_score: 0.6893\n",
      "Epoch 3748: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6893\n",
      "Epoch 3749/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 3749: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3750/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 3750: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 3751/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 3751: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 3752/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6871\n",
      "Epoch 3752: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6872\n",
      "Epoch 3753/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8314 - f1_score: 0.6874\n",
      "Epoch 3753: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8314 - f1_score: 0.6874\n",
      "Epoch 3754/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8299 - f1_score: 0.6883\n",
      "Epoch 3754: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6883\n",
      "Epoch 3755/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8315 - f1_score: 0.6882\n",
      "Epoch 3755: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8314 - f1_score: 0.6883\n",
      "Epoch 3756/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8317 - f1_score: 0.6884\n",
      "Epoch 3756: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8318 - f1_score: 0.6884\n",
      "Epoch 3757/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6891\n",
      "Epoch 3757: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 3758/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8268 - f1_score: 0.6870\n",
      "Epoch 3758: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3862 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 3759/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6873\n",
      "Epoch 3759: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8287 - f1_score: 0.6874\n",
      "Epoch 3760/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8318 - f1_score: 0.6887\n",
      "Epoch 3760: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3789 - accuracy: 0.8318 - f1_score: 0.6887\n",
      "Epoch 3761/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 3761: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3874 - accuracy: 0.8267 - f1_score: 0.6870\n",
      "Epoch 3762/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6881\n",
      "Epoch 3762: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6881\n",
      "Epoch 3763/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8314 - f1_score: 0.6892\n",
      "Epoch 3763: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8314 - f1_score: 0.6892\n",
      "Epoch 3764/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 3764: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 3765/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8307 - f1_score: 0.6895\n",
      "Epoch 3765: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8307 - f1_score: 0.6894\n",
      "Epoch 3766/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8309 - f1_score: 0.6879\n",
      "Epoch 3766: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8309 - f1_score: 0.6878\n",
      "Epoch 3767/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8312 - f1_score: 0.6884\n",
      "Epoch 3767: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8312 - f1_score: 0.6884\n",
      "Epoch 3768/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8307 - f1_score: 0.6882\n",
      "Epoch 3768: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8307 - f1_score: 0.6882\n",
      "Epoch 3769/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 3769: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 3770/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8308 - f1_score: 0.6876\n",
      "Epoch 3770: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8309 - f1_score: 0.6876\n",
      "Epoch 3771/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 3771: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 3772/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8317 - f1_score: 0.6893\n",
      "Epoch 3772: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8317 - f1_score: 0.6893\n",
      "Epoch 3773/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 3773: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 3774/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 3774: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6895\n",
      "Epoch 3775/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6889\n",
      "Epoch 3775: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6890\n",
      "Epoch 3776/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8319 - f1_score: 0.6893\n",
      "Epoch 3776: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8317 - f1_score: 0.6892\n",
      "Epoch 3777/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8317 - f1_score: 0.6886\n",
      "Epoch 3777: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3791 - accuracy: 0.8318 - f1_score: 0.6887\n",
      "Epoch 3778/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8306 - f1_score: 0.6878\n",
      "Epoch 3778: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8305 - f1_score: 0.6878\n",
      "Epoch 3779/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6891\n",
      "Epoch 3779: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 3780/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8309 - f1_score: 0.6876\n",
      "Epoch 3780: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8309 - f1_score: 0.6876\n",
      "Epoch 3781/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8309 - f1_score: 0.6883\n",
      "Epoch 3781: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6883\n",
      "Epoch 3782/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8317 - f1_score: 0.6891\n",
      "Epoch 3782: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8317 - f1_score: 0.6891\n",
      "Epoch 3783/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8310 - f1_score: 0.6892\n",
      "Epoch 3783: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8311 - f1_score: 0.6892\n",
      "Epoch 3784/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8317 - f1_score: 0.6884\n",
      "Epoch 3784: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8317 - f1_score: 0.6884\n",
      "Epoch 3785/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8314 - f1_score: 0.6876\n",
      "Epoch 3785: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8315 - f1_score: 0.6876\n",
      "Epoch 3786/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8316 - f1_score: 0.6884\n",
      "Epoch 3786: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8316 - f1_score: 0.6885\n",
      "Epoch 3787/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 3787: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6881\n",
      "Epoch 3788/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8306 - f1_score: 0.6879\n",
      "Epoch 3788: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8306 - f1_score: 0.6877\n",
      "Epoch 3789/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8321 - f1_score: 0.6877\n",
      "Epoch 3789: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8322 - f1_score: 0.6878\n",
      "Epoch 3790/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8317 - f1_score: 0.6893\n",
      "Epoch 3790: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8318 - f1_score: 0.6894\n",
      "Epoch 3791/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 3791: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 3792/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8308 - f1_score: 0.6882\n",
      "Epoch 3792: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 3793/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8320 - f1_score: 0.6889\n",
      "Epoch 3793: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8320 - f1_score: 0.6888\n",
      "Epoch 3794/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8289 - f1_score: 0.6885\n",
      "Epoch 3794: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 3795/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 3795: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 3796/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8306 - f1_score: 0.6891\n",
      "Epoch 3796: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3818 - accuracy: 0.8305 - f1_score: 0.6890\n",
      "Epoch 3797/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8308 - f1_score: 0.6893\n",
      "Epoch 3797: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8307 - f1_score: 0.6893\n",
      "Epoch 3798/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6898\n",
      "Epoch 3798: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6898\n",
      "Epoch 3799/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6891\n",
      "Epoch 3799: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 3800/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 3800: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 3801/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8311 - f1_score: 0.6894\n",
      "Epoch 3801: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8312 - f1_score: 0.6894\n",
      "Epoch 3802/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 3802: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 3803/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 3803: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 3804/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8305 - f1_score: 0.6894\n",
      "Epoch 3804: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6895\n",
      "Epoch 3805/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8307 - f1_score: 0.6891\n",
      "Epoch 3805: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6890\n",
      "Epoch 3806/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 3806: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 3807/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8287 - f1_score: 0.6889\n",
      "Epoch 3807: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8287 - f1_score: 0.6889\n",
      "Epoch 3808/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8314 - f1_score: 0.6881\n",
      "Epoch 3808: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8314 - f1_score: 0.6881\n",
      "Epoch 3809/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8301 - f1_score: 0.6870\n",
      "Epoch 3809: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6871\n",
      "Epoch 3810/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8307 - f1_score: 0.6877\n",
      "Epoch 3810: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8308 - f1_score: 0.6877\n",
      "Epoch 3811/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 3811: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 3812/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8316 - f1_score: 0.6890\n",
      "Epoch 3812: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8316 - f1_score: 0.6892\n",
      "Epoch 3813/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8317 - f1_score: 0.6890\n",
      "Epoch 3813: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8318 - f1_score: 0.6890\n",
      "Epoch 3814/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8310 - f1_score: 0.6894\n",
      "Epoch 3814: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8311 - f1_score: 0.6894\n",
      "Epoch 3815/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8327 - f1_score: 0.6891\n",
      "Epoch 3815: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3782 - accuracy: 0.8327 - f1_score: 0.6891\n",
      "Epoch 3816/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6888\n",
      "Epoch 3816: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6888\n",
      "Epoch 3817/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8311 - f1_score: 0.6896\n",
      "Epoch 3817: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8311 - f1_score: 0.6896\n",
      "Epoch 3818/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 3818: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6881\n",
      "Epoch 3819/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8301 - f1_score: 0.6881\n",
      "Epoch 3819: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8300 - f1_score: 0.6881\n",
      "Epoch 3820/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8316 - f1_score: 0.6893\n",
      "Epoch 3820: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8315 - f1_score: 0.6894\n",
      "Epoch 3821/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 3821: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8310 - f1_score: 0.6886\n",
      "Epoch 3822/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8303 - f1_score: 0.6880\n",
      "Epoch 3822: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8303 - f1_score: 0.6880\n",
      "Epoch 3823/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6889\n",
      "Epoch 3823: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 3824/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3825 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 3824: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 3825/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8302 - f1_score: 0.6890\n",
      "Epoch 3825: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 3826/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 3826: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8313 - f1_score: 0.6890\n",
      "Epoch 3827/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3827: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 3828/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8293 - f1_score: 0.6878\n",
      "Epoch 3828: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8294 - f1_score: 0.6877\n",
      "Epoch 3829/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8311 - f1_score: 0.6894\n",
      "Epoch 3829: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6893\n",
      "Epoch 3830/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 3830: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 3831/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 3831: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8289 - f1_score: 0.6879\n",
      "Epoch 3832/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8300 - f1_score: 0.6884\n",
      "Epoch 3832: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8302 - f1_score: 0.6884\n",
      "Epoch 3833/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8310 - f1_score: 0.6890\n",
      "Epoch 3833: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6888\n",
      "Epoch 3834/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8279 - f1_score: 0.6870\n",
      "Epoch 3834: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8280 - f1_score: 0.6870\n",
      "Epoch 3835/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8298 - f1_score: 0.6874\n",
      "Epoch 3835: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8297 - f1_score: 0.6874\n",
      "Epoch 3836/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 3836: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 3837/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 3837: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 3838/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8313 - f1_score: 0.6883\n",
      "Epoch 3838: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8313 - f1_score: 0.6882\n",
      "Epoch 3839/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6887\n",
      "Epoch 3839: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6887\n",
      "Epoch 3840/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8315 - f1_score: 0.6893\n",
      "Epoch 3840: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3785 - accuracy: 0.8315 - f1_score: 0.6893\n",
      "Epoch 3841/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8312 - f1_score: 0.6890\n",
      "Epoch 3841: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8312 - f1_score: 0.6890\n",
      "Epoch 3842/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 3842: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 3843/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 3843: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 3844/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6880\n",
      "Epoch 3844: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 3845/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 3845: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6891\n",
      "Epoch 3846/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 3846: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8299 - f1_score: 0.6879\n",
      "Epoch 3847/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8286 - f1_score: 0.6877\n",
      "Epoch 3847: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6876\n",
      "Epoch 3848/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6869\n",
      "Epoch 3848: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8296 - f1_score: 0.6869\n",
      "Epoch 3849/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8291 - f1_score: 0.6876\n",
      "Epoch 3849: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8291 - f1_score: 0.6876\n",
      "Epoch 3850/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 3850: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3851 - accuracy: 0.8280 - f1_score: 0.6873\n",
      "Epoch 3851/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8289 - f1_score: 0.6878\n",
      "Epoch 3851: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 3852/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6880\n",
      "Epoch 3852: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8300 - f1_score: 0.6880\n",
      "Epoch 3853/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 3853: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 3854/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8313 - f1_score: 0.6884\n",
      "Epoch 3854: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3806 - accuracy: 0.8313 - f1_score: 0.6884\n",
      "Epoch 3855/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 3855: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3825 - accuracy: 0.8285 - f1_score: 0.6882\n",
      "Epoch 3856/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8301 - f1_score: 0.6878\n",
      "Epoch 3856: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6877\n",
      "Epoch 3857/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6890\n",
      "Epoch 3857: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 3858/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8301 - f1_score: 0.6895\n",
      "Epoch 3858: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6895\n",
      "Epoch 3859/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 3859: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6872\n",
      "Epoch 3860/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8296 - f1_score: 0.6882\n",
      "Epoch 3860: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 3861/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6873\n",
      "Epoch 3861: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6874\n",
      "Epoch 3862/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 3862: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 3863/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6878\n",
      "Epoch 3863: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6878\n",
      "Epoch 3864/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6878\n",
      "Epoch 3864: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8311 - f1_score: 0.6878\n",
      "Epoch 3865/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8294 - f1_score: 0.6874\n",
      "Epoch 3865: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3836 - accuracy: 0.8294 - f1_score: 0.6876\n",
      "Epoch 3866/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 3866: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 3867/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 3867: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6882\n",
      "Epoch 3868/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 3868: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 3869/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8308 - f1_score: 0.6878\n",
      "Epoch 3869: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8308 - f1_score: 0.6877\n",
      "Epoch 3870/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.8316 - f1_score: 0.6891\n",
      "Epoch 3870: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8316 - f1_score: 0.6891\n",
      "Epoch 3871/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 3871: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 3872/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8323 - f1_score: 0.6881\n",
      "Epoch 3872: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8323 - f1_score: 0.6881\n",
      "Epoch 3873/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8328 - f1_score: 0.6886\n",
      "Epoch 3873: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8328 - f1_score: 0.6886\n",
      "Epoch 3874/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8318 - f1_score: 0.6889\n",
      "Epoch 3874: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8318 - f1_score: 0.6888\n",
      "Epoch 3875/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 3875: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8286 - f1_score: 0.6879\n",
      "Epoch 3876/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 3876: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 3877/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6881\n",
      "Epoch 3877: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8294 - f1_score: 0.6881\n",
      "Epoch 3878/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6891\n",
      "Epoch 3878: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8314 - f1_score: 0.6890\n",
      "Epoch 3879/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3879: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 3880/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 3880: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 3881/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 3881: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 3882/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 3882: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 3883/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8305 - f1_score: 0.6900\n",
      "Epoch 3883: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8305 - f1_score: 0.6900\n",
      "Epoch 3884/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 3884: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 3885/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 3885: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 3886/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6883\n",
      "Epoch 3886: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 3887/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6880\n",
      "Epoch 3887: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6880\n",
      "Epoch 3888/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8295 - f1_score: 0.6874\n",
      "Epoch 3888: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6875\n",
      "Epoch 3889/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 3889: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 3890/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6897\n",
      "Epoch 3890: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6897\n",
      "Epoch 3891/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 3891: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 3892/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 3892: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 3893/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 3893: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8303 - f1_score: 0.6893\n",
      "Epoch 3894/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6889\n",
      "Epoch 3894: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 3895/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 3895: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 3896/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 3896: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 3897/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8283 - f1_score: 0.6888\n",
      "Epoch 3897: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8283 - f1_score: 0.6888\n",
      "Epoch 3898/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 3898: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8288 - f1_score: 0.6879\n",
      "Epoch 3899/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 3899: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 3900/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 3900: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 3901/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 3901: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6881\n",
      "Epoch 3902/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 3902: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3840 - accuracy: 0.8283 - f1_score: 0.6886\n",
      "Epoch 3903/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 3903: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 3904/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8320 - f1_score: 0.6887\n",
      "Epoch 3904: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3794 - accuracy: 0.8320 - f1_score: 0.6887\n",
      "Epoch 3905/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8317 - f1_score: 0.6896\n",
      "Epoch 3905: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3791 - accuracy: 0.8317 - f1_score: 0.6897\n",
      "Epoch 3906/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8307 - f1_score: 0.6876\n",
      "Epoch 3906: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8308 - f1_score: 0.6878\n",
      "Epoch 3907/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8319 - f1_score: 0.6879\n",
      "Epoch 3907: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8319 - f1_score: 0.6879\n",
      "Epoch 3908/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8305 - f1_score: 0.6881\n",
      "Epoch 3908: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8305 - f1_score: 0.6882\n",
      "Epoch 3909/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8304 - f1_score: 0.6876\n",
      "Epoch 3909: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8304 - f1_score: 0.6876\n",
      "Epoch 3910/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 3910: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8281 - f1_score: 0.6879\n",
      "Epoch 3911/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8309 - f1_score: 0.6879\n",
      "Epoch 3911: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8309 - f1_score: 0.6880\n",
      "Epoch 3912/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8306 - f1_score: 0.6886\n",
      "Epoch 3912: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6886\n",
      "Epoch 3913/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8312 - f1_score: 0.6893\n",
      "Epoch 3913: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6894\n",
      "Epoch 3914/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 3914: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8311 - f1_score: 0.6899\n",
      "Epoch 3915/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3915: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 3916/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 3916: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 3917/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6884\n",
      "Epoch 3917: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 3918/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6892\n",
      "Epoch 3918: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3805 - accuracy: 0.8300 - f1_score: 0.6892\n",
      "Epoch 3919/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6892\n",
      "Epoch 3919: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8307 - f1_score: 0.6893\n",
      "Epoch 3920/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8316 - f1_score: 0.6888\n",
      "Epoch 3920: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3792 - accuracy: 0.8317 - f1_score: 0.6888\n",
      "Epoch 3921/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 3921: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 3922/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8313 - f1_score: 0.6885\n",
      "Epoch 3922: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8312 - f1_score: 0.6885\n",
      "Epoch 3923/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8313 - f1_score: 0.6900\n",
      "Epoch 3923: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3782 - accuracy: 0.8313 - f1_score: 0.6899\n",
      "Epoch 3924/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 3924: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8308 - f1_score: 0.6888\n",
      "Epoch 3925/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8286 - f1_score: 0.6877\n",
      "Epoch 3925: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3831 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 3926/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 3926: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3840 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 3927/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 3927: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 3928/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8291 - f1_score: 0.6893\n",
      "Epoch 3928: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8291 - f1_score: 0.6892\n",
      "Epoch 3929/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6885\n",
      "Epoch 3929: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6885\n",
      "Epoch 3930/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 3930: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 3931/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 3931: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3830 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 3932/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 3932: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6884\n",
      "Epoch 3933/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 3933: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 3934/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8298 - f1_score: 0.6876\n",
      "Epoch 3934: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8299 - f1_score: 0.6877\n",
      "Epoch 3935/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 3935: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8296 - f1_score: 0.6878\n",
      "Epoch 3936/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 3936: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 3937/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8312 - f1_score: 0.6883\n",
      "Epoch 3937: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8312 - f1_score: 0.6884\n",
      "Epoch 3938/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3938: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3939/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8294 - f1_score: 0.6881\n",
      "Epoch 3939: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8294 - f1_score: 0.6881\n",
      "Epoch 3940/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 3940: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 3941/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 3941: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 3942/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8271 - f1_score: 0.6880\n",
      "Epoch 3942: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8272 - f1_score: 0.6880\n",
      "Epoch 3943/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8300 - f1_score: 0.6879\n",
      "Epoch 3943: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8300 - f1_score: 0.6878\n",
      "Epoch 3944/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 3944: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8285 - f1_score: 0.6880\n",
      "Epoch 3945/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8298 - f1_score: 0.6875\n",
      "Epoch 3945: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6875\n",
      "Epoch 3946/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8296 - f1_score: 0.6874\n",
      "Epoch 3946: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3835 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 3947/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6873\n",
      "Epoch 3947: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6872\n",
      "Epoch 3948/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 3948: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 3949/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 3949: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6883\n",
      "Epoch 3950/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 3950: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6882\n",
      "Epoch 3951/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 3951: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6876\n",
      "Epoch 3952/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6875\n",
      "Epoch 3952: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 3953/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 3953: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6886\n",
      "Epoch 3954/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8309 - f1_score: 0.6885\n",
      "Epoch 3954: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 3955/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8297 - f1_score: 0.6890\n",
      "Epoch 3955: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 3956/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8300 - f1_score: 0.6877\n",
      "Epoch 3956: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8300 - f1_score: 0.6877\n",
      "Epoch 3957/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6876\n",
      "Epoch 3957: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6876\n",
      "Epoch 3958/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 3958: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 3959/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8289 - f1_score: 0.6869\n",
      "Epoch 3959: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8290 - f1_score: 0.6869\n",
      "Epoch 3960/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8307 - f1_score: 0.6865\n",
      "Epoch 3960: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8306 - f1_score: 0.6864\n",
      "Epoch 3961/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 3961: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 3962/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 3962: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6876\n",
      "Epoch 3963/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8275 - f1_score: 0.6870\n",
      "Epoch 3963: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8274 - f1_score: 0.6870\n",
      "Epoch 3964/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 3964: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 3965/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8312 - f1_score: 0.6887\n",
      "Epoch 3965: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8312 - f1_score: 0.6887\n",
      "Epoch 3966/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 3966: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3785 - accuracy: 0.8312 - f1_score: 0.6890\n",
      "Epoch 3967/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8322 - f1_score: 0.6895\n",
      "Epoch 3967: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3781 - accuracy: 0.8322 - f1_score: 0.6896\n",
      "Epoch 3968/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 3968: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8306 - f1_score: 0.6894\n",
      "Epoch 3969/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 3969: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 3970/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 3970: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 3971/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 3971: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 3972/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 3972: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 3973/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8292 - f1_score: 0.6876\n",
      "Epoch 3973: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8291 - f1_score: 0.6876\n",
      "Epoch 3974/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8298 - f1_score: 0.6878\n",
      "Epoch 3974: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 3975/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8297 - f1_score: 0.6890\n",
      "Epoch 3975: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 3976/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6892\n",
      "Epoch 3976: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6893\n",
      "Epoch 3977/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8313 - f1_score: 0.6892\n",
      "Epoch 3977: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3787 - accuracy: 0.8313 - f1_score: 0.6893\n",
      "Epoch 3978/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6900\n",
      "Epoch 3978: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6900\n",
      "Epoch 3979/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 3979: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8301 - f1_score: 0.6892\n",
      "Epoch 3980/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8265 - f1_score: 0.6881\n",
      "Epoch 3980: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3864 - accuracy: 0.8265 - f1_score: 0.6881\n",
      "Epoch 3981/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6886\n",
      "Epoch 3981: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8279 - f1_score: 0.6887\n",
      "Epoch 3982/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 3982: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 3983/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 3983: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 3984/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3984: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6880\n",
      "Epoch 3985/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8306 - f1_score: 0.6896\n",
      "Epoch 3985: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8306 - f1_score: 0.6896\n",
      "Epoch 3986/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8312 - f1_score: 0.6897\n",
      "Epoch 3986: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3785 - accuracy: 0.8313 - f1_score: 0.6897\n",
      "Epoch 3987/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8318 - f1_score: 0.6890\n",
      "Epoch 3987: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8318 - f1_score: 0.6892\n",
      "Epoch 3988/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8312 - f1_score: 0.6894\n",
      "Epoch 3988: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8312 - f1_score: 0.6895\n",
      "Epoch 3989/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 3989: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 3990/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 3990: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 3991/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8292 - f1_score: 0.6897\n",
      "Epoch 3991: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8292 - f1_score: 0.6897\n",
      "Epoch 3992/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 3992: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 3993/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 3993: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 3994/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 3994: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 3995/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 3995: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 3996/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8306 - f1_score: 0.6878\n",
      "Epoch 3996: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8307 - f1_score: 0.6877\n",
      "Epoch 3997/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6883\n",
      "Epoch 3997: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 3998/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 3998: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 3999/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 3999: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 4000/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8302 - f1_score: 0.6890\n",
      "Epoch 4000: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.8302 - f1_score: 0.6890\n",
      "Epoch 4001/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 4001: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3837 - accuracy: 0.8282 - f1_score: 0.6887\n",
      "Epoch 4002/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6896\n",
      "Epoch 4002: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8297 - f1_score: 0.6896\n",
      "Epoch 4003/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8294 - f1_score: 0.6891\n",
      "Epoch 4003: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 4004/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8310 - f1_score: 0.6886\n",
      "Epoch 4004: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 4005/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 4005: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 4006/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8284 - f1_score: 0.6875\n",
      "Epoch 4006: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8285 - f1_score: 0.6876\n",
      "Epoch 4007/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8279 - f1_score: 0.6881\n",
      "Epoch 4007: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 4008/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 4008: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 4009/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 4009: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 4010/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8290 - f1_score: 0.6890\n",
      "Epoch 4010: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8289 - f1_score: 0.6890\n",
      "Epoch 4011/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8313 - f1_score: 0.6893\n",
      "Epoch 4011: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8312 - f1_score: 0.6893\n",
      "Epoch 4012/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6892\n",
      "Epoch 4012: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 4013/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8310 - f1_score: 0.6893\n",
      "Epoch 4013: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4014/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8312 - f1_score: 0.6897\n",
      "Epoch 4014: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3801 - accuracy: 0.8312 - f1_score: 0.6898\n",
      "Epoch 4015/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8288 - f1_score: 0.6878\n",
      "Epoch 4015: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6877\n",
      "Epoch 4016/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 4016: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 4017/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8310 - f1_score: 0.6885\n",
      "Epoch 4017: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8310 - f1_score: 0.6885\n",
      "Epoch 4018/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4018: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 4019/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8287 - f1_score: 0.6892\n",
      "Epoch 4019: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3820 - accuracy: 0.8287 - f1_score: 0.6892\n",
      "Epoch 4020/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 4020: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 4021/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6889\n",
      "Epoch 4021: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8292 - f1_score: 0.6890\n",
      "Epoch 4022/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 4022: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8306 - f1_score: 0.6883\n",
      "Epoch 4023/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 4023: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6881\n",
      "Epoch 4024/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8303 - f1_score: 0.6876\n",
      "Epoch 4024: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6876\n",
      "Epoch 4025/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 4025: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3828 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 4026/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8293 - f1_score: 0.6873\n",
      "Epoch 4026: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8293 - f1_score: 0.6873\n",
      "Epoch 4027/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8302 - f1_score: 0.6872\n",
      "Epoch 4027: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6874\n",
      "Epoch 4028/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8304 - f1_score: 0.6869\n",
      "Epoch 4028: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8304 - f1_score: 0.6870\n",
      "Epoch 4029/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8290 - f1_score: 0.6894\n",
      "Epoch 4029: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8291 - f1_score: 0.6893\n",
      "Epoch 4030/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 4030: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6888\n",
      "Epoch 4031/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6877\n",
      "Epoch 4031: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8293 - f1_score: 0.6880\n",
      "Epoch 4032/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6882\n",
      "Epoch 4032: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6882\n",
      "Epoch 4033/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8292 - f1_score: 0.6877\n",
      "Epoch 4033: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 4034/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8265 - f1_score: 0.6880\n",
      "Epoch 4034: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8265 - f1_score: 0.6881\n",
      "Epoch 4035/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8285 - f1_score: 0.6885\n",
      "Epoch 4035: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8283 - f1_score: 0.6885\n",
      "Epoch 4036/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 4036: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 4037/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 4037: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 4038/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6875\n",
      "Epoch 4038: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8286 - f1_score: 0.6877\n",
      "Epoch 4039/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 4039: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8296 - f1_score: 0.6891\n",
      "Epoch 4040/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8304 - f1_score: 0.6894\n",
      "Epoch 4040: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3809 - accuracy: 0.8304 - f1_score: 0.6893\n",
      "Epoch 4041/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8307 - f1_score: 0.6896\n",
      "Epoch 4041: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8308 - f1_score: 0.6896\n",
      "Epoch 4042/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 4042: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 4043/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8313 - f1_score: 0.6890\n",
      "Epoch 4043: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8313 - f1_score: 0.6890\n",
      "Epoch 4044/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6889\n",
      "Epoch 4044: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 4045/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8282 - f1_score: 0.6887\n",
      "Epoch 4045: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8281 - f1_score: 0.6887\n",
      "Epoch 4046/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 4046: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 4047/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6878\n",
      "Epoch 4047: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8307 - f1_score: 0.6880\n",
      "Epoch 4048/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 4048: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 4049/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 4049: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 4050/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 4050: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 4051/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8277 - f1_score: 0.6876\n",
      "Epoch 4051: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3865 - accuracy: 0.8276 - f1_score: 0.6875\n",
      "Epoch 4052/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 4052: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6879\n",
      "Epoch 4053/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8294 - f1_score: 0.6876\n",
      "Epoch 4053: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8294 - f1_score: 0.6876\n",
      "Epoch 4054/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8323 - f1_score: 0.6892\n",
      "Epoch 4054: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8321 - f1_score: 0.6893\n",
      "Epoch 4055/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 4055: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 4056/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 4056: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8305 - f1_score: 0.6886\n",
      "Epoch 4057/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4057: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4058/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6888\n",
      "Epoch 4058: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8296 - f1_score: 0.6888\n",
      "Epoch 4059/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8297 - f1_score: 0.6877\n",
      "Epoch 4059: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8298 - f1_score: 0.6877\n",
      "Epoch 4060/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 4060: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 4061/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 4061: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8287 - f1_score: 0.6877\n",
      "Epoch 4062/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 4062: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 4063/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8310 - f1_score: 0.6884\n",
      "Epoch 4063: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8310 - f1_score: 0.6884\n",
      "Epoch 4064/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 4064: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3813 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 4065/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8271 - f1_score: 0.6876\n",
      "Epoch 4065: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3855 - accuracy: 0.8272 - f1_score: 0.6876\n",
      "Epoch 4066/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 4066: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8281 - f1_score: 0.6872\n",
      "Epoch 4067/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 4067: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 4068/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8300 - f1_score: 0.6894\n",
      "Epoch 4068: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8300 - f1_score: 0.6894\n",
      "Epoch 4069/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 4069: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6889\n",
      "Epoch 4070/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8295 - f1_score: 0.6881\n",
      "Epoch 4070: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8296 - f1_score: 0.6882\n",
      "Epoch 4071/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 4071: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 4072/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 4072: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3808 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4073/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 4073: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8275 - f1_score: 0.6876\n",
      "Epoch 4074/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6881\n",
      "Epoch 4074: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 4075/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6881\n",
      "Epoch 4075: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6880\n",
      "Epoch 4076/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6871\n",
      "Epoch 4076: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8288 - f1_score: 0.6871\n",
      "Epoch 4077/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8318 - f1_score: 0.6892\n",
      "Epoch 4077: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8319 - f1_score: 0.6894\n",
      "Epoch 4078/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 4078: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 4079/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8292 - f1_score: 0.6896\n",
      "Epoch 4079: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8293 - f1_score: 0.6896\n",
      "Epoch 4080/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8297 - f1_score: 0.6889\n",
      "Epoch 4080: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8298 - f1_score: 0.6889\n",
      "Epoch 4081/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 4081: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 4082/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 4082: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 4083/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8289 - f1_score: 0.6888\n",
      "Epoch 4083: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8288 - f1_score: 0.6888\n",
      "Epoch 4084/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 4084: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6894\n",
      "Epoch 4085/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 4085: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 4086/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 4086: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 4087/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 4087: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3796 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 4088/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8306 - f1_score: 0.6895\n",
      "Epoch 4088: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8305 - f1_score: 0.6894\n",
      "Epoch 4089/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6894\n",
      "Epoch 4089: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8308 - f1_score: 0.6893\n",
      "Epoch 4090/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6889\n",
      "Epoch 4090: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6889\n",
      "Epoch 4091/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6887\n",
      "Epoch 4091: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6887\n",
      "Epoch 4092/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 4092: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6882\n",
      "Epoch 4093/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4093: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4094/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3860 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 4094: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3859 - accuracy: 0.8276 - f1_score: 0.6887\n",
      "Epoch 4095/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8277 - f1_score: 0.6894\n",
      "Epoch 4095: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8278 - f1_score: 0.6894\n",
      "Epoch 4096/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8312 - f1_score: 0.6895\n",
      "Epoch 4096: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8311 - f1_score: 0.6895\n",
      "Epoch 4097/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6885\n",
      "Epoch 4097: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 4098/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 4098: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6878\n",
      "Epoch 4099/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8273 - f1_score: 0.6884\n",
      "Epoch 4099: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8272 - f1_score: 0.6884\n",
      "Epoch 4100/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8289 - f1_score: 0.6882\n",
      "Epoch 4100: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 4101/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8289 - f1_score: 0.6889\n",
      "Epoch 4101: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8289 - f1_score: 0.6889\n",
      "Epoch 4102/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8307 - f1_score: 0.6904\n",
      "Epoch 4102: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6904\n",
      "Epoch 4103/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8292 - f1_score: 0.6886\n",
      "Epoch 4103: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 4104/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 4104: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 4105/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8297 - f1_score: 0.6902\n",
      "Epoch 4105: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8297 - f1_score: 0.6902\n",
      "Epoch 4106/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8299 - f1_score: 0.6900\n",
      "Epoch 4106: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8299 - f1_score: 0.6900\n",
      "Epoch 4107/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6899\n",
      "Epoch 4107: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6898\n",
      "Epoch 4108/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8278 - f1_score: 0.6886\n",
      "Epoch 4108: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8278 - f1_score: 0.6885\n",
      "Epoch 4109/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6895\n",
      "Epoch 4109: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6895\n",
      "Epoch 4110/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8294 - f1_score: 0.6898\n",
      "Epoch 4110: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8294 - f1_score: 0.6897\n",
      "Epoch 4111/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 4111: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 4112/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 4112: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 4113/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6888\n",
      "Epoch 4113: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 4114/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8297 - f1_score: 0.6892\n",
      "Epoch 4114: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 4115/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 4115: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 4116/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8313 - f1_score: 0.6901\n",
      "Epoch 4116: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8314 - f1_score: 0.6901\n",
      "Epoch 4117/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8308 - f1_score: 0.6896\n",
      "Epoch 4117: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8308 - f1_score: 0.6895\n",
      "Epoch 4118/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 4118: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 4119/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 4119: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6881\n",
      "Epoch 4120/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8284 - f1_score: 0.6887\n",
      "Epoch 4120: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8283 - f1_score: 0.6888\n",
      "Epoch 4121/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6889\n",
      "Epoch 4121: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 4122/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8323 - f1_score: 0.6886\n",
      "Epoch 4122: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3795 - accuracy: 0.8322 - f1_score: 0.6886\n",
      "Epoch 4123/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8316 - f1_score: 0.6900\n",
      "Epoch 4123: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8315 - f1_score: 0.6901\n",
      "Epoch 4124/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4124: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4125/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8287 - f1_score: 0.6888\n",
      "Epoch 4125: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8287 - f1_score: 0.6887\n",
      "Epoch 4126/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 4126: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 4127/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4127: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 4128/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 4128: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 4129/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8313 - f1_score: 0.6890\n",
      "Epoch 4129: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8313 - f1_score: 0.6891\n",
      "Epoch 4130/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8283 - f1_score: 0.6886\n",
      "Epoch 4130: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8282 - f1_score: 0.6885\n",
      "Epoch 4131/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 4131: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4132/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6893\n",
      "Epoch 4132: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8306 - f1_score: 0.6893\n",
      "Epoch 4133/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 4133: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 4134/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 4134: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 4135/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6897\n",
      "Epoch 4135: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8304 - f1_score: 0.6896\n",
      "Epoch 4136/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8320 - f1_score: 0.6900\n",
      "Epoch 4136: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3791 - accuracy: 0.8319 - f1_score: 0.6900\n",
      "Epoch 4137/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8298 - f1_score: 0.6893\n",
      "Epoch 4137: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8298 - f1_score: 0.6892\n",
      "Epoch 4138/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 4138: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 4139/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 4139: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 4140/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 4140: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8305 - f1_score: 0.6886\n",
      "Epoch 4141/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6889\n",
      "Epoch 4141: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4142/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8312 - f1_score: 0.6880\n",
      "Epoch 4142: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8312 - f1_score: 0.6880\n",
      "Epoch 4143/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8304 - f1_score: 0.6892\n",
      "Epoch 4143: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8304 - f1_score: 0.6891\n",
      "Epoch 4144/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8303 - f1_score: 0.6899\n",
      "Epoch 4144: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8303 - f1_score: 0.6900\n",
      "Epoch 4145/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6896\n",
      "Epoch 4145: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6896\n",
      "Epoch 4146/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 4146: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 4147/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8288 - f1_score: 0.6887\n",
      "Epoch 4147: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8288 - f1_score: 0.6888\n",
      "Epoch 4148/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6894\n",
      "Epoch 4148: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6894\n",
      "Epoch 4149/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8279 - f1_score: 0.6886\n",
      "Epoch 4149: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8279 - f1_score: 0.6886\n",
      "Epoch 4150/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8280 - f1_score: 0.6881\n",
      "Epoch 4150: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 4151/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 4151: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 4152/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6873\n",
      "Epoch 4152: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 4153/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8293 - f1_score: 0.6878\n",
      "Epoch 4153: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 4154/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8302 - f1_score: 0.6879\n",
      "Epoch 4154: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8302 - f1_score: 0.6880\n",
      "Epoch 4155/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8299 - f1_score: 0.6895\n",
      "Epoch 4155: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8299 - f1_score: 0.6895\n",
      "Epoch 4156/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8303 - f1_score: 0.6898\n",
      "Epoch 4156: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6898\n",
      "Epoch 4157/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 4157: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8295 - f1_score: 0.6889\n",
      "Epoch 4158/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8301 - f1_score: 0.6899\n",
      "Epoch 4158: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8301 - f1_score: 0.6899\n",
      "Epoch 4159/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8314 - f1_score: 0.6903\n",
      "Epoch 4159: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3776 - accuracy: 0.8314 - f1_score: 0.6903\n",
      "Epoch 4160/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8316 - f1_score: 0.6891\n",
      "Epoch 4160: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8316 - f1_score: 0.6890\n",
      "Epoch 4161/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 4161: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8308 - f1_score: 0.6884\n",
      "Epoch 4162/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 4162: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 4163/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 4163: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 4164/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8303 - f1_score: 0.6893\n",
      "Epoch 4164: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8303 - f1_score: 0.6894\n",
      "Epoch 4165/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8313 - f1_score: 0.6888\n",
      "Epoch 4165: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8312 - f1_score: 0.6889\n",
      "Epoch 4166/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 4166: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.8295 - f1_score: 0.6891\n",
      "Epoch 4167/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8318 - f1_score: 0.6895\n",
      "Epoch 4167: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8318 - f1_score: 0.6895\n",
      "Epoch 4168/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4168: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8308 - f1_score: 0.6889\n",
      "Epoch 4169/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6878\n",
      "Epoch 4169: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6878\n",
      "Epoch 4170/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8268 - f1_score: 0.6873\n",
      "Epoch 4170: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3862 - accuracy: 0.8267 - f1_score: 0.6874\n",
      "Epoch 4171/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8288 - f1_score: 0.6884\n",
      "Epoch 4171: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8289 - f1_score: 0.6884\n",
      "Epoch 4172/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 4172: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 4173/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8314 - f1_score: 0.6888\n",
      "Epoch 4173: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8313 - f1_score: 0.6887\n",
      "Epoch 4174/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 4174: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8293 - f1_score: 0.6888\n",
      "Epoch 4175/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 4175: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 4176/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 4176: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 4177/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3774 - accuracy: 0.8320 - f1_score: 0.6900\n",
      "Epoch 4177: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3775 - accuracy: 0.8321 - f1_score: 0.6902\n",
      "Epoch 4178/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6894\n",
      "Epoch 4178: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6893\n",
      "Epoch 4179/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 4179: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 4180/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 4180: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 4181/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3776 - accuracy: 0.8312 - f1_score: 0.6896\n",
      "Epoch 4181: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3776 - accuracy: 0.8312 - f1_score: 0.6896\n",
      "Epoch 4182/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8316 - f1_score: 0.6898\n",
      "Epoch 4182: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3781 - accuracy: 0.8317 - f1_score: 0.6898\n",
      "Epoch 4183/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6898\n",
      "Epoch 4183: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6899\n",
      "Epoch 4184/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6892\n",
      "Epoch 4184: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8297 - f1_score: 0.6892\n",
      "Epoch 4185/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6885\n",
      "Epoch 4185: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 4186/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8283 - f1_score: 0.6888\n",
      "Epoch 4186: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8284 - f1_score: 0.6889\n",
      "Epoch 4187/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4187: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 4188/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8309 - f1_score: 0.6897\n",
      "Epoch 4188: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8309 - f1_score: 0.6897\n",
      "Epoch 4189/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 4189: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 4190/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8301 - f1_score: 0.6875\n",
      "Epoch 4190: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8301 - f1_score: 0.6875\n",
      "Epoch 4191/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 4191: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4192/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8281 - f1_score: 0.6881\n",
      "Epoch 4192: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 4193/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 4193: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 4194/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8288 - f1_score: 0.6901\n",
      "Epoch 4194: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3822 - accuracy: 0.8288 - f1_score: 0.6900\n",
      "Epoch 4195/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 4195: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8281 - f1_score: 0.6880\n",
      "Epoch 4196/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 4196: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3817 - accuracy: 0.8305 - f1_score: 0.6889\n",
      "Epoch 4197/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6875\n",
      "Epoch 4197: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3834 - accuracy: 0.8296 - f1_score: 0.6875\n",
      "Epoch 4198/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8309 - f1_score: 0.6886\n",
      "Epoch 4198: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8309 - f1_score: 0.6886\n",
      "Epoch 4199/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 4199: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 4200/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4200: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6895\n",
      "Epoch 4201/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8291 - f1_score: 0.6900\n",
      "Epoch 4201: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8290 - f1_score: 0.6898\n",
      "Epoch 4202/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8301 - f1_score: 0.6895\n",
      "Epoch 4202: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3805 - accuracy: 0.8301 - f1_score: 0.6895\n",
      "Epoch 4203/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8315 - f1_score: 0.6892\n",
      "Epoch 4203: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 4204/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8321 - f1_score: 0.6898\n",
      "Epoch 4204: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3791 - accuracy: 0.8322 - f1_score: 0.6898\n",
      "Epoch 4205/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8309 - f1_score: 0.6899\n",
      "Epoch 4205: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8309 - f1_score: 0.6899\n",
      "Epoch 4206/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8310 - f1_score: 0.6894\n",
      "Epoch 4206: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8309 - f1_score: 0.6894\n",
      "Epoch 4207/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8295 - f1_score: 0.6894\n",
      "Epoch 4207: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8295 - f1_score: 0.6893\n",
      "Epoch 4208/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8319 - f1_score: 0.6893\n",
      "Epoch 4208: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8319 - f1_score: 0.6893\n",
      "Epoch 4209/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6892\n",
      "Epoch 4209: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 4210/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 4210: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 4211/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8276 - f1_score: 0.6879\n",
      "Epoch 4211: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8276 - f1_score: 0.6879\n",
      "Epoch 4212/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8299 - f1_score: 0.6896\n",
      "Epoch 4212: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8299 - f1_score: 0.6896\n",
      "Epoch 4213/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 4213: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 4214/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8283 - f1_score: 0.6895\n",
      "Epoch 4214: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8282 - f1_score: 0.6895\n",
      "Epoch 4215/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8293 - f1_score: 0.6889\n",
      "Epoch 4215: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8293 - f1_score: 0.6889\n",
      "Epoch 4216/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8318 - f1_score: 0.6895\n",
      "Epoch 4216: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8317 - f1_score: 0.6895\n",
      "Epoch 4217/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 4217: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 4218/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 4218: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 4219/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8290 - f1_score: 0.6891\n",
      "Epoch 4219: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6889\n",
      "Epoch 4220/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8274 - f1_score: 0.6878\n",
      "Epoch 4220: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8274 - f1_score: 0.6878\n",
      "Epoch 4221/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8297 - f1_score: 0.6878\n",
      "Epoch 4221: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6878\n",
      "Epoch 4222/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8306 - f1_score: 0.6894\n",
      "Epoch 4222: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8307 - f1_score: 0.6894\n",
      "Epoch 4223/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 4223: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 4224/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 4224: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 4225/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8270 - f1_score: 0.6890\n",
      "Epoch 4225: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8269 - f1_score: 0.6889\n",
      "Epoch 4226/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6881\n",
      "Epoch 4226: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 4227/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6871\n",
      "Epoch 4227: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3868 - accuracy: 0.8266 - f1_score: 0.6871\n",
      "Epoch 4228/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6877\n",
      "Epoch 4228: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8300 - f1_score: 0.6877\n",
      "Epoch 4229/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 4229: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 4230/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8300 - f1_score: 0.6881\n",
      "Epoch 4230: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 4231/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 4231: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8309 - f1_score: 0.6885\n",
      "Epoch 4232/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 4232: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 4233/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 4233: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 4234/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6892\n",
      "Epoch 4234: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6892\n",
      "Epoch 4235/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8300 - f1_score: 0.6888\n",
      "Epoch 4235: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8300 - f1_score: 0.6889\n",
      "Epoch 4236/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8311 - f1_score: 0.6890\n",
      "Epoch 4236: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8311 - f1_score: 0.6891\n",
      "Epoch 4237/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3775 - accuracy: 0.8326 - f1_score: 0.6893\n",
      "Epoch 4237: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3775 - accuracy: 0.8327 - f1_score: 0.6894\n",
      "Epoch 4238/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8316 - f1_score: 0.6894\n",
      "Epoch 4238: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8316 - f1_score: 0.6893\n",
      "Epoch 4239/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8301 - f1_score: 0.6893\n",
      "Epoch 4239: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 4240/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8300 - f1_score: 0.6895\n",
      "Epoch 4240: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6895\n",
      "Epoch 4241/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8280 - f1_score: 0.6886\n",
      "Epoch 4241: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8281 - f1_score: 0.6885\n",
      "Epoch 4242/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8287 - f1_score: 0.6889\n",
      "Epoch 4242: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6889\n",
      "Epoch 4243/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 4243: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 4244/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 4244: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6890\n",
      "Epoch 4245/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 4245: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 4246/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4246: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4247/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 4247: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 4248/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8311 - f1_score: 0.6883\n",
      "Epoch 4248: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6882\n",
      "Epoch 4249/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 4249: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 4250/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 4250: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 4251/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8302 - f1_score: 0.6886\n",
      "Epoch 4251: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8302 - f1_score: 0.6885\n",
      "Epoch 4252/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 4252: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8309 - f1_score: 0.6886\n",
      "Epoch 4253/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 4253: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8306 - f1_score: 0.6885\n",
      "Epoch 4254/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8315 - f1_score: 0.6893\n",
      "Epoch 4254: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8316 - f1_score: 0.6892\n",
      "Epoch 4255/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8310 - f1_score: 0.6895\n",
      "Epoch 4255: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8310 - f1_score: 0.6895\n",
      "Epoch 4256/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8305 - f1_score: 0.6890\n",
      "Epoch 4256: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4257/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 4257: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 4258/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4258: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 4259/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8309 - f1_score: 0.6898\n",
      "Epoch 4259: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8309 - f1_score: 0.6898\n",
      "Epoch 4260/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6890\n",
      "Epoch 4260: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6890\n",
      "Epoch 4261/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6895\n",
      "Epoch 4261: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6896\n",
      "Epoch 4262/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 4262: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 4263/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 4263: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 4264/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 4264: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 4265/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6889\n",
      "Epoch 4265: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6889\n",
      "Epoch 4266/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8302 - f1_score: 0.6889\n",
      "Epoch 4266: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8302 - f1_score: 0.6889\n",
      "Epoch 4267/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6886\n",
      "Epoch 4267: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8313 - f1_score: 0.6886\n",
      "Epoch 4268/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8316 - f1_score: 0.6896\n",
      "Epoch 4268: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3794 - accuracy: 0.8317 - f1_score: 0.6897\n",
      "Epoch 4269/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8313 - f1_score: 0.6893\n",
      "Epoch 4269: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8313 - f1_score: 0.6892\n",
      "Epoch 4270/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 4270: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8305 - f1_score: 0.6891\n",
      "Epoch 4271/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 4271: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 4272/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 4272: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 4273/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8297 - f1_score: 0.6883\n",
      "Epoch 4273: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 4274/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 4274: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8303 - f1_score: 0.6892\n",
      "Epoch 4275/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8318 - f1_score: 0.6890\n",
      "Epoch 4275: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8318 - f1_score: 0.6890\n",
      "Epoch 4276/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6897\n",
      "Epoch 4276: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6895\n",
      "Epoch 4277/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 4277: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 4278/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8313 - f1_score: 0.6887\n",
      "Epoch 4278: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8313 - f1_score: 0.6887\n",
      "Epoch 4279/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 4279: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8283 - f1_score: 0.6881\n",
      "Epoch 4280/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 4280: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 4281/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 4281: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8295 - f1_score: 0.6880\n",
      "Epoch 4282/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 4282: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 4283/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 4283: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3781 - accuracy: 0.8310 - f1_score: 0.6889\n",
      "Epoch 4284/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 4284: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 4285/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 4285: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3879 - accuracy: 0.8269 - f1_score: 0.6873\n",
      "Epoch 4286/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 4286: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3847 - accuracy: 0.8287 - f1_score: 0.6880\n",
      "Epoch 4287/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6886\n",
      "Epoch 4287: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6886\n",
      "Epoch 4288/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8308 - f1_score: 0.6886\n",
      "Epoch 4288: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 4289/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 4289: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 4290/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 4290: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8292 - f1_score: 0.6883\n",
      "Epoch 4291/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 4291: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 4292/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 4292: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 4293/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 4293: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 4294/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8318 - f1_score: 0.6893\n",
      "Epoch 4294: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8318 - f1_score: 0.6893\n",
      "Epoch 4295/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 4295: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8308 - f1_score: 0.6885\n",
      "Epoch 4296/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 4296: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 4297/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 4297: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 4298/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8311 - f1_score: 0.6896\n",
      "Epoch 4298: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8311 - f1_score: 0.6896\n",
      "Epoch 4299/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6884\n",
      "Epoch 4299: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6884\n",
      "Epoch 4300/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 4300: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 4301/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 4301: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 4302/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8309 - f1_score: 0.6875\n",
      "Epoch 4302: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8309 - f1_score: 0.6875\n",
      "Epoch 4303/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8311 - f1_score: 0.6891\n",
      "Epoch 4303: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8312 - f1_score: 0.6891\n",
      "Epoch 4304/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4304: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4305/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8296 - f1_score: 0.6889\n",
      "Epoch 4305: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8296 - f1_score: 0.6889\n",
      "Epoch 4306/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6891\n",
      "Epoch 4306: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8285 - f1_score: 0.6891\n",
      "Epoch 4307/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8288 - f1_score: 0.6895\n",
      "Epoch 4307: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8288 - f1_score: 0.6892\n",
      "Epoch 4308/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8284 - f1_score: 0.6894\n",
      "Epoch 4308: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8284 - f1_score: 0.6894\n",
      "Epoch 4309/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 4309: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 4310/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 4310: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3810 - accuracy: 0.8295 - f1_score: 0.6878\n",
      "Epoch 4311/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 4311: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 4312/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6872\n",
      "Epoch 4312: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6872\n",
      "Epoch 4313/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8311 - f1_score: 0.6882\n",
      "Epoch 4313: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8311 - f1_score: 0.6883\n",
      "Epoch 4314/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8320 - f1_score: 0.6898\n",
      "Epoch 4314: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3782 - accuracy: 0.8320 - f1_score: 0.6898\n",
      "Epoch 4315/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8313 - f1_score: 0.6891\n",
      "Epoch 4315: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6889\n",
      "Epoch 4316/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8307 - f1_score: 0.6882\n",
      "Epoch 4316: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8307 - f1_score: 0.6882\n",
      "Epoch 4317/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8298 - f1_score: 0.6880\n",
      "Epoch 4317: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8297 - f1_score: 0.6881\n",
      "Epoch 4318/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 4318: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3839 - accuracy: 0.8294 - f1_score: 0.6875\n",
      "Epoch 4319/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 4319: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8301 - f1_score: 0.6883\n",
      "Epoch 4320/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4320: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8303 - f1_score: 0.6896\n",
      "Epoch 4321/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 4321: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8286 - f1_score: 0.6883\n",
      "Epoch 4322/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8293 - f1_score: 0.6888\n",
      "Epoch 4322: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8293 - f1_score: 0.6888\n",
      "Epoch 4323/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 4323: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 4324/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8269 - f1_score: 0.6874\n",
      "Epoch 4324: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3861 - accuracy: 0.8270 - f1_score: 0.6874\n",
      "Epoch 4325/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8296 - f1_score: 0.6882\n",
      "Epoch 4325: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 4326/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 4326: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 4327/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8304 - f1_score: 0.6885\n",
      "Epoch 4327: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 4328/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8320 - f1_score: 0.6901\n",
      "Epoch 4328: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3786 - accuracy: 0.8320 - f1_score: 0.6901\n",
      "Epoch 4329/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8292 - f1_score: 0.6894\n",
      "Epoch 4329: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8292 - f1_score: 0.6894\n",
      "Epoch 4330/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8287 - f1_score: 0.6891\n",
      "Epoch 4330: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8287 - f1_score: 0.6891\n",
      "Epoch 4331/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6894\n",
      "Epoch 4331: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6894\n",
      "Epoch 4332/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 4332: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 4333/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8269 - f1_score: 0.6870\n",
      "Epoch 4333: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3854 - accuracy: 0.8269 - f1_score: 0.6869\n",
      "Epoch 4334/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8264 - f1_score: 0.6868\n",
      "Epoch 4334: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3860 - accuracy: 0.8264 - f1_score: 0.6868\n",
      "Epoch 4335/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 4335: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8298 - f1_score: 0.6891\n",
      "Epoch 4336/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8293 - f1_score: 0.6898\n",
      "Epoch 4336: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8293 - f1_score: 0.6898\n",
      "Epoch 4337/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6884\n",
      "Epoch 4337: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8289 - f1_score: 0.6884\n",
      "Epoch 4338/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 4338: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8289 - f1_score: 0.6883\n",
      "Epoch 4339/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 4339: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6882\n",
      "Epoch 4340/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6888\n",
      "Epoch 4340: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8293 - f1_score: 0.6889\n",
      "Epoch 4341/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8279 - f1_score: 0.6879\n",
      "Epoch 4341: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8280 - f1_score: 0.6879\n",
      "Epoch 4342/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6876\n",
      "Epoch 4342: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6876\n",
      "Epoch 4343/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 4343: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 4344/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 4344: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 4345/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 4345: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6891\n",
      "Epoch 4346/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8310 - f1_score: 0.6892\n",
      "Epoch 4346: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4347/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8283 - f1_score: 0.6877\n",
      "Epoch 4347: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8284 - f1_score: 0.6877\n",
      "Epoch 4348/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8297 - f1_score: 0.6872\n",
      "Epoch 4348: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8297 - f1_score: 0.6872\n",
      "Epoch 4349/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8306 - f1_score: 0.6876\n",
      "Epoch 4349: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8307 - f1_score: 0.6877\n",
      "Epoch 4350/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 4350: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 4351/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 4351: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 4352/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 4352: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8305 - f1_score: 0.6881\n",
      "Epoch 4353/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 4353: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 4354/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8288 - f1_score: 0.6881\n",
      "Epoch 4354: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6881\n",
      "Epoch 4355/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4355: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4356/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 4356: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 4357/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.8274 - f1_score: 0.6880\n",
      "Epoch 4357: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3869 - accuracy: 0.8275 - f1_score: 0.6881\n",
      "Epoch 4358/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8271 - f1_score: 0.6882\n",
      "Epoch 4358: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3865 - accuracy: 0.8272 - f1_score: 0.6882\n",
      "Epoch 4359/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8276 - f1_score: 0.6886\n",
      "Epoch 4359: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8277 - f1_score: 0.6886\n",
      "Epoch 4360/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8271 - f1_score: 0.6883\n",
      "Epoch 4360: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8272 - f1_score: 0.6885\n",
      "Epoch 4361/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8286 - f1_score: 0.6886\n",
      "Epoch 4361: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 4362/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8294 - f1_score: 0.6877\n",
      "Epoch 4362: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8294 - f1_score: 0.6877\n",
      "Epoch 4363/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6870\n",
      "Epoch 4363: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8289 - f1_score: 0.6872\n",
      "Epoch 4364/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6877\n",
      "Epoch 4364: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6878\n",
      "Epoch 4365/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 4365: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 4366/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8297 - f1_score: 0.6884\n",
      "Epoch 4366: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8297 - f1_score: 0.6883\n",
      "Epoch 4367/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 4367: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 4368/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4368: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4369/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6897\n",
      "Epoch 4369: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6897\n",
      "Epoch 4370/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6886\n",
      "Epoch 4370: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6885\n",
      "Epoch 4371/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8306 - f1_score: 0.6894\n",
      "Epoch 4371: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6894\n",
      "Epoch 4372/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 4372: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6879\n",
      "Epoch 4373/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 4373: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 4374/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8305 - f1_score: 0.6886\n",
      "Epoch 4374: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 4375/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6892\n",
      "Epoch 4375: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 4376/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8283 - f1_score: 0.6886\n",
      "Epoch 4376: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8283 - f1_score: 0.6886\n",
      "Epoch 4377/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8284 - f1_score: 0.6880\n",
      "Epoch 4377: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8285 - f1_score: 0.6881\n",
      "Epoch 4378/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8299 - f1_score: 0.6894\n",
      "Epoch 4378: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8299 - f1_score: 0.6894\n",
      "Epoch 4379/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8297 - f1_score: 0.6878\n",
      "Epoch 4379: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8298 - f1_score: 0.6879\n",
      "Epoch 4380/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8321 - f1_score: 0.6880\n",
      "Epoch 4380: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8321 - f1_score: 0.6879\n",
      "Epoch 4381/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8289 - f1_score: 0.6875\n",
      "Epoch 4381: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8289 - f1_score: 0.6875\n",
      "Epoch 4382/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8295 - f1_score: 0.6884\n",
      "Epoch 4382: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3831 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 4383/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 4383: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 4384/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 4384: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8306 - f1_score: 0.6880\n",
      "Epoch 4385/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8290 - f1_score: 0.6888\n",
      "Epoch 4385: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3821 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 4386/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 4386: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8284 - f1_score: 0.6876\n",
      "Epoch 4387/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8302 - f1_score: 0.6892\n",
      "Epoch 4387: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 4388/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 4388: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 4389/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 4389: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 4390/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6885\n",
      "Epoch 4390: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 4391/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 4391: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8305 - f1_score: 0.6881\n",
      "Epoch 4392/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6880\n",
      "Epoch 4392: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8302 - f1_score: 0.6880\n",
      "Epoch 4393/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8307 - f1_score: 0.6881\n",
      "Epoch 4393: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6880\n",
      "Epoch 4394/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8312 - f1_score: 0.6891\n",
      "Epoch 4394: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3785 - accuracy: 0.8312 - f1_score: 0.6891\n",
      "Epoch 4395/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 4395: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 4396/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8311 - f1_score: 0.6888\n",
      "Epoch 4396: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 4397/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 4397: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 4398/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 4398: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8286 - f1_score: 0.6880\n",
      "Epoch 4399/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 4399: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 4400/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 4400: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 4401/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8315 - f1_score: 0.6882\n",
      "Epoch 4401: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8316 - f1_score: 0.6882\n",
      "Epoch 4402/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6879\n",
      "Epoch 4402: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 4403/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8272 - f1_score: 0.6880\n",
      "Epoch 4403: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3849 - accuracy: 0.8271 - f1_score: 0.6881\n",
      "Epoch 4404/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8319 - f1_score: 0.6891\n",
      "Epoch 4404: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3783 - accuracy: 0.8318 - f1_score: 0.6891\n",
      "Epoch 4405/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3771 - accuracy: 0.8327 - f1_score: 0.6900\n",
      "Epoch 4405: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3771 - accuracy: 0.8327 - f1_score: 0.6900\n",
      "Epoch 4406/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8298 - f1_score: 0.6886\n",
      "Epoch 4406: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8298 - f1_score: 0.6886\n",
      "Epoch 4407/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8326 - f1_score: 0.6900\n",
      "Epoch 4407: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3782 - accuracy: 0.8325 - f1_score: 0.6897\n",
      "Epoch 4408/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 4408: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8296 - f1_score: 0.6889\n",
      "Epoch 4409/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8298 - f1_score: 0.6891\n",
      "Epoch 4409: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8298 - f1_score: 0.6892\n",
      "Epoch 4410/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8305 - f1_score: 0.6881\n",
      "Epoch 4410: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 4411/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 4411: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 4412/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 4412: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8292 - f1_score: 0.6886\n",
      "Epoch 4413/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8291 - f1_score: 0.6893\n",
      "Epoch 4413: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8293 - f1_score: 0.6894\n",
      "Epoch 4414/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8295 - f1_score: 0.6888\n",
      "Epoch 4414: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8295 - f1_score: 0.6889\n",
      "Epoch 4415/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8308 - f1_score: 0.6893\n",
      "Epoch 4415: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8308 - f1_score: 0.6893\n",
      "Epoch 4416/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8318 - f1_score: 0.6896\n",
      "Epoch 4416: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8318 - f1_score: 0.6895\n",
      "Epoch 4417/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 4417: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 4418/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 4418: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6888\n",
      "Epoch 4419/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6893\n",
      "Epoch 4419: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6892\n",
      "Epoch 4420/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 4420: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 4421/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8293 - f1_score: 0.6894\n",
      "Epoch 4421: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8293 - f1_score: 0.6893\n",
      "Epoch 4422/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6896\n",
      "Epoch 4422: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8295 - f1_score: 0.6895\n",
      "Epoch 4423/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8312 - f1_score: 0.6876\n",
      "Epoch 4423: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8312 - f1_score: 0.6876\n",
      "Epoch 4424/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 4424: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 4425/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4425: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 4426/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6874\n",
      "Epoch 4426: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8287 - f1_score: 0.6874\n",
      "Epoch 4427/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6872\n",
      "Epoch 4427: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6873\n",
      "Epoch 4428/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 4428: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 4429/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8298 - f1_score: 0.6891\n",
      "Epoch 4429: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8298 - f1_score: 0.6891\n",
      "Epoch 4430/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8302 - f1_score: 0.6901\n",
      "Epoch 4430: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8302 - f1_score: 0.6900\n",
      "Epoch 4431/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4431: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4432/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8301 - f1_score: 0.6898\n",
      "Epoch 4432: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8300 - f1_score: 0.6897\n",
      "Epoch 4433/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 4433: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 4434/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8293 - f1_score: 0.6892\n",
      "Epoch 4434: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8293 - f1_score: 0.6892\n",
      "Epoch 4435/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8293 - f1_score: 0.6891\n",
      "Epoch 4435: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 4436/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6894\n",
      "Epoch 4436: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6894\n",
      "Epoch 4437/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 4437: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 4438/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 4438: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 4439/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 4439: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 4440/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8298 - f1_score: 0.6885\n",
      "Epoch 4440: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8298 - f1_score: 0.6884\n",
      "Epoch 4441/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6895\n",
      "Epoch 4441: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8306 - f1_score: 0.6895\n",
      "Epoch 4442/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8304 - f1_score: 0.6892\n",
      "Epoch 4442: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6892\n",
      "Epoch 4443/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8312 - f1_score: 0.6896\n",
      "Epoch 4443: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8312 - f1_score: 0.6897\n",
      "Epoch 4444/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 4444: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 4445/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8286 - f1_score: 0.6883\n",
      "Epoch 4445: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3829 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 4446/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 4446: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8300 - f1_score: 0.6892\n",
      "Epoch 4447/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8296 - f1_score: 0.6886\n",
      "Epoch 4447: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6887\n",
      "Epoch 4448/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 4448: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 4449/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6885\n",
      "Epoch 4449: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 4450/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8280 - f1_score: 0.6892\n",
      "Epoch 4450: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8279 - f1_score: 0.6892\n",
      "Epoch 4451/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 4451: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6886\n",
      "Epoch 4452/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6892\n",
      "Epoch 4452: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6892\n",
      "Epoch 4453/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8310 - f1_score: 0.6899\n",
      "Epoch 4453: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 4454/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6893\n",
      "Epoch 4454: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6893\n",
      "Epoch 4455/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4455: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 4456/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 4456: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 4457/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 4457: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 4458/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6893\n",
      "Epoch 4458: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8293 - f1_score: 0.6893\n",
      "Epoch 4459/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8298 - f1_score: 0.6887\n",
      "Epoch 4459: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 4460/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8313 - f1_score: 0.6885\n",
      "Epoch 4460: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8313 - f1_score: 0.6885\n",
      "Epoch 4461/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8317 - f1_score: 0.6883\n",
      "Epoch 4461: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8317 - f1_score: 0.6883\n",
      "Epoch 4462/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8323 - f1_score: 0.6883\n",
      "Epoch 4462: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3782 - accuracy: 0.8321 - f1_score: 0.6884\n",
      "Epoch 4463/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4463: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 4464/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 4464: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 4465/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.8322 - f1_score: 0.6896\n",
      "Epoch 4465: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8321 - f1_score: 0.6896\n",
      "Epoch 4466/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 4466: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 4467/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8312 - f1_score: 0.6892\n",
      "Epoch 4467: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8313 - f1_score: 0.6893\n",
      "Epoch 4468/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8314 - f1_score: 0.6896\n",
      "Epoch 4468: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8314 - f1_score: 0.6895\n",
      "Epoch 4469/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.8323 - f1_score: 0.6894\n",
      "Epoch 4469: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3779 - accuracy: 0.8323 - f1_score: 0.6893\n",
      "Epoch 4470/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8309 - f1_score: 0.6892\n",
      "Epoch 4470: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4471/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 4471: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8305 - f1_score: 0.6886\n",
      "Epoch 4472/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 4472: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4473/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8309 - f1_score: 0.6886\n",
      "Epoch 4473: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8308 - f1_score: 0.6886\n",
      "Epoch 4474/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 4474: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 4475/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6885\n",
      "Epoch 4475: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 4476/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 4476: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 4477/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6883\n",
      "Epoch 4477: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8282 - f1_score: 0.6882\n",
      "Epoch 4478/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8293 - f1_score: 0.6879\n",
      "Epoch 4478: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 4479/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8308 - f1_score: 0.6885\n",
      "Epoch 4479: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4480/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6877\n",
      "Epoch 4480: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8292 - f1_score: 0.6877\n",
      "Epoch 4481/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6879\n",
      "Epoch 4481: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8293 - f1_score: 0.6878\n",
      "Epoch 4482/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 4482: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6880\n",
      "Epoch 4483/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.8320 - f1_score: 0.6898\n",
      "Epoch 4483: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3785 - accuracy: 0.8320 - f1_score: 0.6897\n",
      "Epoch 4484/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6883\n",
      "Epoch 4484: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8299 - f1_score: 0.6884\n",
      "Epoch 4485/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8313 - f1_score: 0.6894\n",
      "Epoch 4485: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8312 - f1_score: 0.6893\n",
      "Epoch 4486/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6891\n",
      "Epoch 4486: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6891\n",
      "Epoch 4487/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 4487: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 4488/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 4488: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 4489/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4489: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4490/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 4490: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6883\n",
      "Epoch 4491/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 4491: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 4492/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8315 - f1_score: 0.6887\n",
      "Epoch 4492: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8314 - f1_score: 0.6885\n",
      "Epoch 4493/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 4493: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 4494/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8290 - f1_score: 0.6897\n",
      "Epoch 4494: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8290 - f1_score: 0.6897\n",
      "Epoch 4495/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8284 - f1_score: 0.6902\n",
      "Epoch 4495: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8285 - f1_score: 0.6902\n",
      "Epoch 4496/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 4496: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3827 - accuracy: 0.8294 - f1_score: 0.6890\n",
      "Epoch 4497/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 4497: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8292 - f1_score: 0.6878\n",
      "Epoch 4498/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 4498: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 4499/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3867 - accuracy: 0.8279 - f1_score: 0.6871\n",
      "Epoch 4499: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3867 - accuracy: 0.8279 - f1_score: 0.6871\n",
      "Epoch 4500/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6881\n",
      "Epoch 4500: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 4501/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8300 - f1_score: 0.6885\n",
      "Epoch 4501: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 4502/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8311 - f1_score: 0.6891\n",
      "Epoch 4502: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8311 - f1_score: 0.6891\n",
      "Epoch 4503/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 4503: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8307 - f1_score: 0.6890\n",
      "Epoch 4504/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8304 - f1_score: 0.6903\n",
      "Epoch 4504: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8304 - f1_score: 0.6902\n",
      "Epoch 4505/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8295 - f1_score: 0.6902\n",
      "Epoch 4505: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8295 - f1_score: 0.6902\n",
      "Epoch 4506/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 4506: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8302 - f1_score: 0.6891\n",
      "Epoch 4507/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8287 - f1_score: 0.6885\n",
      "Epoch 4507: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6886\n",
      "Epoch 4508/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8317 - f1_score: 0.6877\n",
      "Epoch 4508: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8317 - f1_score: 0.6879\n",
      "Epoch 4509/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8300 - f1_score: 0.6872\n",
      "Epoch 4509: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8300 - f1_score: 0.6874\n",
      "Epoch 4510/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8309 - f1_score: 0.6883\n",
      "Epoch 4510: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 4511/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8305 - f1_score: 0.6879\n",
      "Epoch 4511: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8303 - f1_score: 0.6881\n",
      "Epoch 4512/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8309 - f1_score: 0.6888\n",
      "Epoch 4512: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8308 - f1_score: 0.6888\n",
      "Epoch 4513/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 4513: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 4514/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 4514: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6883\n",
      "Epoch 4515/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8324 - f1_score: 0.6882\n",
      "Epoch 4515: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8324 - f1_score: 0.6882\n",
      "Epoch 4516/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 4516: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6880\n",
      "Epoch 4517/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8297 - f1_score: 0.6888\n",
      "Epoch 4517: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8297 - f1_score: 0.6888\n",
      "Epoch 4518/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6882\n",
      "Epoch 4518: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3843 - accuracy: 0.8282 - f1_score: 0.6881\n",
      "Epoch 4519/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 4519: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 4520/5000\n",
      "443/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8292 - f1_score: 0.6884\n",
      "Epoch 4520: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3822 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 4521/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8293 - f1_score: 0.6891\n",
      "Epoch 4521: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8293 - f1_score: 0.6890\n",
      "Epoch 4522/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8302 - f1_score: 0.6880\n",
      "Epoch 4522: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6879\n",
      "Epoch 4523/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8310 - f1_score: 0.6892\n",
      "Epoch 4523: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8310 - f1_score: 0.6891\n",
      "Epoch 4524/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8308 - f1_score: 0.6880\n",
      "Epoch 4524: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8308 - f1_score: 0.6880\n",
      "Epoch 4525/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8312 - f1_score: 0.6885\n",
      "Epoch 4525: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 4526/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6887\n",
      "Epoch 4526: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6887\n",
      "Epoch 4527/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 4527: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 4528/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6900\n",
      "Epoch 4528: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6900\n",
      "Epoch 4529/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8300 - f1_score: 0.6889\n",
      "Epoch 4529: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 4530/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8308 - f1_score: 0.6878\n",
      "Epoch 4530: accuracy did not improve from 0.83287\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8307 - f1_score: 0.6878\n",
      "Epoch 4531/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3771 - accuracy: 0.8329 - f1_score: 0.6892\n",
      "Epoch 4531: accuracy improved from 0.83287 to 0.83288, saving model to ./625-batch_size625\\weight-improvement2-4531-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3771 - accuracy: 0.8329 - f1_score: 0.6892\n",
      "Epoch 4532/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 4532: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 4533/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8309 - f1_score: 0.6896\n",
      "Epoch 4533: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8308 - f1_score: 0.6894\n",
      "Epoch 4534/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8311 - f1_score: 0.6894\n",
      "Epoch 4534: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8312 - f1_score: 0.6893\n",
      "Epoch 4535/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8293 - f1_score: 0.6882\n",
      "Epoch 4535: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8293 - f1_score: 0.6881\n",
      "Epoch 4536/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 4536: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8294 - f1_score: 0.6886\n",
      "Epoch 4537/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 4537: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8304 - f1_score: 0.6887\n",
      "Epoch 4538/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6891\n",
      "Epoch 4538: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6891\n",
      "Epoch 4539/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6892\n",
      "Epoch 4539: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8311 - f1_score: 0.6893\n",
      "Epoch 4540/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4540: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 4541/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 4541: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 4542/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8297 - f1_score: 0.6881\n",
      "Epoch 4542: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8297 - f1_score: 0.6881\n",
      "Epoch 4543/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8310 - f1_score: 0.6899\n",
      "Epoch 4543: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8310 - f1_score: 0.6899\n",
      "Epoch 4544/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.8308 - f1_score: 0.6895\n",
      "Epoch 4544: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8308 - f1_score: 0.6895\n",
      "Epoch 4545/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8302 - f1_score: 0.6889\n",
      "Epoch 4545: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8302 - f1_score: 0.6889\n",
      "Epoch 4546/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8288 - f1_score: 0.6896\n",
      "Epoch 4546: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8288 - f1_score: 0.6896\n",
      "Epoch 4547/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8286 - f1_score: 0.6893\n",
      "Epoch 4547: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8285 - f1_score: 0.6893\n",
      "Epoch 4548/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6891\n",
      "Epoch 4548: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6891\n",
      "Epoch 4549/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8307 - f1_score: 0.6895\n",
      "Epoch 4549: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8307 - f1_score: 0.6895\n",
      "Epoch 4550/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4550: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 4551/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 4551: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 4552/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6881\n",
      "Epoch 4552: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6881\n",
      "Epoch 4553/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8306 - f1_score: 0.6891\n",
      "Epoch 4553: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3812 - accuracy: 0.8306 - f1_score: 0.6891\n",
      "Epoch 4554/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8283 - f1_score: 0.6884\n",
      "Epoch 4554: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6883\n",
      "Epoch 4555/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6891\n",
      "Epoch 4555: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6891\n",
      "Epoch 4556/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.8278 - f1_score: 0.6891\n",
      "Epoch 4556: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3850 - accuracy: 0.8277 - f1_score: 0.6891\n",
      "Epoch 4557/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 4557: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 4558/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8309 - f1_score: 0.6891\n",
      "Epoch 4558: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 4559/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8317 - f1_score: 0.6900\n",
      "Epoch 4559: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8318 - f1_score: 0.6900\n",
      "Epoch 4560/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8279 - f1_score: 0.6884\n",
      "Epoch 4560: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3858 - accuracy: 0.8279 - f1_score: 0.6883\n",
      "Epoch 4561/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6900\n",
      "Epoch 4561: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8300 - f1_score: 0.6898\n",
      "Epoch 4562/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8304 - f1_score: 0.6894\n",
      "Epoch 4562: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8304 - f1_score: 0.6894\n",
      "Epoch 4563/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8306 - f1_score: 0.6899\n",
      "Epoch 4563: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8307 - f1_score: 0.6899\n",
      "Epoch 4564/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8316 - f1_score: 0.6886\n",
      "Epoch 4564: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8316 - f1_score: 0.6887\n",
      "Epoch 4565/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 4565: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3847 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 4566/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3822 - accuracy: 0.8302 - f1_score: 0.6884\n",
      "Epoch 4566: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8302 - f1_score: 0.6884\n",
      "Epoch 4567/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 4567: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3816 - accuracy: 0.8303 - f1_score: 0.6886\n",
      "Epoch 4568/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8309 - f1_score: 0.6901\n",
      "Epoch 4568: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8309 - f1_score: 0.6902\n",
      "Epoch 4569/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8317 - f1_score: 0.6889\n",
      "Epoch 4569: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8317 - f1_score: 0.6889\n",
      "Epoch 4570/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 4570: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8296 - f1_score: 0.6882\n",
      "Epoch 4571/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8306 - f1_score: 0.6887\n",
      "Epoch 4571: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8305 - f1_score: 0.6886\n",
      "Epoch 4572/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8317 - f1_score: 0.6896\n",
      "Epoch 4572: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8317 - f1_score: 0.6896\n",
      "Epoch 4573/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6885\n",
      "Epoch 4573: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6885\n",
      "Epoch 4574/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 4574: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 4575/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 4575: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 4576/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8308 - f1_score: 0.6894\n",
      "Epoch 4576: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8308 - f1_score: 0.6894\n",
      "Epoch 4577/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8308 - f1_score: 0.6899\n",
      "Epoch 4577: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8309 - f1_score: 0.6900\n",
      "Epoch 4578/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8320 - f1_score: 0.6900\n",
      "Epoch 4578: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8320 - f1_score: 0.6900\n",
      "Epoch 4579/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8317 - f1_score: 0.6893\n",
      "Epoch 4579: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8317 - f1_score: 0.6894\n",
      "Epoch 4580/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8314 - f1_score: 0.6895\n",
      "Epoch 4580: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8314 - f1_score: 0.6895\n",
      "Epoch 4581/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8317 - f1_score: 0.6889\n",
      "Epoch 4581: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8315 - f1_score: 0.6887\n",
      "Epoch 4582/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8314 - f1_score: 0.6890\n",
      "Epoch 4582: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8313 - f1_score: 0.6888\n",
      "Epoch 4583/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8301 - f1_score: 0.6891\n",
      "Epoch 4583: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4584/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8308 - f1_score: 0.6889\n",
      "Epoch 4584: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8308 - f1_score: 0.6889\n",
      "Epoch 4585/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8321 - f1_score: 0.6892\n",
      "Epoch 4585: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8321 - f1_score: 0.6892\n",
      "Epoch 4586/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8303 - f1_score: 0.6879\n",
      "Epoch 4586: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6881\n",
      "Epoch 4587/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8296 - f1_score: 0.6889\n",
      "Epoch 4587: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8296 - f1_score: 0.6889\n",
      "Epoch 4588/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8312 - f1_score: 0.6890\n",
      "Epoch 4588: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8312 - f1_score: 0.6887\n",
      "Epoch 4589/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6889\n",
      "Epoch 4589: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 4590/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4590: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4591/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8303 - f1_score: 0.6879\n",
      "Epoch 4591: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8303 - f1_score: 0.6879\n",
      "Epoch 4592/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 4592: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3836 - accuracy: 0.8285 - f1_score: 0.6883\n",
      "Epoch 4593/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8301 - f1_score: 0.6893\n",
      "Epoch 4593: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8301 - f1_score: 0.6893\n",
      "Epoch 4594/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8317 - f1_score: 0.6877\n",
      "Epoch 4594: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8319 - f1_score: 0.6877\n",
      "Epoch 4595/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8316 - f1_score: 0.6884\n",
      "Epoch 4595: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8315 - f1_score: 0.6885\n",
      "Epoch 4596/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8322 - f1_score: 0.6891\n",
      "Epoch 4596: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8322 - f1_score: 0.6891\n",
      "Epoch 4597/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4597: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 4598/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8307 - f1_score: 0.6878\n",
      "Epoch 4598: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8307 - f1_score: 0.6878\n",
      "Epoch 4599/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8298 - f1_score: 0.6882\n",
      "Epoch 4599: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 4600/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 4600: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 4601/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8308 - f1_score: 0.6896\n",
      "Epoch 4601: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8309 - f1_score: 0.6896\n",
      "Epoch 4602/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 4602: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 4603/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 4603: accuracy did not improve from 0.83288\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 4604/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3779 - accuracy: 0.8329 - f1_score: 0.6895\n",
      "Epoch 4604: accuracy improved from 0.83288 to 0.83299, saving model to ./625-batch_size625\\weight-improvement2-4604-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3778 - accuracy: 0.8330 - f1_score: 0.6894\n",
      "Epoch 4605/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.8317 - f1_score: 0.6898\n",
      "Epoch 4605: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3782 - accuracy: 0.8316 - f1_score: 0.6898\n",
      "Epoch 4606/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6883\n",
      "Epoch 4606: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6884\n",
      "Epoch 4607/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8292 - f1_score: 0.6886\n",
      "Epoch 4607: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 4608/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 4608: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 4609/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8294 - f1_score: 0.6883\n",
      "Epoch 4609: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 4610/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8283 - f1_score: 0.6878\n",
      "Epoch 4610: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6879\n",
      "Epoch 4611/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8308 - f1_score: 0.6877\n",
      "Epoch 4611: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8308 - f1_score: 0.6877\n",
      "Epoch 4612/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8305 - f1_score: 0.6881\n",
      "Epoch 4612: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8305 - f1_score: 0.6881\n",
      "Epoch 4613/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6873\n",
      "Epoch 4613: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6873\n",
      "Epoch 4614/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8311 - f1_score: 0.6877\n",
      "Epoch 4614: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8310 - f1_score: 0.6878\n",
      "Epoch 4615/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8316 - f1_score: 0.6877\n",
      "Epoch 4615: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8317 - f1_score: 0.6879\n",
      "Epoch 4616/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8311 - f1_score: 0.6883\n",
      "Epoch 4616: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3799 - accuracy: 0.8312 - f1_score: 0.6883\n",
      "Epoch 4617/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 4617: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8304 - f1_score: 0.6882\n",
      "Epoch 4618/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8317 - f1_score: 0.6892\n",
      "Epoch 4618: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8318 - f1_score: 0.6893\n",
      "Epoch 4619/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8307 - f1_score: 0.6887\n",
      "Epoch 4619: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8308 - f1_score: 0.6888\n",
      "Epoch 4620/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 4620: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 4621/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3777 - accuracy: 0.8322 - f1_score: 0.6902\n",
      "Epoch 4621: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3777 - accuracy: 0.8322 - f1_score: 0.6902\n",
      "Epoch 4622/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8313 - f1_score: 0.6895\n",
      "Epoch 4622: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8312 - f1_score: 0.6895\n",
      "Epoch 4623/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8304 - f1_score: 0.6892\n",
      "Epoch 4623: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8305 - f1_score: 0.6891\n",
      "Epoch 4624/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 4624: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6889\n",
      "Epoch 4625/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8324 - f1_score: 0.6892\n",
      "Epoch 4625: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8323 - f1_score: 0.6894\n",
      "Epoch 4626/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8310 - f1_score: 0.6901\n",
      "Epoch 4626: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8309 - f1_score: 0.6901\n",
      "Epoch 4627/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 4627: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8305 - f1_score: 0.6884\n",
      "Epoch 4628/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 4628: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 4629/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8279 - f1_score: 0.6886\n",
      "Epoch 4629: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8278 - f1_score: 0.6886\n",
      "Epoch 4630/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6895\n",
      "Epoch 4630: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6895\n",
      "Epoch 4631/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8314 - f1_score: 0.6898\n",
      "Epoch 4631: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6897\n",
      "Epoch 4632/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6892\n",
      "Epoch 4632: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8292 - f1_score: 0.6892\n",
      "Epoch 4633/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8303 - f1_score: 0.6894\n",
      "Epoch 4633: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8303 - f1_score: 0.6894\n",
      "Epoch 4634/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8278 - f1_score: 0.6892\n",
      "Epoch 4634: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3850 - accuracy: 0.8278 - f1_score: 0.6892\n",
      "Epoch 4635/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8308 - f1_score: 0.6892\n",
      "Epoch 4635: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8308 - f1_score: 0.6892\n",
      "Epoch 4636/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6890\n",
      "Epoch 4636: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8311 - f1_score: 0.6891\n",
      "Epoch 4637/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8320 - f1_score: 0.6889\n",
      "Epoch 4637: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8319 - f1_score: 0.6889\n",
      "Epoch 4638/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6879\n",
      "Epoch 4638: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8300 - f1_score: 0.6880\n",
      "Epoch 4639/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6887\n",
      "Epoch 4639: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8284 - f1_score: 0.6887\n",
      "Epoch 4640/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6883\n",
      "Epoch 4640: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6885\n",
      "Epoch 4641/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8315 - f1_score: 0.6894\n",
      "Epoch 4641: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8316 - f1_score: 0.6894\n",
      "Epoch 4642/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8310 - f1_score: 0.6891\n",
      "Epoch 4642: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 4643/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8315 - f1_score: 0.6890\n",
      "Epoch 4643: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8315 - f1_score: 0.6890\n",
      "Epoch 4644/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8306 - f1_score: 0.6887\n",
      "Epoch 4644: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8306 - f1_score: 0.6887\n",
      "Epoch 4645/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 4645: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 4646/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8301 - f1_score: 0.6885\n",
      "Epoch 4646: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8301 - f1_score: 0.6886\n",
      "Epoch 4647/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 4647: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 4648/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 4648: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 4649/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 4649: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8297 - f1_score: 0.6885\n",
      "Epoch 4650/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3837 - accuracy: 0.8289 - f1_score: 0.6890\n",
      "Epoch 4650: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8291 - f1_score: 0.6890\n",
      "Epoch 4651/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8317 - f1_score: 0.6898\n",
      "Epoch 4651: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8316 - f1_score: 0.6898\n",
      "Epoch 4652/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 4652: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 4653/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8314 - f1_score: 0.6901\n",
      "Epoch 4653: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8314 - f1_score: 0.6901\n",
      "Epoch 4654/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8306 - f1_score: 0.6888\n",
      "Epoch 4654: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8306 - f1_score: 0.6887\n",
      "Epoch 4655/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 4655: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8300 - f1_score: 0.6893\n",
      "Epoch 4656/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6896\n",
      "Epoch 4656: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8310 - f1_score: 0.6895\n",
      "Epoch 4657/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8292 - f1_score: 0.6891\n",
      "Epoch 4657: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8292 - f1_score: 0.6891\n",
      "Epoch 4658/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8310 - f1_score: 0.6897\n",
      "Epoch 4658: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8309 - f1_score: 0.6897\n",
      "Epoch 4659/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 4659: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8299 - f1_score: 0.6892\n",
      "Epoch 4660/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8296 - f1_score: 0.6905\n",
      "Epoch 4660: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8297 - f1_score: 0.6906\n",
      "Epoch 4661/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3785 - accuracy: 0.8309 - f1_score: 0.6902\n",
      "Epoch 4661: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3785 - accuracy: 0.8309 - f1_score: 0.6902\n",
      "Epoch 4662/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6895\n",
      "Epoch 4662: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8309 - f1_score: 0.6892\n",
      "Epoch 4663/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8316 - f1_score: 0.6902\n",
      "Epoch 4663: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8314 - f1_score: 0.6901\n",
      "Epoch 4664/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8309 - f1_score: 0.6884\n",
      "Epoch 4664: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8310 - f1_score: 0.6884\n",
      "Epoch 4665/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8316 - f1_score: 0.6891\n",
      "Epoch 4665: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8317 - f1_score: 0.6891\n",
      "Epoch 4666/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3776 - accuracy: 0.8319 - f1_score: 0.6900\n",
      "Epoch 4666: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3776 - accuracy: 0.8319 - f1_score: 0.6900\n",
      "Epoch 4667/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8311 - f1_score: 0.6898\n",
      "Epoch 4667: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3790 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 4668/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6898\n",
      "Epoch 4668: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8305 - f1_score: 0.6898\n",
      "Epoch 4669/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8317 - f1_score: 0.6893\n",
      "Epoch 4669: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8317 - f1_score: 0.6893\n",
      "Epoch 4670/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 4670: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8308 - f1_score: 0.6888\n",
      "Epoch 4671/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8311 - f1_score: 0.6889\n",
      "Epoch 4671: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8311 - f1_score: 0.6889\n",
      "Epoch 4672/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8305 - f1_score: 0.6895\n",
      "Epoch 4672: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8305 - f1_score: 0.6894\n",
      "Epoch 4673/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8306 - f1_score: 0.6897\n",
      "Epoch 4673: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3807 - accuracy: 0.8305 - f1_score: 0.6897\n",
      "Epoch 4674/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8307 - f1_score: 0.6887\n",
      "Epoch 4674: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 4675/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8304 - f1_score: 0.6879\n",
      "Epoch 4675: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8305 - f1_score: 0.6879\n",
      "Epoch 4676/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 4676: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6881\n",
      "Epoch 4677/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8263 - f1_score: 0.6879\n",
      "Epoch 4677: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3874 - accuracy: 0.8263 - f1_score: 0.6879\n",
      "Epoch 4678/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8283 - f1_score: 0.6904\n",
      "Epoch 4678: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8284 - f1_score: 0.6904\n",
      "Epoch 4679/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8311 - f1_score: 0.6892\n",
      "Epoch 4679: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3809 - accuracy: 0.8311 - f1_score: 0.6892\n",
      "Epoch 4680/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8314 - f1_score: 0.6893\n",
      "Epoch 4680: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 1s 2ms/step - loss: 0.3796 - accuracy: 0.8314 - f1_score: 0.6892\n",
      "Epoch 4681/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8313 - f1_score: 0.6890\n",
      "Epoch 4681: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3803 - accuracy: 0.8312 - f1_score: 0.6890\n",
      "Epoch 4682/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 4682: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3808 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 4683/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 4683: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8299 - f1_score: 0.6889\n",
      "Epoch 4684/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 4684: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8311 - f1_score: 0.6898\n",
      "Epoch 4685/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6889\n",
      "Epoch 4685: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8300 - f1_score: 0.6889\n",
      "Epoch 4686/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6889\n",
      "Epoch 4686: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 4687/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6880\n",
      "Epoch 4687: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8300 - f1_score: 0.6881\n",
      "Epoch 4688/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6878\n",
      "Epoch 4688: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3866 - accuracy: 0.8268 - f1_score: 0.6878\n",
      "Epoch 4689/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 4689: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 4690/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6890\n",
      "Epoch 4690: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6890\n",
      "Epoch 4691/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8314 - f1_score: 0.6894\n",
      "Epoch 4691: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8314 - f1_score: 0.6894\n",
      "Epoch 4692/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8325 - f1_score: 0.6901\n",
      "Epoch 4692: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8325 - f1_score: 0.6901\n",
      "Epoch 4693/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8297 - f1_score: 0.6901\n",
      "Epoch 4693: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8296 - f1_score: 0.6900\n",
      "Epoch 4694/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8290 - f1_score: 0.6897\n",
      "Epoch 4694: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8290 - f1_score: 0.6897\n",
      "Epoch 4695/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8300 - f1_score: 0.6893\n",
      "Epoch 4695: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8301 - f1_score: 0.6894\n",
      "Epoch 4696/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8265 - f1_score: 0.6881\n",
      "Epoch 4696: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8264 - f1_score: 0.6881\n",
      "Epoch 4697/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8295 - f1_score: 0.6889\n",
      "Epoch 4697: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 4698/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8284 - f1_score: 0.6886\n",
      "Epoch 4698: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6886\n",
      "Epoch 4699/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8284 - f1_score: 0.6891\n",
      "Epoch 4699: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8284 - f1_score: 0.6891\n",
      "Epoch 4700/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8307 - f1_score: 0.6894\n",
      "Epoch 4700: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8307 - f1_score: 0.6896\n",
      "Epoch 4701/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8280 - f1_score: 0.6883\n",
      "Epoch 4701: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3842 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 4702/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8286 - f1_score: 0.6881\n",
      "Epoch 4702: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 4703/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8316 - f1_score: 0.6893\n",
      "Epoch 4703: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8315 - f1_score: 0.6893\n",
      "Epoch 4704/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 4704: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3801 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 4705/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8305 - f1_score: 0.6902\n",
      "Epoch 4705: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8304 - f1_score: 0.6900\n",
      "Epoch 4706/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8310 - f1_score: 0.6904\n",
      "Epoch 4706: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3790 - accuracy: 0.8310 - f1_score: 0.6903\n",
      "Epoch 4707/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 4707: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 4708/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8309 - f1_score: 0.6889\n",
      "Epoch 4708: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8310 - f1_score: 0.6890\n",
      "Epoch 4709/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8321 - f1_score: 0.6904\n",
      "Epoch 4709: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3781 - accuracy: 0.8320 - f1_score: 0.6905\n",
      "Epoch 4710/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6883\n",
      "Epoch 4710: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8306 - f1_score: 0.6884\n",
      "Epoch 4711/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6888\n",
      "Epoch 4711: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3821 - accuracy: 0.8299 - f1_score: 0.6887\n",
      "Epoch 4712/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 4712: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8298 - f1_score: 0.6888\n",
      "Epoch 4713/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8308 - f1_score: 0.6892\n",
      "Epoch 4713: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3805 - accuracy: 0.8308 - f1_score: 0.6892\n",
      "Epoch 4714/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3832 - accuracy: 0.8297 - f1_score: 0.6881\n",
      "Epoch 4714: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8296 - f1_score: 0.6880\n",
      "Epoch 4715/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3839 - accuracy: 0.8287 - f1_score: 0.6883\n",
      "Epoch 4715: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8287 - f1_score: 0.6884\n",
      "Epoch 4716/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 4716: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8288 - f1_score: 0.6875\n",
      "Epoch 4717/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8273 - f1_score: 0.6882\n",
      "Epoch 4717: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8274 - f1_score: 0.6881\n",
      "Epoch 4718/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8262 - f1_score: 0.6880\n",
      "Epoch 4718: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3863 - accuracy: 0.8262 - f1_score: 0.6880\n",
      "Epoch 4719/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 4719: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 4720/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8288 - f1_score: 0.6887\n",
      "Epoch 4720: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8288 - f1_score: 0.6887\n",
      "Epoch 4721/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8293 - f1_score: 0.6884\n",
      "Epoch 4721: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8293 - f1_score: 0.6885\n",
      "Epoch 4722/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 4722: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8309 - f1_score: 0.6885\n",
      "Epoch 4723/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6885\n",
      "Epoch 4723: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 4724/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8294 - f1_score: 0.6891\n",
      "Epoch 4724: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8295 - f1_score: 0.6892\n",
      "Epoch 4725/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 4725: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3797 - accuracy: 0.8310 - f1_score: 0.6887\n",
      "Epoch 4726/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8317 - f1_score: 0.6885\n",
      "Epoch 4726: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8317 - f1_score: 0.6885\n",
      "Epoch 4727/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 4727: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8294 - f1_score: 0.6882\n",
      "Epoch 4728/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8297 - f1_score: 0.6893\n",
      "Epoch 4728: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3819 - accuracy: 0.8297 - f1_score: 0.6891\n",
      "Epoch 4729/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8302 - f1_score: 0.6893\n",
      "Epoch 4729: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8303 - f1_score: 0.6891\n",
      "Epoch 4730/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4730: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4731/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8313 - f1_score: 0.6892\n",
      "Epoch 4731: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8313 - f1_score: 0.6892\n",
      "Epoch 4732/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6894\n",
      "Epoch 4732: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6894\n",
      "Epoch 4733/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6894\n",
      "Epoch 4733: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6895\n",
      "Epoch 4734/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8300 - f1_score: 0.6891\n",
      "Epoch 4734: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3812 - accuracy: 0.8301 - f1_score: 0.6891\n",
      "Epoch 4735/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6889\n",
      "Epoch 4735: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4736/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8298 - f1_score: 0.6876\n",
      "Epoch 4736: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8299 - f1_score: 0.6876\n",
      "Epoch 4737/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8312 - f1_score: 0.6884\n",
      "Epoch 4737: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3796 - accuracy: 0.8312 - f1_score: 0.6884\n",
      "Epoch 4738/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3774 - accuracy: 0.8320 - f1_score: 0.6889\n",
      "Epoch 4738: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3774 - accuracy: 0.8320 - f1_score: 0.6889\n",
      "Epoch 4739/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 4739: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 4740/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8314 - f1_score: 0.6898\n",
      "Epoch 4740: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8314 - f1_score: 0.6898\n",
      "Epoch 4741/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8325 - f1_score: 0.6897\n",
      "Epoch 4741: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8324 - f1_score: 0.6897\n",
      "Epoch 4742/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6873\n",
      "Epoch 4742: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8298 - f1_score: 0.6873\n",
      "Epoch 4743/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8290 - f1_score: 0.6884\n",
      "Epoch 4743: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 4744/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6895\n",
      "Epoch 4744: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8312 - f1_score: 0.6895\n",
      "Epoch 4745/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8318 - f1_score: 0.6898\n",
      "Epoch 4745: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8318 - f1_score: 0.6898\n",
      "Epoch 4746/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8317 - f1_score: 0.6897\n",
      "Epoch 4746: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3791 - accuracy: 0.8317 - f1_score: 0.6897\n",
      "Epoch 4747/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8305 - f1_score: 0.6890\n",
      "Epoch 4747: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6893\n",
      "Epoch 4748/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4748: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8309 - f1_score: 0.6890\n",
      "Epoch 4749/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8315 - f1_score: 0.6889\n",
      "Epoch 4749: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3799 - accuracy: 0.8315 - f1_score: 0.6888\n",
      "Epoch 4750/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8325 - f1_score: 0.6890\n",
      "Epoch 4750: accuracy did not improve from 0.83299\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3786 - accuracy: 0.8322 - f1_score: 0.6889\n",
      "Epoch 4751/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3776 - accuracy: 0.8335 - f1_score: 0.6893\n",
      "Epoch 4751: accuracy improved from 0.83299 to 0.83344, saving model to ./625-batch_size625\\weight-improvement2-4751-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3778 - accuracy: 0.8334 - f1_score: 0.6892\n",
      "Epoch 4752/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6892\n",
      "Epoch 4752: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6892\n",
      "Epoch 4753/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8310 - f1_score: 0.6901\n",
      "Epoch 4753: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8310 - f1_score: 0.6901\n",
      "Epoch 4754/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8301 - f1_score: 0.6904\n",
      "Epoch 4754: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8301 - f1_score: 0.6904\n",
      "Epoch 4755/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 4755: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8302 - f1_score: 0.6894\n",
      "Epoch 4756/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8316 - f1_score: 0.6901\n",
      "Epoch 4756: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3791 - accuracy: 0.8315 - f1_score: 0.6900\n",
      "Epoch 4757/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6896\n",
      "Epoch 4757: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8293 - f1_score: 0.6896\n",
      "Epoch 4758/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8319 - f1_score: 0.6905\n",
      "Epoch 4758: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8319 - f1_score: 0.6906\n",
      "Epoch 4759/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3764 - accuracy: 0.8326 - f1_score: 0.6901\n",
      "Epoch 4759: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3765 - accuracy: 0.8325 - f1_score: 0.6902\n",
      "Epoch 4760/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8309 - f1_score: 0.6900\n",
      "Epoch 4760: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8310 - f1_score: 0.6901\n",
      "Epoch 4761/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8319 - f1_score: 0.6895\n",
      "Epoch 4761: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8320 - f1_score: 0.6896\n",
      "Epoch 4762/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3775 - accuracy: 0.8331 - f1_score: 0.6903\n",
      "Epoch 4762: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3773 - accuracy: 0.8332 - f1_score: 0.6902\n",
      "Epoch 4763/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6901\n",
      "Epoch 4763: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6901\n",
      "Epoch 4764/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8302 - f1_score: 0.6902\n",
      "Epoch 4764: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 4s 8ms/step - loss: 0.3814 - accuracy: 0.8303 - f1_score: 0.6903\n",
      "Epoch 4765/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4765: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4766/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8288 - f1_score: 0.6889\n",
      "Epoch 4766: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6888\n",
      "Epoch 4767/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4767: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3816 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4768/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8299 - f1_score: 0.6897\n",
      "Epoch 4768: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8299 - f1_score: 0.6897\n",
      "Epoch 4769/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8300 - f1_score: 0.6900\n",
      "Epoch 4769: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8300 - f1_score: 0.6900\n",
      "Epoch 4770/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8318 - f1_score: 0.6901\n",
      "Epoch 4770: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3781 - accuracy: 0.8319 - f1_score: 0.6901\n",
      "Epoch 4771/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3774 - accuracy: 0.8321 - f1_score: 0.6898\n",
      "Epoch 4771: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3772 - accuracy: 0.8323 - f1_score: 0.6898\n",
      "Epoch 4772/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8304 - f1_score: 0.6896\n",
      "Epoch 4772: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8304 - f1_score: 0.6896\n",
      "Epoch 4773/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3841 - accuracy: 0.8288 - f1_score: 0.6886\n",
      "Epoch 4773: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 4774/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 4774: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 4775/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8295 - f1_score: 0.6890\n",
      "Epoch 4775: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3829 - accuracy: 0.8294 - f1_score: 0.6889\n",
      "Epoch 4776/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8316 - f1_score: 0.6896\n",
      "Epoch 4776: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8317 - f1_score: 0.6896\n",
      "Epoch 4777/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8328 - f1_score: 0.6900\n",
      "Epoch 4777: accuracy did not improve from 0.83344\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3776 - accuracy: 0.8328 - f1_score: 0.6900\n",
      "Epoch 4778/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3773 - accuracy: 0.8336 - f1_score: 0.6897\n",
      "Epoch 4778: accuracy improved from 0.83344 to 0.83360, saving model to ./625-batch_size625\\weight-improvement2-4778-0.83-0.69.hdf5\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3773 - accuracy: 0.8336 - f1_score: 0.6895\n",
      "Epoch 4779/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8317 - f1_score: 0.6897\n",
      "Epoch 4779: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3786 - accuracy: 0.8318 - f1_score: 0.6897\n",
      "Epoch 4780/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3779 - accuracy: 0.8314 - f1_score: 0.6901\n",
      "Epoch 4780: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3777 - accuracy: 0.8315 - f1_score: 0.6901\n",
      "Epoch 4781/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8318 - f1_score: 0.6888\n",
      "Epoch 4781: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8317 - f1_score: 0.6888\n",
      "Epoch 4782/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6897\n",
      "Epoch 4782: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8305 - f1_score: 0.6897\n",
      "Epoch 4783/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8305 - f1_score: 0.6887\n",
      "Epoch 4783: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8304 - f1_score: 0.6886\n",
      "Epoch 4784/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8271 - f1_score: 0.6879\n",
      "Epoch 4784: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3853 - accuracy: 0.8270 - f1_score: 0.6880\n",
      "Epoch 4785/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8289 - f1_score: 0.6882\n",
      "Epoch 4785: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 4786/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8314 - f1_score: 0.6886\n",
      "Epoch 4786: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8314 - f1_score: 0.6886\n",
      "Epoch 4787/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8312 - f1_score: 0.6892\n",
      "Epoch 4787: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8314 - f1_score: 0.6893\n",
      "Epoch 4788/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 4788: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8312 - f1_score: 0.6885\n",
      "Epoch 4789/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8306 - f1_score: 0.6876\n",
      "Epoch 4789: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8304 - f1_score: 0.6876\n",
      "Epoch 4790/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8317 - f1_score: 0.6877\n",
      "Epoch 4790: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8317 - f1_score: 0.6877\n",
      "Epoch 4791/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 4791: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8308 - f1_score: 0.6887\n",
      "Epoch 4792/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8307 - f1_score: 0.6888\n",
      "Epoch 4792: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6887\n",
      "Epoch 4793/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8314 - f1_score: 0.6890\n",
      "Epoch 4793: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8314 - f1_score: 0.6890\n",
      "Epoch 4794/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8308 - f1_score: 0.6882\n",
      "Epoch 4794: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8308 - f1_score: 0.6883\n",
      "Epoch 4795/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6887\n",
      "Epoch 4795: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 4796/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8306 - f1_score: 0.6892\n",
      "Epoch 4796: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 6ms/step - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6894\n",
      "Epoch 4797/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8310 - f1_score: 0.6900\n",
      "Epoch 4797: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8310 - f1_score: 0.6900\n",
      "Epoch 4798/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8307 - f1_score: 0.6894\n",
      "Epoch 4798: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8307 - f1_score: 0.6895\n",
      "Epoch 4799/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8309 - f1_score: 0.6897\n",
      "Epoch 4799: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8309 - f1_score: 0.6897\n",
      "Epoch 4800/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8315 - f1_score: 0.6891\n",
      "Epoch 4800: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8315 - f1_score: 0.6891\n",
      "Epoch 4801/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8311 - f1_score: 0.6892\n",
      "Epoch 4801: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8312 - f1_score: 0.6894\n",
      "Epoch 4802/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 4802: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8291 - f1_score: 0.6887\n",
      "Epoch 4803/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 4803: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3815 - accuracy: 0.8304 - f1_score: 0.6884\n",
      "Epoch 4804/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8315 - f1_score: 0.6895\n",
      "Epoch 4804: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3784 - accuracy: 0.8316 - f1_score: 0.6894\n",
      "Epoch 4805/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8306 - f1_score: 0.6896\n",
      "Epoch 4805: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8306 - f1_score: 0.6897\n",
      "Epoch 4806/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8313 - f1_score: 0.6903\n",
      "Epoch 4806: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8314 - f1_score: 0.6904\n",
      "Epoch 4807/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8278 - f1_score: 0.6896\n",
      "Epoch 4807: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8277 - f1_score: 0.6896\n",
      "Epoch 4808/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8307 - f1_score: 0.6895\n",
      "Epoch 4808: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8307 - f1_score: 0.6896\n",
      "Epoch 4809/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8314 - f1_score: 0.6889\n",
      "Epoch 4809: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3797 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 4810/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8311 - f1_score: 0.6898\n",
      "Epoch 4810: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8311 - f1_score: 0.6898\n",
      "Epoch 4811/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8324 - f1_score: 0.6893\n",
      "Epoch 4811: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8324 - f1_score: 0.6894\n",
      "Epoch 4812/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8314 - f1_score: 0.6894\n",
      "Epoch 4812: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6894\n",
      "Epoch 4813/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3772 - accuracy: 0.8322 - f1_score: 0.6900\n",
      "Epoch 4813: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3772 - accuracy: 0.8322 - f1_score: 0.6900\n",
      "Epoch 4814/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8315 - f1_score: 0.6892\n",
      "Epoch 4814: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8315 - f1_score: 0.6892\n",
      "Epoch 4815/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8325 - f1_score: 0.6890\n",
      "Epoch 4815: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8325 - f1_score: 0.6891\n",
      "Epoch 4816/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8307 - f1_score: 0.6893\n",
      "Epoch 4816: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6892\n",
      "Epoch 4817/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6883\n",
      "Epoch 4817: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 4818/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8292 - f1_score: 0.6892\n",
      "Epoch 4818: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8293 - f1_score: 0.6891\n",
      "Epoch 4819/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6900\n",
      "Epoch 4819: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8306 - f1_score: 0.6899\n",
      "Epoch 4820/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8298 - f1_score: 0.6890\n",
      "Epoch 4820: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8297 - f1_score: 0.6890\n",
      "Epoch 4821/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8300 - f1_score: 0.6893\n",
      "Epoch 4821: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8300 - f1_score: 0.6893\n",
      "Epoch 4822/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.8324 - f1_score: 0.6895\n",
      "Epoch 4822: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8324 - f1_score: 0.6894\n",
      "Epoch 4823/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8313 - f1_score: 0.6895\n",
      "Epoch 4823: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8312 - f1_score: 0.6894\n",
      "Epoch 4824/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8329 - f1_score: 0.6893\n",
      "Epoch 4824: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3775 - accuracy: 0.8329 - f1_score: 0.6893\n",
      "Epoch 4825/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4825: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4826/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6881\n",
      "Epoch 4826: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8291 - f1_score: 0.6882\n",
      "Epoch 4827/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8289 - f1_score: 0.6887\n",
      "Epoch 4827: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8290 - f1_score: 0.6887\n",
      "Epoch 4828/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6884\n",
      "Epoch 4828: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8302 - f1_score: 0.6883\n",
      "Epoch 4829/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8314 - f1_score: 0.6887\n",
      "Epoch 4829: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8314 - f1_score: 0.6886\n",
      "Epoch 4830/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8317 - f1_score: 0.6890\n",
      "Epoch 4830: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8317 - f1_score: 0.6890\n",
      "Epoch 4831/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8323 - f1_score: 0.6893\n",
      "Epoch 4831: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3781 - accuracy: 0.8322 - f1_score: 0.6894\n",
      "Epoch 4832/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8318 - f1_score: 0.6898\n",
      "Epoch 4832: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3781 - accuracy: 0.8318 - f1_score: 0.6897\n",
      "Epoch 4833/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8318 - f1_score: 0.6891\n",
      "Epoch 4833: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8318 - f1_score: 0.6891\n",
      "Epoch 4834/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6893\n",
      "Epoch 4834: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8306 - f1_score: 0.6893\n",
      "Epoch 4835/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 4835: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8312 - f1_score: 0.6886\n",
      "Epoch 4836/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8312 - f1_score: 0.6892\n",
      "Epoch 4836: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8313 - f1_score: 0.6892\n",
      "Epoch 4837/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8311 - f1_score: 0.6896\n",
      "Epoch 4837: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8310 - f1_score: 0.6894\n",
      "Epoch 4838/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8310 - f1_score: 0.6896\n",
      "Epoch 4838: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8310 - f1_score: 0.6895\n",
      "Epoch 4839/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8313 - f1_score: 0.6886\n",
      "Epoch 4839: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8312 - f1_score: 0.6887\n",
      "Epoch 4840/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8301 - f1_score: 0.6871\n",
      "Epoch 4840: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8302 - f1_score: 0.6871\n",
      "Epoch 4841/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8293 - f1_score: 0.6880\n",
      "Epoch 4841: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8293 - f1_score: 0.6880\n",
      "Epoch 4842/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8319 - f1_score: 0.6893\n",
      "Epoch 4842: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3797 - accuracy: 0.8318 - f1_score: 0.6892\n",
      "Epoch 4843/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 4843: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 4844/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6892\n",
      "Epoch 4844: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8296 - f1_score: 0.6892\n",
      "Epoch 4845/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8297 - f1_score: 0.6882\n",
      "Epoch 4845: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8298 - f1_score: 0.6883\n",
      "Epoch 4846/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8292 - f1_score: 0.6879\n",
      "Epoch 4846: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8290 - f1_score: 0.6880\n",
      "Epoch 4847/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8302 - f1_score: 0.6889\n",
      "Epoch 4847: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8301 - f1_score: 0.6891\n",
      "Epoch 4848/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8294 - f1_score: 0.6901\n",
      "Epoch 4848: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8294 - f1_score: 0.6901\n",
      "Epoch 4849/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 4849: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8285 - f1_score: 0.6879\n",
      "Epoch 4850/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8289 - f1_score: 0.6874\n",
      "Epoch 4850: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3841 - accuracy: 0.8292 - f1_score: 0.6875\n",
      "Epoch 4851/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6879\n",
      "Epoch 4851: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8296 - f1_score: 0.6881\n",
      "Epoch 4852/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8302 - f1_score: 0.6878\n",
      "Epoch 4852: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6879\n",
      "Epoch 4853/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8292 - f1_score: 0.6893\n",
      "Epoch 4853: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8292 - f1_score: 0.6893\n",
      "Epoch 4854/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 4854: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8290 - f1_score: 0.6878\n",
      "Epoch 4855/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8288 - f1_score: 0.6887\n",
      "Epoch 4855: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3834 - accuracy: 0.8289 - f1_score: 0.6889\n",
      "Epoch 4856/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 4856: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 4857/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 4857: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8293 - f1_score: 0.6885\n",
      "Epoch 4858/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8272 - f1_score: 0.6886\n",
      "Epoch 4858: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8273 - f1_score: 0.6885\n",
      "Epoch 4859/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8301 - f1_score: 0.6888\n",
      "Epoch 4859: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8300 - f1_score: 0.6887\n",
      "Epoch 4860/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 4860: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8306 - f1_score: 0.6882\n",
      "Epoch 4861/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8290 - f1_score: 0.6891\n",
      "Epoch 4861: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8290 - f1_score: 0.6891\n",
      "Epoch 4862/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3823 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 4862: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3823 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 4863/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8298 - f1_score: 0.6878\n",
      "Epoch 4863: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8298 - f1_score: 0.6877\n",
      "Epoch 4864/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8285 - f1_score: 0.6878\n",
      "Epoch 4864: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3831 - accuracy: 0.8286 - f1_score: 0.6878\n",
      "Epoch 4865/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6880\n",
      "Epoch 4865: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6880\n",
      "Epoch 4866/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6891\n",
      "Epoch 4866: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8301 - f1_score: 0.6891\n",
      "Epoch 4867/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 4867: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 4868/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8325 - f1_score: 0.6889\n",
      "Epoch 4868: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3775 - accuracy: 0.8325 - f1_score: 0.6889\n",
      "Epoch 4869/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8294 - f1_score: 0.6884\n",
      "Epoch 4869: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3823 - accuracy: 0.8295 - f1_score: 0.6884\n",
      "Epoch 4870/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8312 - f1_score: 0.6879\n",
      "Epoch 4870: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8312 - f1_score: 0.6877\n",
      "Epoch 4871/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 4871: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3830 - accuracy: 0.8287 - f1_score: 0.6882\n",
      "Epoch 4872/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8299 - f1_score: 0.6886\n",
      "Epoch 4872: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3802 - accuracy: 0.8300 - f1_score: 0.6886\n",
      "Epoch 4873/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 4873: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 4874/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8290 - f1_score: 0.6886\n",
      "Epoch 4874: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8289 - f1_score: 0.6886\n",
      "Epoch 4875/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6885\n",
      "Epoch 4875: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 4876/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8304 - f1_score: 0.6885\n",
      "Epoch 4876: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8303 - f1_score: 0.6885\n",
      "Epoch 4877/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4877: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8308 - f1_score: 0.6890\n",
      "Epoch 4878/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8313 - f1_score: 0.6892\n",
      "Epoch 4878: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3796 - accuracy: 0.8314 - f1_score: 0.6892\n",
      "Epoch 4879/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6895\n",
      "Epoch 4879: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6895\n",
      "Epoch 4880/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8304 - f1_score: 0.6890\n",
      "Epoch 4880: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8303 - f1_score: 0.6889\n",
      "Epoch 4881/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8293 - f1_score: 0.6887\n",
      "Epoch 4881: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8292 - f1_score: 0.6887\n",
      "Epoch 4882/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8310 - f1_score: 0.6898\n",
      "Epoch 4882: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8310 - f1_score: 0.6897\n",
      "Epoch 4883/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8297 - f1_score: 0.6888\n",
      "Epoch 4883: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8295 - f1_score: 0.6887\n",
      "Epoch 4884/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8291 - f1_score: 0.6884\n",
      "Epoch 4884: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8293 - f1_score: 0.6886\n",
      "Epoch 4885/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8308 - f1_score: 0.6896\n",
      "Epoch 4885: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3794 - accuracy: 0.8308 - f1_score: 0.6896\n",
      "Epoch 4886/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3773 - accuracy: 0.8324 - f1_score: 0.6898\n",
      "Epoch 4886: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3773 - accuracy: 0.8324 - f1_score: 0.6898\n",
      "Epoch 4887/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8321 - f1_score: 0.6893\n",
      "Epoch 4887: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8321 - f1_score: 0.6893\n",
      "Epoch 4888/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8309 - f1_score: 0.6881\n",
      "Epoch 4888: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3795 - accuracy: 0.8308 - f1_score: 0.6880\n",
      "Epoch 4889/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3806 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 4889: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8307 - f1_score: 0.6889\n",
      "Epoch 4890/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6895\n",
      "Epoch 4890: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6895\n",
      "Epoch 4891/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8303 - f1_score: 0.6888\n",
      "Epoch 4891: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8303 - f1_score: 0.6887\n",
      "Epoch 4892/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 4892: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3818 - accuracy: 0.8300 - f1_score: 0.6882\n",
      "Epoch 4893/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8300 - f1_score: 0.6875\n",
      "Epoch 4893: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3826 - accuracy: 0.8301 - f1_score: 0.6876\n",
      "Epoch 4894/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6893\n",
      "Epoch 4894: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8300 - f1_score: 0.6893\n",
      "Epoch 4895/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8283 - f1_score: 0.6876\n",
      "Epoch 4895: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8282 - f1_score: 0.6876\n",
      "Epoch 4896/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8278 - f1_score: 0.6880\n",
      "Epoch 4896: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8277 - f1_score: 0.6880\n",
      "Epoch 4897/5000\n",
      "444/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 4897: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6884\n",
      "Epoch 4898/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4898: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3809 - accuracy: 0.8300 - f1_score: 0.6890\n",
      "Epoch 4899/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3799 - accuracy: 0.8314 - f1_score: 0.6888\n",
      "Epoch 4899: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3800 - accuracy: 0.8314 - f1_score: 0.6887\n",
      "Epoch 4900/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8295 - f1_score: 0.6870\n",
      "Epoch 4900: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8295 - f1_score: 0.6870\n",
      "Epoch 4901/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 4901: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8297 - f1_score: 0.6887\n",
      "Epoch 4902/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8283 - f1_score: 0.6888\n",
      "Epoch 4902: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3836 - accuracy: 0.8283 - f1_score: 0.6889\n",
      "Epoch 4903/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8316 - f1_score: 0.6887\n",
      "Epoch 4903: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8316 - f1_score: 0.6886\n",
      "Epoch 4904/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8285 - f1_score: 0.6872\n",
      "Epoch 4904: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3838 - accuracy: 0.8286 - f1_score: 0.6872\n",
      "Epoch 4905/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8315 - f1_score: 0.6881\n",
      "Epoch 4905: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8314 - f1_score: 0.6882\n",
      "Epoch 4906/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3775 - accuracy: 0.8331 - f1_score: 0.6895\n",
      "Epoch 4906: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3775 - accuracy: 0.8330 - f1_score: 0.6895\n",
      "Epoch 4907/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 4907: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8294 - f1_score: 0.6885\n",
      "Epoch 4908/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8306 - f1_score: 0.6896\n",
      "Epoch 4908: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3800 - accuracy: 0.8306 - f1_score: 0.6896\n",
      "Epoch 4909/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8296 - f1_score: 0.6890\n",
      "Epoch 4909: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3828 - accuracy: 0.8296 - f1_score: 0.6889\n",
      "Epoch 4910/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8292 - f1_score: 0.6882\n",
      "Epoch 4910: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8293 - f1_score: 0.6883\n",
      "Epoch 4911/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8308 - f1_score: 0.6900\n",
      "Epoch 4911: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8308 - f1_score: 0.6901\n",
      "Epoch 4912/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8314 - f1_score: 0.6900\n",
      "Epoch 4912: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3793 - accuracy: 0.8315 - f1_score: 0.6901\n",
      "Epoch 4913/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 4913: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 4914/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8302 - f1_score: 0.6897\n",
      "Epoch 4914: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8303 - f1_score: 0.6896\n",
      "Epoch 4915/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8310 - f1_score: 0.6892\n",
      "Epoch 4915: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8311 - f1_score: 0.6891\n",
      "Epoch 4916/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3776 - accuracy: 0.8327 - f1_score: 0.6890\n",
      "Epoch 4916: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3775 - accuracy: 0.8327 - f1_score: 0.6890\n",
      "Epoch 4917/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8313 - f1_score: 0.6884\n",
      "Epoch 4917: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3801 - accuracy: 0.8313 - f1_score: 0.6885\n",
      "Epoch 4918/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8321 - f1_score: 0.6893\n",
      "Epoch 4918: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3786 - accuracy: 0.8321 - f1_score: 0.6894\n",
      "Epoch 4919/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8298 - f1_score: 0.6879\n",
      "Epoch 4919: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3832 - accuracy: 0.8297 - f1_score: 0.6878\n",
      "Epoch 4920/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.8319 - f1_score: 0.6879\n",
      "Epoch 4920: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8319 - f1_score: 0.6879\n",
      "Epoch 4921/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3772 - accuracy: 0.8322 - f1_score: 0.6891\n",
      "Epoch 4921: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3772 - accuracy: 0.8323 - f1_score: 0.6891\n",
      "Epoch 4922/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.8335 - f1_score: 0.6889\n",
      "Epoch 4922: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3778 - accuracy: 0.8335 - f1_score: 0.6889\n",
      "Epoch 4923/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3767 - accuracy: 0.8333 - f1_score: 0.6898\n",
      "Epoch 4923: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3767 - accuracy: 0.8333 - f1_score: 0.6898\n",
      "Epoch 4924/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8321 - f1_score: 0.6893\n",
      "Epoch 4924: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3786 - accuracy: 0.8321 - f1_score: 0.6892\n",
      "Epoch 4925/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8305 - f1_score: 0.6890\n",
      "Epoch 4925: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8304 - f1_score: 0.6889\n",
      "Epoch 4926/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8305 - f1_score: 0.6896\n",
      "Epoch 4926: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8305 - f1_score: 0.6896\n",
      "Epoch 4927/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8315 - f1_score: 0.6894\n",
      "Epoch 4927: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8315 - f1_score: 0.6895\n",
      "Epoch 4928/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6893\n",
      "Epoch 4928: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8300 - f1_score: 0.6894\n",
      "Epoch 4929/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8280 - f1_score: 0.6883\n",
      "Epoch 4929: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3857 - accuracy: 0.8281 - f1_score: 0.6883\n",
      "Epoch 4930/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8286 - f1_score: 0.6901\n",
      "Epoch 4930: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3837 - accuracy: 0.8285 - f1_score: 0.6902\n",
      "Epoch 4931/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8305 - f1_score: 0.6906\n",
      "Epoch 4931: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8305 - f1_score: 0.6906\n",
      "Epoch 4932/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3819 - accuracy: 0.8306 - f1_score: 0.6891\n",
      "Epoch 4932: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8308 - f1_score: 0.6891\n",
      "Epoch 4933/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8307 - f1_score: 0.6894\n",
      "Epoch 4933: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3812 - accuracy: 0.8309 - f1_score: 0.6894\n",
      "Epoch 4934/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8283 - f1_score: 0.6874\n",
      "Epoch 4934: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3848 - accuracy: 0.8283 - f1_score: 0.6875\n",
      "Epoch 4935/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6884\n",
      "Epoch 4935: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3845 - accuracy: 0.8284 - f1_score: 0.6885\n",
      "Epoch 4936/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 4936: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3850 - accuracy: 0.8290 - f1_score: 0.6882\n",
      "Epoch 4937/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3854 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 4937: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3852 - accuracy: 0.8279 - f1_score: 0.6878\n",
      "Epoch 4938/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8300 - f1_score: 0.6860\n",
      "Epoch 4938: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3844 - accuracy: 0.8299 - f1_score: 0.6860\n",
      "Epoch 4939/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8306 - f1_score: 0.6881\n",
      "Epoch 4939: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8307 - f1_score: 0.6880\n",
      "Epoch 4940/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3810 - accuracy: 0.8309 - f1_score: 0.6883\n",
      "Epoch 4940: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8310 - f1_score: 0.6883\n",
      "Epoch 4941/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 4941: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3804 - accuracy: 0.8309 - f1_score: 0.6887\n",
      "Epoch 4942/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8303 - f1_score: 0.6890\n",
      "Epoch 4942: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3810 - accuracy: 0.8303 - f1_score: 0.6889\n",
      "Epoch 4943/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8308 - f1_score: 0.6883\n",
      "Epoch 4943: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3813 - accuracy: 0.8309 - f1_score: 0.6883\n",
      "Epoch 4944/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3800 - accuracy: 0.8311 - f1_score: 0.6881\n",
      "Epoch 4944: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3800 - accuracy: 0.8311 - f1_score: 0.6882\n",
      "Epoch 4945/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 4945: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3827 - accuracy: 0.8299 - f1_score: 0.6882\n",
      "Epoch 4946/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8297 - f1_score: 0.6882\n",
      "Epoch 4946: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8296 - f1_score: 0.6883\n",
      "Epoch 4947/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8295 - f1_score: 0.6876\n",
      "Epoch 4947: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8295 - f1_score: 0.6877\n",
      "Epoch 4948/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8299 - f1_score: 0.6869\n",
      "Epoch 4948: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8298 - f1_score: 0.6869\n",
      "Epoch 4949/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.8309 - f1_score: 0.6884\n",
      "Epoch 4949: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8309 - f1_score: 0.6884\n",
      "Epoch 4950/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8311 - f1_score: 0.6887\n",
      "Epoch 4950: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8311 - f1_score: 0.6886\n",
      "Epoch 4951/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8318 - f1_score: 0.6893\n",
      "Epoch 4951: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3799 - accuracy: 0.8318 - f1_score: 0.6893\n",
      "Epoch 4952/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 4952: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8314 - f1_score: 0.6891\n",
      "Epoch 4953/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8294 - f1_score: 0.6888\n",
      "Epoch 4953: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3819 - accuracy: 0.8294 - f1_score: 0.6887\n",
      "Epoch 4954/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6884\n",
      "Epoch 4954: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3815 - accuracy: 0.8301 - f1_score: 0.6885\n",
      "Epoch 4955/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3835 - accuracy: 0.8284 - f1_score: 0.6890\n",
      "Epoch 4955: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3835 - accuracy: 0.8283 - f1_score: 0.6889\n",
      "Epoch 4956/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.8311 - f1_score: 0.6896\n",
      "Epoch 4956: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8311 - f1_score: 0.6896\n",
      "Epoch 4957/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8321 - f1_score: 0.6897\n",
      "Epoch 4957: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3788 - accuracy: 0.8322 - f1_score: 0.6896\n",
      "Epoch 4958/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.8271 - f1_score: 0.6878\n",
      "Epoch 4958: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3856 - accuracy: 0.8271 - f1_score: 0.6878\n",
      "Epoch 4959/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8304 - f1_score: 0.6888\n",
      "Epoch 4959: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3807 - accuracy: 0.8305 - f1_score: 0.6888\n",
      "Epoch 4960/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3848 - accuracy: 0.8276 - f1_score: 0.6877\n",
      "Epoch 4960: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3846 - accuracy: 0.8278 - f1_score: 0.6876\n",
      "Epoch 4961/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 4961: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3824 - accuracy: 0.8295 - f1_score: 0.6882\n",
      "Epoch 4962/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8284 - f1_score: 0.6878\n",
      "Epoch 4962: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3832 - accuracy: 0.8285 - f1_score: 0.6877\n",
      "Epoch 4963/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8315 - f1_score: 0.6886\n",
      "Epoch 4963: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3787 - accuracy: 0.8315 - f1_score: 0.6886\n",
      "Epoch 4964/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8317 - f1_score: 0.6894\n",
      "Epoch 4964: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3791 - accuracy: 0.8317 - f1_score: 0.6894\n",
      "Epoch 4965/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3794 - accuracy: 0.8319 - f1_score: 0.6891\n",
      "Epoch 4965: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3793 - accuracy: 0.8319 - f1_score: 0.6891\n",
      "Epoch 4966/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8315 - f1_score: 0.6888\n",
      "Epoch 4966: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3791 - accuracy: 0.8316 - f1_score: 0.6889\n",
      "Epoch 4967/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8313 - f1_score: 0.6890\n",
      "Epoch 4967: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8313 - f1_score: 0.6890\n",
      "Epoch 4968/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8313 - f1_score: 0.6892\n",
      "Epoch 4968: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 8ms/step - loss: 0.3797 - accuracy: 0.8313 - f1_score: 0.6891\n",
      "Epoch 4969/5000\n",
      "447/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8313 - f1_score: 0.6880\n",
      "Epoch 4969: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8313 - f1_score: 0.6882\n",
      "Epoch 4970/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8300 - f1_score: 0.6898\n",
      "Epoch 4970: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3797 - accuracy: 0.8301 - f1_score: 0.6898\n",
      "Epoch 4971/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8314 - f1_score: 0.6888\n",
      "Epoch 4971: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8313 - f1_score: 0.6888\n",
      "Epoch 4972/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8313 - f1_score: 0.6887\n",
      "Epoch 4972: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3802 - accuracy: 0.8313 - f1_score: 0.6887\n",
      "Epoch 4973/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8321 - f1_score: 0.6895\n",
      "Epoch 4973: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3785 - accuracy: 0.8322 - f1_score: 0.6895\n",
      "Epoch 4974/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6892\n",
      "Epoch 4974: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - f1_score: 0.6892\n",
      "Epoch 4975/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3798 - accuracy: 0.8312 - f1_score: 0.6884\n",
      "Epoch 4975: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3798 - accuracy: 0.8311 - f1_score: 0.6885\n",
      "Epoch 4976/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 4976: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3817 - accuracy: 0.8297 - f1_score: 0.6886\n",
      "Epoch 4977/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8324 - f1_score: 0.6898\n",
      "Epoch 4977: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8324 - f1_score: 0.6898\n",
      "Epoch 4978/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 4978: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8307 - f1_score: 0.6884\n",
      "Epoch 4979/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 4979: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8295 - f1_score: 0.6883\n",
      "Epoch 4980/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8290 - f1_score: 0.6879\n",
      "Epoch 4980: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3833 - accuracy: 0.8291 - f1_score: 0.6879\n",
      "Epoch 4981/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8309 - f1_score: 0.6878\n",
      "Epoch 4981: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3808 - accuracy: 0.8309 - f1_score: 0.6878\n",
      "Epoch 4982/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8309 - f1_score: 0.6886\n",
      "Epoch 4982: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3822 - accuracy: 0.8310 - f1_score: 0.6885\n",
      "Epoch 4983/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 4983: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3792 - accuracy: 0.8313 - f1_score: 0.6889\n",
      "Epoch 4984/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3805 - accuracy: 0.8312 - f1_score: 0.6871\n",
      "Epoch 4984: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3805 - accuracy: 0.8312 - f1_score: 0.6872\n",
      "Epoch 4985/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8291 - f1_score: 0.6875\n",
      "Epoch 4985: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3842 - accuracy: 0.8289 - f1_score: 0.6876\n",
      "Epoch 4986/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 4986: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3820 - accuracy: 0.8291 - f1_score: 0.6885\n",
      "Epoch 4987/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8314 - f1_score: 0.6882\n",
      "Epoch 4987: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8314 - f1_score: 0.6882\n",
      "Epoch 4988/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3780 - accuracy: 0.8325 - f1_score: 0.6889\n",
      "Epoch 4988: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3779 - accuracy: 0.8326 - f1_score: 0.6890\n",
      "Epoch 4989/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8328 - f1_score: 0.6892\n",
      "Epoch 4989: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3783 - accuracy: 0.8327 - f1_score: 0.6893\n",
      "Epoch 4990/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8318 - f1_score: 0.6890\n",
      "Epoch 4990: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3785 - accuracy: 0.8319 - f1_score: 0.6891\n",
      "Epoch 4991/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8303 - f1_score: 0.6881\n",
      "Epoch 4991: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8303 - f1_score: 0.6880\n",
      "Epoch 4992/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3785 - accuracy: 0.8322 - f1_score: 0.6890\n",
      "Epoch 4992: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3785 - accuracy: 0.8322 - f1_score: 0.6889\n",
      "Epoch 4993/5000\n",
      "445/452 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.8321 - f1_score: 0.6889\n",
      "Epoch 4993: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3780 - accuracy: 0.8321 - f1_score: 0.6889\n",
      "Epoch 4994/5000\n",
      "446/452 [============================>.] - ETA: 0s - loss: 0.3784 - accuracy: 0.8322 - f1_score: 0.6883\n",
      "Epoch 4994: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3783 - accuracy: 0.8321 - f1_score: 0.6883\n",
      "Epoch 4995/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6890\n",
      "Epoch 4995: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3804 - accuracy: 0.8306 - f1_score: 0.6890\n",
      "Epoch 4996/5000\n",
      "450/452 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.8303 - f1_score: 0.6884\n",
      "Epoch 4996: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3803 - accuracy: 0.8303 - f1_score: 0.6885\n",
      "Epoch 4997/5000\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8313 - f1_score: 0.6902\n",
      "Epoch 4997: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3789 - accuracy: 0.8313 - f1_score: 0.6902\n",
      "Epoch 4998/5000\n",
      "448/452 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8300 - f1_score: 0.6875\n",
      "Epoch 4998: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3825 - accuracy: 0.8300 - f1_score: 0.6874\n",
      "Epoch 4999/5000\n",
      "449/452 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6886\n",
      "Epoch 4999: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3814 - accuracy: 0.8302 - f1_score: 0.6887\n",
      "Epoch 5000/5000\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8307 - f1_score: 0.6886\n",
      "Epoch 5000: accuracy did not improve from 0.83360\n",
      "452/452 [==============================] - 3s 7ms/step - loss: 0.3811 - accuracy: 0.8308 - f1_score: 0.6886\n"
     ]
    }
   ],
   "source": [
    "batch_size=625\n",
    "filepath=\"./625-batch_size\" + str(batch_size) + \"/weight-improvement2-{epoch}-{accuracy:.2f}-{f1_score:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5000, batch_size=batch_size, callbacks=callbacks_list)\n",
    "model.save_weights(\"./batch_size-\" + str(batch_size) + \"/6000.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2207/2207 - 7s - loss: 0.3384 - accuracy: 0.8543 - f1_score: 0.6858 - 7s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3384332060813904, 0.8543389439582825, 0.6858328580856323]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"625-batch_size625/weight-improvement2-4778-0.83-0.69.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 428)\n",
      "(428,)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 431)\n",
      "(431,)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 429)\n",
      "(429,)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(257, 430)\n",
      "(430,)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_folder = \"audio/audio\"  # Replace with the path to your audio files folder\n",
    "threshold = 0.5\n",
    "\n",
    "n_fft = 512  # Number of points in each FFT\n",
    "hop_length = n_fft  # Hop size\n",
    "fft_len = n_fft//2 + 1  # Number of Mel bands\n",
    "window = \"hann\"  # Window function\n",
    "stft_taken = fft_len//4\n",
    "\n",
    "# Iterate through audio files in the folder\n",
    "for filename in sorted(os.listdir(audio_folder)):\n",
    "    audio_path = os.path.join(audio_folder, filename)\n",
    "\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    if sr != 22050:\n",
    "        print(sr)\n",
    "\n",
    "    stft = np.abs(librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, window=window))\n",
    "    flux = librosa.onset.onset_strength(y=y, sr=sr, n_fft=n_fft, hop_length = hop_length)\n",
    "    flux = flux\n",
    "    stft_new = stft[:stft_taken,:]\n",
    "    #mfcc = librosa.feature.mfcc(y=y, n_mfcc=13, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    stft_new = stft_new.T\n",
    "    print(stft.shape)\n",
    "    print(flux.shape)\n",
    "    features_test = np.column_stack((stft_new, flux*4))\n",
    "    print(features_test.shape)\n",
    "    prediction_test = model.predict(features_test)\n",
    "    file = filename.split(\".\")[0]\n",
    "    csv_file = \"audio/onsets/\" + file + \".csv\"\n",
    "    # Supress and amplify predictions to 0 and 1\n",
    "    prediction_test[prediction_test >= threshold] = 1\n",
    "    prediction_test[prediction_test < threshold] = 0\n",
    "    prediction_test.astype(int)\n",
    "\n",
    "    #Generate segments of speech from the predictions for each small segment\n",
    "    previous_frame = 0\n",
    "    stepLength = 512/22050\n",
    "\n",
    "    data = [[\"Stroke\", \"Index\"]]\n",
    "\n",
    "    for i in range(len(prediction_test)):\n",
    "\n",
    "        current_time = i*stepLength\n",
    "        current_frame = prediction_test[i]\n",
    "        #If previous frame has no stroke\n",
    "        #and current frame has stroke\n",
    "        if previous_frame == 0 and current_frame != 0:\n",
    "            data.append([current_time, 1])\n",
    "\n",
    "        previous_frame = current_frame\n",
    "\n",
    "\n",
    "    # Open the CSV file in write mode\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the data to the CSV file row by row\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "prediction_test = model.predict(test_features)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/14 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n",
      " 1/14 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(430, 1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(430, 1)\n",
      "(430, 65)\n",
      " 1/14 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(428, 1)\n",
      "(428, 1)\n",
      "(428, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(431, 1)\n",
      "(431, 1)\n",
      "(431, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n",
      "14/14 [==============================] - 0s 2ms/step\n",
      "(429, 1)\n",
      "(429, 1)\n",
      "(429, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "(430, 1)\n",
      "(430, 1)\n",
      "(430, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_folder = \"audio/audio\"  # Replace with the path to your audio files folder\n",
    "threshold = 0.5\n",
    "\n",
    "n_fft = 512  # Number of points in each FFT\n",
    "hop_length = n_fft  # Hop size\n",
    "fft_len = n_fft//2 + 1  # Number of Mel bands\n",
    "window = \"hann\"  # Window function\n",
    "stft_taken = fft_len//4\n",
    "\n",
    "# Iterate through audio files in the folder\n",
    "for filename in sorted(os.listdir(audio_folder)):\n",
    "    audio_path = os.path.join(audio_folder, filename)\n",
    "\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    if sr != 22050:\n",
    "        print(sr)\n",
    "\n",
    "    stft = np.abs(librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, window=window))\n",
    "    flux = librosa.onset.onset_strength(y=y, sr=sr, n_fft=n_fft, hop_length = hop_length)\n",
    "    mfcc = librosa.feature.mfcc(y=y, n_mfcc=13, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "    stft = stft[:stft_taken,:]\n",
    "    stft = stft.T\n",
    "    mfcc = mfcc.T\n",
    "\n",
    "    features_test = np.column_stack((stft, flux*4))\n",
    "\n",
    "    prediction_test = model.predict(features_test)\n",
    "    file = filename.split(\".\")[0]\n",
    "    csv_file = \"audio/clustered_onsets/\" + file + \".csv\"\n",
    "    # Supress and amplify predictions to 0 and 1\n",
    "    prediction_test[prediction_test >= threshold] = 1\n",
    "    prediction_test[prediction_test < threshold] = 0\n",
    "    prediction_test.astype(int)\n",
    "\n",
    "\n",
    "    indices = np.array([i for i in range(prediction_test.shape[0])])\n",
    "    indices = indices.reshape(-1, 1)\n",
    "    print(indices.shape)\n",
    "    print(prediction_test.shape)\n",
    "    print(features_test.shape)\n",
    "    \n",
    "    pos_labels = prediction_test[prediction_test!=0]\n",
    "    pos_index = indices[prediction_test != 0]\n",
    "    pos_features = features_test[prediction_test[:, 0] != 0, :]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(pos_features)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    y_pred_kmeans = kmeans.fit_predict(features_scaled)\n",
    "    #Generate segments of speech from the predictions for each small segment\n",
    "    stepLength = 512/22050\n",
    "\n",
    "\n",
    "    data = [[\"Stroke\", \"Index\"]]\n",
    "\n",
    "    for i in range(len(pos_labels)):\n",
    "\n",
    "        current_time = pos_index[i]*stepLength\n",
    "        current_frame = y_pred_kmeans[i]\n",
    "        #If previous frame has no stroke\n",
    "        #and current frame has stroke\n",
    "        data.append([current_time, current_frame])\\\n",
    "\n",
    "\n",
    "    # Open the CSV file in write mode\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the data to the CSV file row by row\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(pos_features.shape)\n",
    "print(pos_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index (ARI): 0.007933165406509093\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "y_pred_kmeans = kmeans.fit_predict(features_scaled)\n",
    "# ari = adjusted_rand_score(pos_labels, y_pred_kmeans)\n",
    "# print(f\"Adjusted Rand Index (ARI): {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Generate segments of speech from the predictions for each small segment\n",
    "previous_frame = 0\n",
    "start_time = 0\n",
    "stepLength = n_fft/22050\n",
    "\n",
    "data = [[\"Stroke\", \"Index\"]]\n",
    "idx = 0\n",
    "\n",
    "for i in range(len(y_pred_kmeans)):\n",
    "\n",
    "    current_time = pos_index[i]*stepLength\n",
    "    current_frame = y_pred_kmeans[i]\n",
    "    #If previous frame has no stroke\n",
    "    #and current frame has stroke\n",
    "    if previous_frame == 0 and current_frame != 0:\n",
    "        data.append([start_time, current_frame])\n",
    "        idx += 1\n",
    "\n",
    "    previous_frame = current_frame\n",
    "\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the data to the CSV file row by row\n",
    "    for row in data:\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
