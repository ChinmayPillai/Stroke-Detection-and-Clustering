{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chinm\\Documents\\IITK\\EE798K\\Stroke_Detection\\stroke_classification.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chinm/Documents/IITK/EE798K/Stroke_Detection/stroke_classification.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m max_freq \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chinm/Documents/IITK/EE798K/Stroke_Detection/stroke_classification.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Iterate through audio files in the folder\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chinm/Documents/IITK/EE798K/Stroke_Detection/stroke_classification.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(audio_folder)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chinm/Documents/IITK/EE798K/Stroke_Detection/stroke_classification.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# Adjust the file extension if needed\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chinm/Documents/IITK/EE798K/Stroke_Detection/stroke_classification.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         audio_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(audio_folder, filename)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Set the path to the folder containing audio files\n",
    "audio_folder = \"4way-tabla-ismir21-dataset/train/audios\"  # Replace with the path to your audio files folder\n",
    "\n",
    "# Set the parameters for Mel spectrogram\n",
    "n_fft = 512 # Number of points in each FFT\n",
    "hop_length = n_fft  # Hop size\n",
    "fft_len = n_fft//2 + 1  # Number of Mel bands\n",
    "window = \"hann\"  # Window function\n",
    "stft_taken = fft_len//4\n",
    "\n",
    "# Initialize an empty matrix\n",
    "stft_matrix = []\n",
    "flux_arr = []\n",
    "mfcc_matrix = []\n",
    "centroids = []\n",
    "centroid_matrix = []\n",
    "segments_matrix = []\n",
    "max_freq = []\n",
    "\n",
    "# Iterate through audio files in the folder\n",
    "for filename in sorted(os.listdir(audio_folder)):\n",
    "    if filename.endswith(\".wav\"):  # Adjust the file extension if needed\n",
    "        audio_path = os.path.join(audio_folder, filename)\n",
    "\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        if sr != 22050:\n",
    "            print(sr)\n",
    "        \n",
    "        # num_samples = len(y)\n",
    "        # num_segments = num_samples // n_fft\n",
    "        # segments = [y[i * n_fft:(i + 1) * n_fft] for i in range(num_segments)]\n",
    "        # if(num_samples % n_fft != 0):\n",
    "        #     segment = y[num_segments * n_fft:]\n",
    "        #     segment = segment.tolist()\n",
    "        #     for i in range(n_fft - num_samples % n_fft):\n",
    "        #         segment.append(0)\n",
    "        #     segments.append(segment)\n",
    "\n",
    "        # segments_matrix.extend(segments)\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=y, n_mfcc=13, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "        stft = np.abs(librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, window=window))\n",
    "        flux = librosa.onset.onset_strength(y=y, sr=sr, n_fft=n_fft, hop_length = hop_length)\n",
    "        flux = flux\n",
    "        \n",
    "        stft_matrix.append(stft[:stft_taken,:])\n",
    "        flux_arr.append(flux)\n",
    "        mfcc_matrix.append(mfcc)\n",
    "        \n",
    "\n",
    "\n",
    "#segments_matrix = np.concatenate(segments_matrix)\n",
    "stft_matrix = np.hstack(stft_matrix)\n",
    "flux_arr = np.hstack(flux_arr)\n",
    "mfcc_matrix = np.hstack(mfcc_matrix)\n",
    "\n",
    "\n",
    "for i in range(stft_matrix.shape[1]):\n",
    "    segment = stft_matrix[:, i]\n",
    "    \n",
    "    # Compute the frequencies and magnitudes\n",
    "    frequencies = librosa.fft_frequencies(sr=sr, n_fft=n_fft)[:stft_taken]\n",
    "    magnitudes = segment\n",
    "    # # Transpose frequencies to match the shape of magnitudes\n",
    "    # frequencies = frequencies[:, np.newaxis]\n",
    "    max_frequency_index = np.argmax(segment, axis=0)\n",
    "    max_freq.append(frequencies[max_frequency_index])\n",
    "    # Calculate the spectral centroid\n",
    "\n",
    "    centroid = np.sum(frequencies * magnitudes, axis=0) / np.sum(magnitudes, axis=0)\n",
    "    # Take the mean of the centroid values across the segment\n",
    "    mean_centroid = np.mean(centroid)\n",
    "    centroid_matrix.append(mean_centroid)\n",
    "\n",
    "flux_arr = flux_arr.T\n",
    "stft_matrix = stft_matrix.T\n",
    "\n",
    "mfcc_matrix = mfcc_matrix.T\n",
    "max_freq = np.array(max_freq)\n",
    "centroid_matrix = np.array(centroid_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "(64,)\n",
      "(202194,)\n"
     ]
    }
   ],
   "source": [
    "# print(segment.shape)\n",
    "print(frequencies.shape)\n",
    "print(magnitudes.shape)\n",
    "print(max_freq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202194, 13)\n",
      "(202194,)\n",
      "(202194,)\n"
     ]
    }
   ],
   "source": [
    "print(mfcc_matrix.shape)\n",
    "print(flux_arr.shape)\n",
    "print(centroid_matrix.shape)\n",
    "# print(segments_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments_matrix = np.array(segments_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# # Record the start time\n",
    "# start_time = time.time()\n",
    "# autocorrelation_matrix[0, 0] = np.correlate(segments_matrix[0], segments_matrix[0], mode='full')[0]\n",
    "# # Record the end time\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Calculate the elapsed time\n",
    "# elapsed_time = end_time - start_time\n",
    "\n",
    "# print(f\"Time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_segments = segments_matrix.shape[0]\n",
    "# autocorrelation_matrix = np.zeros((num_segments, num_segments))\n",
    "\n",
    "# for i in range(num_segments):\n",
    "#     for j in range(i,num_segments):\n",
    "#         autocorrelation_matrix[i, j] = np.correlate(segments_matrix[i], segments_matrix[j], mode='full')[0]\n",
    "#         autocorrelation_matrix[j,i] = autocorrelation_matrix[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_segments = segments_matrix.shape[0]\n",
    "# autocorrelation_matrix = np.zeros((num_segments, num_segments))\n",
    "# for i in range(num_segments):\n",
    "#     for j in range(i,num_segments):\n",
    "#         result = np.fft.ifft(np.fft.fft(segments_matrix[i]) * np.fft.fft(segments_matrix[j]).conj()).real\n",
    "#         autocorrelation_matrix[i, j] = np.sum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = np.column_stack((mfcc_matrix, flux_arr*4, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.        0.        ... 0.607357  1.1710113 0.9910203]\n",
      "44.454247\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(flux_arr)\n",
    "print(flux_arr.max())\n",
    "print(flux_arr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1365.09812052 1469.53397279 1381.88916934 ...  171.80083917  163.47974022\n",
      "  168.5204392 ]\n",
      "1848.0559591116091\n",
      "37.71570449081577\n"
     ]
    }
   ],
   "source": [
    "print(centroid_matrix)\n",
    "print(centroid_matrix.max())\n",
    "print(centroid_matrix.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time_step of the audio file\n",
    "time_step = hop_length/22050\n",
    "\n",
    "audio_folder = \"4way-tabla-ismir21-dataset/train/audios\" \n",
    "onset_folder = \"4way-tabla-ismir21-dataset/train/onsets\"\n",
    "\n",
    "# Initialize an empty matrix to store the spectrograms\n",
    "label_array = []\n",
    "lens = []\n",
    "\n",
    "for filename in sorted(os.listdir(audio_folder)):\n",
    "\n",
    "    file_name, extension = os.path.splitext(filename)\n",
    "    onsetfile = f\"{file_name}.{'onsets'}\"\n",
    "\n",
    "    # Provide the path to your audio file\n",
    "    audio_file_path = os.path.join(audio_folder, filename)\n",
    "    \n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file_path)\n",
    "\n",
    "    # Calculate the duration of the audio in seconds\n",
    "    audio_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "\n",
    "    # Calculate the number of time steps and initialize the array with zeros\n",
    "    num_time_steps = int(audio_duration / time_step)\n",
    "    num_time_steps += 1\n",
    "    stroke_array = np.zeros(num_time_steps)\n",
    "    \n",
    "    # Read the .ONSETS file to get the times of the strokes\n",
    "    for index, i in enumerate([\"b\", \"d\", \"rb\", \"rt\"]):\n",
    "        file_path = os.path.join(onset_folder, i, onsetfile)\n",
    "        with open(file_path, 'r') as file:\n",
    "            stroke_times = [float(line.strip()) for line in file]\n",
    "\n",
    "        # Set the values to 1 where there is a stroke within the time period\n",
    "        for stroke_time in stroke_times:\n",
    "            time_step_index = int(stroke_time / time_step)\n",
    "            if time_step_index < num_time_steps:\n",
    "                stroke_array[time_step_index] = index + 1\n",
    "        \n",
    "    \n",
    "    label_array.append(stroke_array)\n",
    "    lens.append(len(stroke_array))\n",
    "\n",
    "label_array = np.hstack(label_array)\n",
    "\n",
    "label_array = label_array.T   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202194, 14)\n",
      "(202194,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25654, 14)\n",
      "(25654,)\n"
     ]
    }
   ],
   "source": [
    "pos_labels = label_array[label_array != 0]\n",
    "pos_features = features[label_array != 0][:]\n",
    "\n",
    "print(pos_features.shape)\n",
    "print(pos_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_labels = pos_labels - 1\n",
    "pos_labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(pos_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index (ARI): 0.007933165406509093\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "y_pred_kmeans = kmeans.fit_predict(features_scaled)\n",
    "ari = adjusted_rand_score(pos_labels, y_pred_kmeans)\n",
    "print(f\"Adjusted Rand Index (ARI): {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04873491632785393"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "y_pred_kmeans = kmeans.fit_predict(features_scaled)\n",
    "ari = adjusted_rand_score(pos_labels, y_pred_kmeans)\n",
    "print(f\"Adjusted Rand Index (ARI): {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index (ARI): 0.022156200140686807\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=1.525, min_samples=2) \n",
    "y_pred_dbscan = dbscan.fit_predict(features_scaled)\n",
    "ari = adjusted_rand_score(pos_labels, y_pred_dbscan)\n",
    "print(f\"Adjusted Rand Index (ARI): {ari}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index (ARI) for Agglomerative Clustering: 0.03815880441380059\n"
     ]
    }
   ],
   "source": [
    "agglomerative = AgglomerativeClustering(n_clusters=num_strokes)\n",
    "y_pred_agglomerative = agglomerative.fit_predict(features_scaled)\n",
    "\n",
    "# Evaluate the clustering results using Adjusted Rand Index (ARI)\n",
    "ari_agglomerative = adjusted_rand_score(pos_labels, y_pred_agglomerative)\n",
    "print(f\"Adjusted Rand Index (ARI) for Agglomerative Clustering: {ari_agglomerative}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
